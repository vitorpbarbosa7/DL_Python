{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"5_Hyperparameters_Tuning.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyPDU2L6B3mhM6ml5ha0IYoC"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"C8hS6k5goOqo","colab_type":"text"},"source":["# GridSearchCV em rede neural"]},{"cell_type":"code","metadata":{"id":"9h0-aM_4oVWs","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1592656923495,"user_tz":180,"elapsed":2119,"user":{"displayName":"Vitor Pereira Barbosa","photoUrl":"","userId":"04831474142422958031"}},"outputId":"076eb0fa-0071-4441-a0a5-3aebfab3e2f7"},"source":["import pandas as pd\n","import numpy as np\n","import math\n","\n","#Keras from tensorflow\n","import keras \n","# Rede neural\n","from tensorflow import keras\n","#Arquitetura da rede neural\n","from keras.models import Sequential\n","#Rede neural fully connected\n","from keras.layers import Dense\n","#Import dropout layer from Keras\n","from keras.layers import Dropout\n"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"5PWFCR2vuZFl","colab_type":"text"},"source":["## Carregar os dados a partir do Google Drive"]},{"cell_type":"code","metadata":{"id":"cvkcyigcudOw","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":127},"executionInfo":{"status":"ok","timestamp":1592656608308,"user_tz":180,"elapsed":25619,"user":{"displayName":"Vitor Pereira Barbosa","photoUrl":"","userId":"04831474142422958031"}},"outputId":"88703ab2-aa3c-45b5-b78d-aa6ea3673ff2"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7fD8avHcu0hU","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1592656883987,"user_tz":180,"elapsed":2621,"user":{"displayName":"Vitor Pereira Barbosa","photoUrl":"","userId":"04831474142422958031"}},"outputId":"279ecbea-89c4-40d3-c4fc-75c79654d669"},"source":["# Após montar o drive é possível copiar o path a partir do menu à esquerda <=========\n","!ls '/content/drive/My Drive/DS/DS_Share/Udemy-DeepLearning/S4_ClassificacaoBinaria/colab'"],"execution_count":6,"outputs":[{"output_type":"stream","text":["5_Hyperparameters_Tuning.ipynb\tentradas.csv  saidas.csv\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Ft7lxZzZuXOQ","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592657052084,"user_tz":180,"elapsed":1318,"user":{"displayName":"Vitor Pereira Barbosa","photoUrl":"","userId":"04831474142422958031"}}},"source":["#Carregar os dados\n","path = '/content/drive/My Drive/DS/DS_Share/Udemy-DeepLearning/S4_ClassificacaoBinaria/colab'\n","df_entradas = pd.read_csv(path + '/entradas.csv')\n","df_saidas = pd.read_csv(path + '/saidas.csv')"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"stFdzGDQv-Ow","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592657052088,"user_tz":180,"elapsed":971,"user":{"displayName":"Vitor Pereira Barbosa","photoUrl":"","userId":"04831474142422958031"}}},"source":["X = df_entradas.values\n","y = df_saidas.values\n"],"execution_count":15,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NtUqe22VoiLt","colab_type":"text"},"source":["## Validação cruzada"]},{"cell_type":"code","metadata":{"id":"tDuDBoGOol5J","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592657056823,"user_tz":180,"elapsed":1190,"user":{"displayName":"Vitor Pereira Barbosa","photoUrl":"","userId":"04831474142422958031"}}},"source":["#O wrapper do keras é uma função da rotina keras responsável por chamar uma segunda subrotina, ou seja, o scikit learn\n","from keras.wrappers.scikit_learn import KerasClassifier\n","from sklearn.model_selection import cross_val_score\n"],"execution_count":16,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zah5wT_tolKC","colab_type":"text"},"source":["# GridSearchCV para tuning dos parâmetros\n"]},{"cell_type":"code","metadata":{"id":"K8l-iMcsor6f","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592657067119,"user_tz":180,"elapsed":8521,"user":{"displayName":"Vitor Pereira Barbosa","photoUrl":"","userId":"04831474142422958031"}}},"source":["# Pesquisa em grade para encontrar os melhores parâmetros\n","from sklearn.model_selection import GridSearchCV "],"execution_count":17,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"D-b_297You1Q","colab_type":"text"},"source":["# Criação da rede dentro de uma função (a função retornará o classificador)\n"]},{"cell_type":"code","metadata":{"id":"2LP1N2TiozGa","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592657091991,"user_tz":180,"elapsed":924,"user":{"displayName":"Vitor Pereira Barbosa","photoUrl":"","userId":"04831474142422958031"}}},"source":["# Anteriormente ao GridSearchCV, haviámos criado a rede neural de forma estática. \n","# Agora vamos passar como hyperparâmetros:\n","#optimizer, \n","def criar_rede(optimizer, loss, kernel_initializer, activation, neurons):\n","\n","    #Network creation\n","    classificador = Sequential()\n","    \n","    #Adicao da primeira camada oculta do tipo Dense, ou seja, fully connected\n","    classificador.add(Dense(units = neurons,\n","                        activation=activation, #Geralmente bom desempenho para Deep Learning \n","                        kernel_initializer=kernel_initializer, #Inicilializacao dos pesos\n","                        input_dim=30,\n","                        use_bias = True))\n","    \n","    #Camada de dropout introduzida com o propósito de reduzir o overfitting\n","    #Possui portanto efeito de regularização, assim como ocorre com Ridge e Lasso Regression\n","    #Introdução de um bias para reduzir a variancia \n","    classificador.add(Dropout(rate = 0.2)) #20 % dos neurônios irão zerar\n","    \n","    #Adição de mais uma camada oculta:\n","    classificador.add(Dense(units = neurons,\n","                        activation=activation, #Geralmente bom desempenho para Deep Learning \n","                        kernel_initializer=kernel_initializer,\n","                        use_bias = True)), #Inicilializacao dos pesos\n","    \n","    #Adição da camada de dropout para zerar neurônios da camada anteriormente definida? \n","    #Geralmente eh importante se preocupar em reduzir o overfitting de camadas maiores, \n","    #Como essas duas camadas bem grandes\n","    classificador.add(Dropout(rate = 0.2))\n","    \n","    #Output layer\n","    # Para classificação binária, utilizar sigmoid é adequado porque retorna uma probabilidade \n","    classificador.add(Dense(units=1, \n","                  activation='sigmoid',\n","                  use_bias = True))    \n","    \n","    #Compilacao da rede neural:\n","    #Classificação binária posso utilizar crossnetropy\n","    #Antes estávamos utilizando otimizador fixo, e agora será otimizador do GridSearchCV\n","    classificador.compile(optimizer=optimizer,\n","                      loss = loss,\n","                      metrics= ['binary_accuracy']) #Sempre no formato de lista ou dicionário\n","    \n","    #Visualizar a arquitetura total da rede mais seus hiperparâmetros definidos para o treinamento\n","    classificador.summary()\n","    \n","    #O importante é que esta funcao retorne o classificador\n","    return classificador\n"],"execution_count":19,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kmK3PIC9o0tH","colab_type":"text"},"source":["# Criando o classificador a partir do KerasClassifier"]},{"cell_type":"code","metadata":{"id":"9wJrYyO_pI6b","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592657096234,"user_tz":180,"elapsed":809,"user":{"displayName":"Vitor Pereira Barbosa","photoUrl":"","userId":"04831474142422958031"}}},"source":["#Na utilização de GridSearchCV, ao instanciar o objeto classificador a partir da classe KerasClassifier, só preciso inserir o build_fn para criar a função \n","# e não as épocas e batch size\n","classificador = KerasClassifier(build_fn=criar_rede)"],"execution_count":20,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HHakFggHpq64","colab_type":"text"},"source":["## Hyperparâmetros que serão testados no tuning"]},{"cell_type":"code","metadata":{"id":"5AoC6I8Pp5mi","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592657099689,"user_tz":180,"elapsed":1002,"user":{"displayName":"Vitor Pereira Barbosa","photoUrl":"","userId":"04831474142422958031"}}},"source":["#Hyperparâmetros são inseridos no formato de dicionário. \n","#Chaves com o nome do hyperparâmetro e valor na forma de lista\n","parameters = {'batch_size': [16,32], \n","              'epochs': [30,50],\n","              'optimizer': ['SGD','Adam'],\n","              'loss': ['binary_crossentropy','poisson'],\n","              'kernel_initializer': ['random_uniform','random_normal'],\n","              'activation': ['relu','tanh'],\n","              'neurons': [16,20]} "],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"7xOVw_ngsWx5","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":143},"executionInfo":{"status":"ok","timestamp":1592657101573,"user_tz":180,"elapsed":517,"user":{"displayName":"Vitor Pereira Barbosa","photoUrl":"","userId":"04831474142422958031"}},"outputId":"8faf1a2a-a3b0-4163-845d-a9ab0f9a3a4a"},"source":["parameters"],"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'activation': ['relu', 'tanh'],\n"," 'batch_size': [16, 32],\n"," 'epochs': [30, 50],\n"," 'kernel_initializer': ['random_uniform', 'random_normal'],\n"," 'loss': ['binary_crossentropy', 'poisson'],\n"," 'neurons': [16, 20],\n"," 'optimizer': ['SGD', 'Adam']}"]},"metadata":{"tags":[]},"execution_count":22}]},{"cell_type":"markdown","metadata":{"id":"Q35fKV75sXiZ","colab_type":"text"},"source":["# Criação do GridSearchCV\n","- No próprio GridSearchCV está implementado a Validação Cruzada "]},{"cell_type":"code","metadata":{"id":"1QxrFLY1shAc","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592657105225,"user_tz":180,"elapsed":969,"user":{"displayName":"Vitor Pereira Barbosa","photoUrl":"","userId":"04831474142422958031"}}},"source":["gridsearch = GridSearchCV(estimator = classificador, \n","                          param_grid = parameters, \n","                          scoring = 'accuracy',\n","                          cv = 5)"],"execution_count":23,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xtFP_v0Ts0U0","colab_type":"text"},"source":["## O treinamento do modelo é realizado a partir do objeto gridsearch instanciado a partir da classe GridSearchCV, logo a esta classe possui a ação, o método, a função fit()"]},{"cell_type":"code","metadata":{"id":"Bh93REpls-uP","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"error","timestamp":1592657519061,"user_tz":180,"elapsed":411715,"user":{"displayName":"Vitor Pereira Barbosa","photoUrl":"","userId":"04831474142422958031"}},"outputId":"3e4a529e-ff2a-426c-d1b7-39ce85ff71c5"},"source":["gridsearch = gridsearch.fit(X = X, \n","                            y = y)"],"execution_count":24,"outputs":[{"output_type":"stream","text":["\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n","Epoch 28/30\n","455/455 [==============================] - 0s 193us/step - loss: 0.2940 - binary_accuracy: 0.8681\n","Epoch 29/30\n","455/455 [==============================] - 0s 195us/step - loss: 0.3043 - binary_accuracy: 0.8703\n","Epoch 30/30\n","455/455 [==============================] - 0s 200us/step - loss: 0.2770 - binary_accuracy: 0.8901\n","Model: \"sequential_60\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_178 (Dense)            (None, 20)                620       \n","_________________________________________________________________\n","dropout_119 (Dropout)        (None, 20)                0         \n","_________________________________________________________________\n","dense_179 (Dense)            (None, 20)                420       \n","_________________________________________________________________\n","dropout_120 (Dropout)        (None, 20)                0         \n","_________________________________________________________________\n","dense_180 (Dense)            (None, 1)                 21        \n","=================================================================\n","Total params: 1,061\n","Trainable params: 1,061\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/30\n","456/456 [==============================] - 0s 471us/step - loss: 4.3262 - binary_accuracy: 0.5526\n","Epoch 2/30\n","456/456 [==============================] - 0s 188us/step - loss: 2.4206 - binary_accuracy: 0.5702\n","Epoch 3/30\n","456/456 [==============================] - 0s 195us/step - loss: 1.6612 - binary_accuracy: 0.5570\n","Epoch 4/30\n","456/456 [==============================] - 0s 201us/step - loss: 1.1586 - binary_accuracy: 0.5965\n","Epoch 5/30\n","456/456 [==============================] - 0s 210us/step - loss: 0.8757 - binary_accuracy: 0.5768\n","Epoch 6/30\n","456/456 [==============================] - 0s 193us/step - loss: 0.7583 - binary_accuracy: 0.5987\n","Epoch 7/30\n","456/456 [==============================] - 0s 222us/step - loss: 0.7091 - binary_accuracy: 0.6031\n","Epoch 8/30\n","456/456 [==============================] - 0s 203us/step - loss: 0.6890 - binary_accuracy: 0.5658\n","Epoch 9/30\n","456/456 [==============================] - 0s 191us/step - loss: 0.7106 - binary_accuracy: 0.5811\n","Epoch 10/30\n","456/456 [==============================] - 0s 188us/step - loss: 0.6268 - binary_accuracy: 0.5921\n","Epoch 11/30\n","456/456 [==============================] - 0s 189us/step - loss: 0.5777 - binary_accuracy: 0.6228\n","Epoch 12/30\n","456/456 [==============================] - 0s 213us/step - loss: 0.6072 - binary_accuracy: 0.6250\n","Epoch 13/30\n","456/456 [==============================] - 0s 196us/step - loss: 0.5861 - binary_accuracy: 0.6184\n","Epoch 14/30\n","456/456 [==============================] - 0s 199us/step - loss: 0.6425 - binary_accuracy: 0.6601\n","Epoch 15/30\n","456/456 [==============================] - 0s 190us/step - loss: 0.5967 - binary_accuracy: 0.6316\n","Epoch 16/30\n","456/456 [==============================] - 0s 192us/step - loss: 0.5792 - binary_accuracy: 0.6184\n","Epoch 17/30\n","456/456 [==============================] - 0s 215us/step - loss: 0.5394 - binary_accuracy: 0.6557\n","Epoch 18/30\n","456/456 [==============================] - 0s 196us/step - loss: 0.5592 - binary_accuracy: 0.6623\n","Epoch 19/30\n","456/456 [==============================] - 0s 192us/step - loss: 0.5253 - binary_accuracy: 0.6996\n","Epoch 20/30\n","456/456 [==============================] - 0s 192us/step - loss: 0.5518 - binary_accuracy: 0.6908\n","Epoch 21/30\n","456/456 [==============================] - 0s 191us/step - loss: 0.5449 - binary_accuracy: 0.6754\n","Epoch 22/30\n","456/456 [==============================] - 0s 192us/step - loss: 0.5222 - binary_accuracy: 0.6908\n","Epoch 23/30\n","456/456 [==============================] - 0s 220us/step - loss: 0.5372 - binary_accuracy: 0.6776\n","Epoch 24/30\n","456/456 [==============================] - 0s 196us/step - loss: 0.5360 - binary_accuracy: 0.6798\n","Epoch 25/30\n","456/456 [==============================] - 0s 197us/step - loss: 0.5424 - binary_accuracy: 0.6842\n","Epoch 26/30\n","456/456 [==============================] - 0s 192us/step - loss: 0.5214 - binary_accuracy: 0.6579\n","Epoch 27/30\n","456/456 [==============================] - 0s 208us/step - loss: 0.5199 - binary_accuracy: 0.7127\n","Epoch 28/30\n","456/456 [==============================] - 0s 210us/step - loss: 0.4995 - binary_accuracy: 0.6776\n","Epoch 29/30\n","456/456 [==============================] - 0s 223us/step - loss: 0.4798 - binary_accuracy: 0.7325\n","Epoch 30/30\n","456/456 [==============================] - 0s 201us/step - loss: 0.4997 - binary_accuracy: 0.7083\n","Model: \"sequential_61\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_181 (Dense)            (None, 16)                496       \n","_________________________________________________________________\n","dropout_121 (Dropout)        (None, 16)                0         \n","_________________________________________________________________\n","dense_182 (Dense)            (None, 16)                272       \n","_________________________________________________________________\n","dropout_122 (Dropout)        (None, 16)                0         \n","_________________________________________________________________\n","dense_183 (Dense)            (None, 1)                 17        \n","=================================================================\n","Total params: 785\n","Trainable params: 785\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/30\n","455/455 [==============================] - 0s 340us/step - loss: 1.1418 - binary_accuracy: 0.6747\n","Epoch 2/30\n","455/455 [==============================] - 0s 158us/step - loss: 1.0003 - binary_accuracy: 0.6835\n","Epoch 3/30\n","455/455 [==============================] - 0s 156us/step - loss: 1.0333 - binary_accuracy: 0.6813\n","Epoch 4/30\n","455/455 [==============================] - 0s 159us/step - loss: 1.0006 - binary_accuracy: 0.6835\n","Epoch 5/30\n","455/455 [==============================] - 0s 152us/step - loss: 1.0997 - binary_accuracy: 0.6769\n","Epoch 6/30\n","455/455 [==============================] - 0s 150us/step - loss: 1.0002 - binary_accuracy: 0.6835\n","Epoch 7/30\n","455/455 [==============================] - 0s 159us/step - loss: 0.9978 - binary_accuracy: 0.6857\n","Epoch 8/30\n","455/455 [==============================] - 0s 191us/step - loss: 1.0664 - binary_accuracy: 0.6791\n","Epoch 9/30\n","455/455 [==============================] - 0s 180us/step - loss: 1.0332 - binary_accuracy: 0.6813\n","Epoch 10/30\n","455/455 [==============================] - 0s 200us/step - loss: 1.0665 - binary_accuracy: 0.6791\n","Epoch 11/30\n","455/455 [==============================] - 0s 193us/step - loss: 1.0333 - binary_accuracy: 0.6813\n","Epoch 12/30\n","455/455 [==============================] - 0s 168us/step - loss: 0.9994 - binary_accuracy: 0.6835\n","Epoch 13/30\n","455/455 [==============================] - 0s 155us/step - loss: 1.0000 - binary_accuracy: 0.6835\n","Epoch 14/30\n","455/455 [==============================] - 0s 155us/step - loss: 1.0000 - binary_accuracy: 0.6835\n","Epoch 15/30\n","455/455 [==============================] - 0s 155us/step - loss: 0.9991 - binary_accuracy: 0.6835\n","Epoch 16/30\n","455/455 [==============================] - 0s 162us/step - loss: 1.0009 - binary_accuracy: 0.6813\n","Epoch 17/30\n","455/455 [==============================] - 0s 166us/step - loss: 1.0000 - binary_accuracy: 0.6835\n","Epoch 18/30\n","455/455 [==============================] - 0s 154us/step - loss: 1.0653 - binary_accuracy: 0.6791\n","Epoch 19/30\n","455/455 [==============================] - 0s 158us/step - loss: 1.0173 - binary_accuracy: 0.6813\n","Epoch 20/30\n","455/455 [==============================] - 0s 182us/step - loss: 1.0000 - binary_accuracy: 0.6835\n","Epoch 21/30\n","455/455 [==============================] - 0s 207us/step - loss: 0.9989 - binary_accuracy: 0.6835\n","Epoch 22/30\n","455/455 [==============================] - 0s 173us/step - loss: 1.0000 - binary_accuracy: 0.6835\n","Epoch 23/30\n","455/455 [==============================] - 0s 161us/step - loss: 1.0000 - binary_accuracy: 0.6835\n","Epoch 24/30\n","455/455 [==============================] - 0s 151us/step - loss: 1.0000 - binary_accuracy: 0.6835\n","Epoch 25/30\n","455/455 [==============================] - 0s 149us/step - loss: 1.0000 - binary_accuracy: 0.6835\n","Epoch 26/30\n","455/455 [==============================] - 0s 161us/step - loss: 1.0000 - binary_accuracy: 0.6835\n","Epoch 27/30\n","455/455 [==============================] - 0s 147us/step - loss: 1.0000 - binary_accuracy: 0.6835\n","Epoch 28/30\n","455/455 [==============================] - 0s 148us/step - loss: 1.0000 - binary_accuracy: 0.6835\n","Epoch 29/30\n","455/455 [==============================] - 0s 146us/step - loss: 1.0000 - binary_accuracy: 0.6835\n","Epoch 30/30\n","455/455 [==============================] - 0s 158us/step - loss: 1.0000 - binary_accuracy: 0.6835\n","Model: \"sequential_62\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_184 (Dense)            (None, 16)                496       \n","_________________________________________________________________\n","dropout_123 (Dropout)        (None, 16)                0         \n","_________________________________________________________________\n","dense_185 (Dense)            (None, 16)                272       \n","_________________________________________________________________\n","dropout_124 (Dropout)        (None, 16)                0         \n","_________________________________________________________________\n","dense_186 (Dense)            (None, 1)                 17        \n","=================================================================\n","Total params: 785\n","Trainable params: 785\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/30\n","455/455 [==============================] - 0s 399us/step - loss: 1.0469 - binary_accuracy: 0.6352\n","Epoch 2/30\n","455/455 [==============================] - 0s 186us/step - loss: 0.9990 - binary_accuracy: 0.6418\n","Epoch 3/30\n","455/455 [==============================] - 0s 186us/step - loss: 0.9999 - binary_accuracy: 0.6418\n","Epoch 4/30\n","455/455 [==============================] - 0s 190us/step - loss: 1.0000 - binary_accuracy: 0.6418\n","Epoch 5/30\n","455/455 [==============================] - 0s 192us/step - loss: 1.0011 - binary_accuracy: 0.6396\n","Epoch 6/30\n","455/455 [==============================] - 0s 199us/step - loss: 0.9996 - binary_accuracy: 0.6418\n","Epoch 7/30\n","455/455 [==============================] - 0s 194us/step - loss: 0.9993 - binary_accuracy: 0.6418\n","Epoch 8/30\n","455/455 [==============================] - 0s 187us/step - loss: 1.0007 - binary_accuracy: 0.6418\n","Epoch 9/30\n","455/455 [==============================] - 0s 196us/step - loss: 1.0000 - binary_accuracy: 0.6418\n","Epoch 10/30\n","455/455 [==============================] - 0s 173us/step - loss: 1.0014 - binary_accuracy: 0.6396\n","Epoch 11/30\n","455/455 [==============================] - 0s 149us/step - loss: 1.0000 - binary_accuracy: 0.6418\n","Epoch 12/30\n","455/455 [==============================] - 0s 149us/step - loss: 1.0000 - binary_accuracy: 0.6418\n","Epoch 13/30\n","455/455 [==============================] - 0s 163us/step - loss: 1.0000 - binary_accuracy: 0.6418\n","Epoch 14/30\n","455/455 [==============================] - 0s 159us/step - loss: 1.0004 - binary_accuracy: 0.6418\n","Epoch 15/30\n","455/455 [==============================] - 0s 150us/step - loss: 1.0000 - binary_accuracy: 0.6418\n","Epoch 16/30\n","455/455 [==============================] - 0s 147us/step - loss: 1.0004 - binary_accuracy: 0.6418\n","Epoch 17/30\n","455/455 [==============================] - 0s 153us/step - loss: 1.0000 - binary_accuracy: 0.6418\n","Epoch 18/30\n","455/455 [==============================] - 0s 152us/step - loss: 1.0004 - binary_accuracy: 0.6418\n","Epoch 19/30\n","455/455 [==============================] - 0s 168us/step - loss: 0.9998 - binary_accuracy: 0.6418\n","Epoch 20/30\n","455/455 [==============================] - 0s 191us/step - loss: 0.9996 - binary_accuracy: 0.6418\n","Epoch 21/30\n","455/455 [==============================] - 0s 155us/step - loss: 0.9999 - binary_accuracy: 0.6418\n","Epoch 22/30\n","455/455 [==============================] - 0s 151us/step - loss: 1.0000 - binary_accuracy: 0.6418\n","Epoch 23/30\n","455/455 [==============================] - 0s 181us/step - loss: 0.9991 - binary_accuracy: 0.6418\n","Epoch 24/30\n","455/455 [==============================] - 0s 152us/step - loss: 0.9993 - binary_accuracy: 0.6418\n","Epoch 25/30\n","455/455 [==============================] - 0s 146us/step - loss: 1.0002 - binary_accuracy: 0.6418\n","Epoch 26/30\n","455/455 [==============================] - 0s 175us/step - loss: 1.0005 - binary_accuracy: 0.6418\n","Epoch 27/30\n","455/455 [==============================] - 0s 156us/step - loss: 1.0000 - binary_accuracy: 0.6418\n","Epoch 28/30\n","455/455 [==============================] - 0s 148us/step - loss: 0.9999 - binary_accuracy: 0.6418\n","Epoch 29/30\n","455/455 [==============================] - 0s 151us/step - loss: 0.9993 - binary_accuracy: 0.6418\n","Epoch 30/30\n","455/455 [==============================] - 0s 143us/step - loss: 1.0000 - binary_accuracy: 0.6418\n","Model: \"sequential_63\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_187 (Dense)            (None, 16)                496       \n","_________________________________________________________________\n","dropout_125 (Dropout)        (None, 16)                0         \n","_________________________________________________________________\n","dense_188 (Dense)            (None, 16)                272       \n","_________________________________________________________________\n","dropout_126 (Dropout)        (None, 16)                0         \n","_________________________________________________________________\n","dense_189 (Dense)            (None, 1)                 17        \n","=================================================================\n","Total params: 785\n","Trainable params: 785\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/30\n","455/455 [==============================] - 0s 363us/step - loss: 1.6145 - binary_accuracy: 0.5802\n","Epoch 2/30\n","455/455 [==============================] - 0s 147us/step - loss: 1.1106 - binary_accuracy: 0.6132\n","Epoch 3/30\n","455/455 [==============================] - 0s 146us/step - loss: 1.0087 - binary_accuracy: 0.6198\n","Epoch 4/30\n","455/455 [==============================] - 0s 171us/step - loss: 0.9995 - binary_accuracy: 0.6220\n","Epoch 5/30\n","455/455 [==============================] - 0s 151us/step - loss: 1.0003 - binary_accuracy: 0.6220\n","Epoch 6/30\n","455/455 [==============================] - 0s 155us/step - loss: 0.9983 - binary_accuracy: 0.6242\n","Epoch 7/30\n","455/455 [==============================] - 0s 151us/step - loss: 0.9905 - binary_accuracy: 0.6330\n","Epoch 8/30\n","455/455 [==============================] - 0s 150us/step - loss: 1.0000 - binary_accuracy: 0.6198\n","Epoch 9/30\n","455/455 [==============================] - 0s 148us/step - loss: 1.0021 - binary_accuracy: 0.6198\n","Epoch 10/30\n","455/455 [==============================] - 0s 174us/step - loss: 0.9986 - binary_accuracy: 0.6242\n","Epoch 11/30\n","455/455 [==============================] - 0s 148us/step - loss: 0.9985 - binary_accuracy: 0.6220\n","Epoch 12/30\n","455/455 [==============================] - 0s 153us/step - loss: 1.0001 - binary_accuracy: 0.6220\n","Epoch 13/30\n","455/455 [==============================] - 0s 149us/step - loss: 1.0024 - binary_accuracy: 0.6242\n","Epoch 14/30\n","455/455 [==============================] - 0s 175us/step - loss: 0.9918 - binary_accuracy: 0.6242\n","Epoch 15/30\n","455/455 [==============================] - 0s 150us/step - loss: 1.0000 - binary_accuracy: 0.6220\n","Epoch 16/30\n","455/455 [==============================] - 0s 181us/step - loss: 1.0041 - binary_accuracy: 0.6198\n","Epoch 17/30\n","455/455 [==============================] - 0s 210us/step - loss: 0.9985 - binary_accuracy: 0.6220\n","Epoch 18/30\n","455/455 [==============================] - 0s 202us/step - loss: 0.9994 - binary_accuracy: 0.6220\n","Epoch 19/30\n","455/455 [==============================] - 0s 193us/step - loss: 0.9978 - binary_accuracy: 0.6242\n","Epoch 20/30\n","455/455 [==============================] - 0s 189us/step - loss: 0.9997 - binary_accuracy: 0.6220\n","Epoch 21/30\n","455/455 [==============================] - 0s 188us/step - loss: 0.9955 - binary_accuracy: 0.6242\n","Epoch 22/30\n","455/455 [==============================] - 0s 215us/step - loss: 0.9968 - binary_accuracy: 0.6220\n","Epoch 23/30\n","455/455 [==============================] - 0s 199us/step - loss: 0.9992 - binary_accuracy: 0.6220\n","Epoch 24/30\n","455/455 [==============================] - 0s 189us/step - loss: 0.9979 - binary_accuracy: 0.6242\n","Epoch 25/30\n","455/455 [==============================] - 0s 191us/step - loss: 1.0033 - binary_accuracy: 0.6198\n","Epoch 26/30\n","455/455 [==============================] - 0s 195us/step - loss: 0.9982 - binary_accuracy: 0.6220\n","Epoch 27/30\n","455/455 [==============================] - 0s 185us/step - loss: 1.0004 - binary_accuracy: 0.6220\n","Epoch 28/30\n","455/455 [==============================] - 0s 193us/step - loss: 0.9995 - binary_accuracy: 0.6220\n","Epoch 29/30\n","455/455 [==============================] - 0s 150us/step - loss: 1.0000 - binary_accuracy: 0.6220\n","Epoch 30/30\n","455/455 [==============================] - 0s 150us/step - loss: 0.9990 - binary_accuracy: 0.6220\n","Model: \"sequential_64\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_190 (Dense)            (None, 16)                496       \n","_________________________________________________________________\n","dropout_127 (Dropout)        (None, 16)                0         \n","_________________________________________________________________\n","dense_191 (Dense)            (None, 16)                272       \n","_________________________________________________________________\n","dropout_128 (Dropout)        (None, 16)                0         \n","_________________________________________________________________\n","dense_192 (Dense)            (None, 1)                 17        \n","=================================================================\n","Total params: 785\n","Trainable params: 785\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/30\n","455/455 [==============================] - 0s 353us/step - loss: 1.1920 - binary_accuracy: 0.5780\n","Epoch 2/30\n","455/455 [==============================] - 0s 156us/step - loss: 1.0360 - binary_accuracy: 0.5934\n","Epoch 3/30\n","455/455 [==============================] - 0s 147us/step - loss: 0.9991 - binary_accuracy: 0.5978\n","Epoch 4/30\n","455/455 [==============================] - 0s 150us/step - loss: 1.0302 - binary_accuracy: 0.5978\n","Epoch 5/30\n","455/455 [==============================] - 0s 152us/step - loss: 1.0022 - binary_accuracy: 0.5956\n","Epoch 6/30\n","455/455 [==============================] - 0s 194us/step - loss: 0.9983 - binary_accuracy: 0.6000\n","Epoch 7/30\n","455/455 [==============================] - 0s 213us/step - loss: 0.9993 - binary_accuracy: 0.5978\n","Epoch 8/30\n","455/455 [==============================] - 0s 190us/step - loss: 1.0163 - binary_accuracy: 0.5956\n","Epoch 9/30\n","455/455 [==============================] - 0s 193us/step - loss: 1.0000 - binary_accuracy: 0.5978\n","Epoch 10/30\n","455/455 [==============================] - 0s 178us/step - loss: 1.0000 - binary_accuracy: 0.5978\n","Epoch 11/30\n","455/455 [==============================] - 0s 181us/step - loss: 1.0011 - binary_accuracy: 0.5956\n","Epoch 12/30\n","455/455 [==============================] - 0s 183us/step - loss: 1.0005 - binary_accuracy: 0.5978\n","Epoch 13/30\n","455/455 [==============================] - 0s 172us/step - loss: 1.0004 - binary_accuracy: 0.5978\n","Epoch 14/30\n","455/455 [==============================] - 0s 184us/step - loss: 1.0000 - binary_accuracy: 0.5978\n","Epoch 15/30\n","455/455 [==============================] - 0s 153us/step - loss: 1.0000 - binary_accuracy: 0.5978\n","Epoch 16/30\n","455/455 [==============================] - 0s 152us/step - loss: 0.9989 - binary_accuracy: 0.5978\n","Epoch 17/30\n","455/455 [==============================] - 0s 152us/step - loss: 1.0033 - binary_accuracy: 0.5956\n","Epoch 18/30\n","455/455 [==============================] - 0s 152us/step - loss: 0.9991 - binary_accuracy: 0.5978\n","Epoch 19/30\n","455/455 [==============================] - 0s 160us/step - loss: 1.0015 - binary_accuracy: 0.5956\n","Epoch 20/30\n","455/455 [==============================] - 0s 175us/step - loss: 1.0004 - binary_accuracy: 0.5978\n","Epoch 21/30\n","455/455 [==============================] - 0s 163us/step - loss: 1.0005 - binary_accuracy: 0.5978\n","Epoch 22/30\n","455/455 [==============================] - 0s 147us/step - loss: 1.0006 - binary_accuracy: 0.5956\n","Epoch 23/30\n","455/455 [==============================] - 0s 159us/step - loss: 0.9993 - binary_accuracy: 0.5978\n","Epoch 24/30\n","455/455 [==============================] - 0s 154us/step - loss: 1.0000 - binary_accuracy: 0.5978\n","Epoch 25/30\n","455/455 [==============================] - 0s 154us/step - loss: 1.0006 - binary_accuracy: 0.5978\n","Epoch 26/30\n","455/455 [==============================] - 0s 170us/step - loss: 1.0004 - binary_accuracy: 0.5978\n","Epoch 27/30\n","455/455 [==============================] - 0s 206us/step - loss: 1.0000 - binary_accuracy: 0.5978\n","Epoch 28/30\n","455/455 [==============================] - 0s 184us/step - loss: 1.0000 - binary_accuracy: 0.5978\n","Epoch 29/30\n","455/455 [==============================] - 0s 185us/step - loss: 1.0000 - binary_accuracy: 0.5978\n","Epoch 30/30\n","455/455 [==============================] - 0s 198us/step - loss: 1.0000 - binary_accuracy: 0.5978\n","Model: \"sequential_65\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_193 (Dense)            (None, 16)                496       \n","_________________________________________________________________\n","dropout_129 (Dropout)        (None, 16)                0         \n","_________________________________________________________________\n","dense_194 (Dense)            (None, 16)                272       \n","_________________________________________________________________\n","dropout_130 (Dropout)        (None, 16)                0         \n","_________________________________________________________________\n","dense_195 (Dense)            (None, 1)                 17        \n","=================================================================\n","Total params: 785\n","Trainable params: 785\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/30\n","456/456 [==============================] - 0s 413us/step - loss: 1.0834 - binary_accuracy: 0.5833\n","Epoch 2/30\n","456/456 [==============================] - 0s 164us/step - loss: 0.9999 - binary_accuracy: 0.5921\n","Epoch 3/30\n","456/456 [==============================] - 0s 180us/step - loss: 1.0000 - binary_accuracy: 0.5921\n","Epoch 4/30\n","456/456 [==============================] - 0s 151us/step - loss: 1.0000 - binary_accuracy: 0.5921\n","Epoch 5/30\n","456/456 [==============================] - 0s 152us/step - loss: 1.0000 - binary_accuracy: 0.5921\n","Epoch 6/30\n","456/456 [==============================] - 0s 153us/step - loss: 1.0000 - binary_accuracy: 0.5921\n","Epoch 7/30\n","456/456 [==============================] - 0s 158us/step - loss: 1.0000 - binary_accuracy: 0.5921\n","Epoch 8/30\n","456/456 [==============================] - 0s 161us/step - loss: 1.0048 - binary_accuracy: 0.5899\n","Epoch 9/30\n","456/456 [==============================] - 0s 167us/step - loss: 1.0000 - binary_accuracy: 0.5921\n","Epoch 10/30\n","456/456 [==============================] - 0s 155us/step - loss: 1.0000 - binary_accuracy: 0.5921\n","Epoch 11/30\n","456/456 [==============================] - 0s 156us/step - loss: 1.0000 - binary_accuracy: 0.5921\n","Epoch 12/30\n","456/456 [==============================] - 0s 153us/step - loss: 1.0000 - binary_accuracy: 0.5921\n","Epoch 13/30\n","456/456 [==============================] - 0s 151us/step - loss: 1.0001 - binary_accuracy: 0.5921\n","Epoch 14/30\n","456/456 [==============================] - 0s 154us/step - loss: 1.0003 - binary_accuracy: 0.5921\n","Epoch 15/30\n","456/456 [==============================] - 0s 163us/step - loss: 1.0000 - binary_accuracy: 0.5921\n","Epoch 16/30\n","456/456 [==============================] - 0s 173us/step - loss: 1.0000 - binary_accuracy: 0.5921\n","Epoch 17/30\n","456/456 [==============================] - 0s 156us/step - loss: 1.0000 - binary_accuracy: 0.5921\n","Epoch 18/30\n","456/456 [==============================] - 0s 172us/step - loss: 1.0000 - binary_accuracy: 0.5921\n","Epoch 19/30\n","456/456 [==============================] - 0s 157us/step - loss: 1.0000 - binary_accuracy: 0.5921\n","Epoch 20/30\n","456/456 [==============================] - 0s 158us/step - loss: 1.0000 - binary_accuracy: 0.5921\n","Epoch 21/30\n","456/456 [==============================] - 0s 159us/step - loss: 1.0000 - binary_accuracy: 0.5921\n","Epoch 22/30\n","456/456 [==============================] - 0s 177us/step - loss: 1.0000 - binary_accuracy: 0.5921\n","Epoch 23/30\n","456/456 [==============================] - 0s 191us/step - loss: 1.0000 - binary_accuracy: 0.5921\n","Epoch 24/30\n","456/456 [==============================] - 0s 190us/step - loss: 0.9989 - binary_accuracy: 0.5921\n","Epoch 25/30\n","456/456 [==============================] - 0s 196us/step - loss: 1.0000 - binary_accuracy: 0.5921\n","Epoch 26/30\n","456/456 [==============================] - 0s 186us/step - loss: 1.0000 - binary_accuracy: 0.5921\n","Epoch 27/30\n","456/456 [==============================] - 0s 191us/step - loss: 1.0000 - binary_accuracy: 0.5921\n","Epoch 28/30\n","456/456 [==============================] - 0s 198us/step - loss: 1.0000 - binary_accuracy: 0.5921\n","Epoch 29/30\n","456/456 [==============================] - 0s 209us/step - loss: 1.0000 - binary_accuracy: 0.5921\n","Epoch 30/30\n","456/456 [==============================] - 0s 198us/step - loss: 0.9993 - binary_accuracy: 0.5921\n","Model: \"sequential_66\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_196 (Dense)            (None, 16)                496       \n","_________________________________________________________________\n","dropout_131 (Dropout)        (None, 16)                0         \n","_________________________________________________________________\n","dense_197 (Dense)            (None, 16)                272       \n","_________________________________________________________________\n","dropout_132 (Dropout)        (None, 16)                0         \n","_________________________________________________________________\n","dense_198 (Dense)            (None, 1)                 17        \n","=================================================================\n","Total params: 785\n","Trainable params: 785\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/30\n","455/455 [==============================] - 0s 489us/step - loss: 7.0431 - binary_accuracy: 0.3626\n","Epoch 2/30\n","455/455 [==============================] - 0s 217us/step - loss: 1.4914 - binary_accuracy: 0.6044\n","Epoch 3/30\n","455/455 [==============================] - 0s 181us/step - loss: 1.1129 - binary_accuracy: 0.6659\n","Epoch 4/30\n","455/455 [==============================] - 0s 188us/step - loss: 1.0025 - binary_accuracy: 0.6857\n","Epoch 5/30\n","455/455 [==============================] - 0s 191us/step - loss: 1.0046 - binary_accuracy: 0.6813\n","Epoch 6/30\n","455/455 [==============================] - 0s 188us/step - loss: 1.0338 - binary_accuracy: 0.6791\n","Epoch 7/30\n","455/455 [==============================] - 0s 239us/step - loss: 0.9934 - binary_accuracy: 0.6901\n","Epoch 8/30\n","455/455 [==============================] - 0s 232us/step - loss: 1.0008 - binary_accuracy: 0.6813\n","Epoch 9/30\n","455/455 [==============================] - 0s 188us/step - loss: 0.9984 - binary_accuracy: 0.6857\n","Epoch 10/30\n","455/455 [==============================] - 0s 195us/step - loss: 1.0026 - binary_accuracy: 0.6835\n","Epoch 11/30\n","455/455 [==============================] - 0s 183us/step - loss: 1.0013 - binary_accuracy: 0.6791\n","Epoch 12/30\n","455/455 [==============================] - 0s 184us/step - loss: 1.0044 - binary_accuracy: 0.6857\n","Epoch 13/30\n","455/455 [==============================] - 0s 201us/step - loss: 1.0069 - binary_accuracy: 0.6769\n","Epoch 14/30\n","455/455 [==============================] - 0s 189us/step - loss: 1.0007 - binary_accuracy: 0.6813\n","Epoch 15/30\n","455/455 [==============================] - 0s 200us/step - loss: 1.0013 - binary_accuracy: 0.6813\n","Epoch 16/30\n","455/455 [==============================] - 0s 191us/step - loss: 1.0009 - binary_accuracy: 0.6813\n","Epoch 17/30\n","455/455 [==============================] - 0s 196us/step - loss: 1.0008 - binary_accuracy: 0.6813\n","Epoch 18/30\n","455/455 [==============================] - 0s 189us/step - loss: 1.0000 - binary_accuracy: 0.6835\n","Epoch 19/30\n","455/455 [==============================] - 0s 187us/step - loss: 1.0001 - binary_accuracy: 0.6835\n","Epoch 20/30\n","455/455 [==============================] - 0s 256us/step - loss: 1.0142 - binary_accuracy: 0.6813\n","Epoch 21/30\n","455/455 [==============================] - 0s 235us/step - loss: 0.9995 - binary_accuracy: 0.6813\n","Epoch 22/30\n","455/455 [==============================] - 0s 231us/step - loss: 0.9981 - binary_accuracy: 0.6857\n","Epoch 23/30\n","455/455 [==============================] - 0s 255us/step - loss: 0.9999 - binary_accuracy: 0.6835\n","Epoch 24/30\n","455/455 [==============================] - 0s 234us/step - loss: 1.0022 - binary_accuracy: 0.6791\n","Epoch 25/30\n","455/455 [==============================] - 0s 265us/step - loss: 1.0008 - binary_accuracy: 0.6813\n","Epoch 26/30\n","455/455 [==============================] - 0s 280us/step - loss: 1.0029 - binary_accuracy: 0.6835\n","Epoch 27/30\n","455/455 [==============================] - 0s 276us/step - loss: 1.0027 - binary_accuracy: 0.6835\n","Epoch 28/30\n","455/455 [==============================] - 0s 217us/step - loss: 1.0139 - binary_accuracy: 0.6813\n","Epoch 29/30\n","455/455 [==============================] - 0s 193us/step - loss: 0.9983 - binary_accuracy: 0.6857\n","Epoch 30/30\n","455/455 [==============================] - 0s 188us/step - loss: 1.0056 - binary_accuracy: 0.6813\n","Model: \"sequential_67\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_199 (Dense)            (None, 16)                496       \n","_________________________________________________________________\n","dropout_133 (Dropout)        (None, 16)                0         \n","_________________________________________________________________\n","dense_200 (Dense)            (None, 16)                272       \n","_________________________________________________________________\n","dropout_134 (Dropout)        (None, 16)                0         \n","_________________________________________________________________\n","dense_201 (Dense)            (None, 1)                 17        \n","=================================================================\n","Total params: 785\n","Trainable params: 785\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/30\n","455/455 [==============================] - 0s 461us/step - loss: 2.4772 - binary_accuracy: 0.5429\n","Epoch 2/30\n","455/455 [==============================] - 0s 202us/step - loss: 1.0615 - binary_accuracy: 0.6396\n","Epoch 3/30\n","455/455 [==============================] - 0s 181us/step - loss: 0.9952 - binary_accuracy: 0.6396\n","Epoch 4/30\n","455/455 [==============================] - 0s 181us/step - loss: 1.0166 - binary_accuracy: 0.6396\n","Epoch 5/30\n","455/455 [==============================] - 0s 183us/step - loss: 0.9954 - binary_accuracy: 0.6418\n","Epoch 6/30\n","455/455 [==============================] - 0s 177us/step - loss: 0.9997 - binary_accuracy: 0.6352\n","Epoch 7/30\n","455/455 [==============================] - 0s 198us/step - loss: 1.0331 - binary_accuracy: 0.6352\n","Epoch 8/30\n","455/455 [==============================] - 0s 186us/step - loss: 1.0098 - binary_accuracy: 0.6352\n","Epoch 9/30\n","455/455 [==============================] - 0s 187us/step - loss: 0.9944 - binary_accuracy: 0.6418\n","Epoch 10/30\n","455/455 [==============================] - 0s 187us/step - loss: 0.9994 - binary_accuracy: 0.6396\n","Epoch 11/30\n","455/455 [==============================] - 0s 218us/step - loss: 1.0316 - binary_accuracy: 0.6308\n","Epoch 12/30\n","455/455 [==============================] - 0s 265us/step - loss: 1.0007 - binary_accuracy: 0.6374\n","Epoch 13/30\n","455/455 [==============================] - 0s 184us/step - loss: 0.9941 - binary_accuracy: 0.6440\n","Epoch 14/30\n","455/455 [==============================] - 0s 183us/step - loss: 0.9848 - binary_accuracy: 0.6549\n","Epoch 15/30\n","455/455 [==============================] - 0s 177us/step - loss: 0.9942 - binary_accuracy: 0.6462\n","Epoch 16/30\n","455/455 [==============================] - 0s 192us/step - loss: 0.9913 - binary_accuracy: 0.6462\n","Epoch 17/30\n","455/455 [==============================] - 0s 183us/step - loss: 0.9971 - binary_accuracy: 0.6396\n","Epoch 18/30\n","455/455 [==============================] - 0s 220us/step - loss: 0.9823 - binary_accuracy: 0.6571\n","Epoch 19/30\n","455/455 [==============================] - 0s 178us/step - loss: 0.9837 - binary_accuracy: 0.6549\n","Epoch 20/30\n","455/455 [==============================] - 0s 181us/step - loss: 0.9824 - binary_accuracy: 0.6462\n","Epoch 21/30\n","455/455 [==============================] - 0s 186us/step - loss: 1.0144 - binary_accuracy: 0.6462\n","Epoch 22/30\n","455/455 [==============================] - 0s 182us/step - loss: 0.9770 - binary_accuracy: 0.6615\n","Epoch 23/30\n","455/455 [==============================] - 0s 186us/step - loss: 0.9871 - binary_accuracy: 0.6264\n","Epoch 24/30\n","455/455 [==============================] - 0s 178us/step - loss: 0.9817 - binary_accuracy: 0.6549\n","Epoch 25/30\n","455/455 [==============================] - 0s 183us/step - loss: 0.9619 - binary_accuracy: 0.6484\n","Epoch 26/30\n","455/455 [==============================] - 0s 191us/step - loss: 0.9625 - binary_accuracy: 0.6484\n","Epoch 27/30\n","455/455 [==============================] - 0s 211us/step - loss: 0.9699 - binary_accuracy: 0.6484\n","Epoch 28/30\n","455/455 [==============================] - 0s 181us/step - loss: 0.9475 - binary_accuracy: 0.6637\n","Epoch 29/30\n","455/455 [==============================] - 0s 186us/step - loss: 0.9159 - binary_accuracy: 0.6505\n","Epoch 30/30\n","455/455 [==============================] - 0s 208us/step - loss: 0.9315 - binary_accuracy: 0.6505\n","Model: \"sequential_68\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_202 (Dense)            (None, 16)                496       \n","_________________________________________________________________\n","dropout_135 (Dropout)        (None, 16)                0         \n","_________________________________________________________________\n","dense_203 (Dense)            (None, 16)                272       \n","_________________________________________________________________\n","dropout_136 (Dropout)        (None, 16)                0         \n","_________________________________________________________________\n","dense_204 (Dense)            (None, 1)                 17        \n","=================================================================\n","Total params: 785\n","Trainable params: 785\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/30\n","455/455 [==============================] - 0s 453us/step - loss: 1.7967 - binary_accuracy: 0.5407\n","Epoch 2/30\n","455/455 [==============================] - 0s 210us/step - loss: 1.1667 - binary_accuracy: 0.6110\n","Epoch 3/30\n","455/455 [==============================] - 0s 201us/step - loss: 1.0367 - binary_accuracy: 0.6110\n","Epoch 4/30\n","455/455 [==============================] - 0s 182us/step - loss: 0.9990 - binary_accuracy: 0.6220\n","Epoch 5/30\n","455/455 [==============================] - 0s 194us/step - loss: 1.0791 - binary_accuracy: 0.6154\n","Epoch 6/30\n","455/455 [==============================] - 0s 206us/step - loss: 1.0103 - binary_accuracy: 0.6176\n","Epoch 7/30\n","455/455 [==============================] - 0s 200us/step - loss: 0.9988 - binary_accuracy: 0.6220\n","Epoch 8/30\n","455/455 [==============================] - 0s 191us/step - loss: 1.0004 - binary_accuracy: 0.6220\n","Epoch 9/30\n","455/455 [==============================] - 0s 189us/step - loss: 0.9990 - binary_accuracy: 0.6220\n","Epoch 10/30\n","455/455 [==============================] - 0s 191us/step - loss: 0.9981 - binary_accuracy: 0.6242\n","Epoch 11/30\n","455/455 [==============================] - 0s 191us/step - loss: 0.9998 - binary_accuracy: 0.6198\n","Epoch 12/30\n","455/455 [==============================] - 0s 187us/step - loss: 0.9986 - binary_accuracy: 0.6220\n","Epoch 13/30\n","455/455 [==============================] - 0s 184us/step - loss: 1.0328 - binary_accuracy: 0.6198\n","Epoch 14/30\n","455/455 [==============================] - 0s 181us/step - loss: 0.9969 - binary_accuracy: 0.6220\n","Epoch 15/30\n","455/455 [==============================] - 0s 200us/step - loss: 1.0204 - binary_accuracy: 0.6154\n","Epoch 16/30\n","455/455 [==============================] - 0s 196us/step - loss: 0.9958 - binary_accuracy: 0.6220\n","Epoch 17/30\n","455/455 [==============================] - 0s 191us/step - loss: 1.0013 - binary_accuracy: 0.6220\n","Epoch 18/30\n","455/455 [==============================] - 0s 185us/step - loss: 1.0011 - binary_accuracy: 0.6176\n","Epoch 19/30\n","455/455 [==============================] - 0s 198us/step - loss: 0.9982 - binary_accuracy: 0.6220\n","Epoch 20/30\n","455/455 [==============================] - 0s 200us/step - loss: 1.0009 - binary_accuracy: 0.6198\n","Epoch 21/30\n","455/455 [==============================] - 0s 189us/step - loss: 0.9973 - binary_accuracy: 0.6242\n","Epoch 22/30\n","455/455 [==============================] - 0s 222us/step - loss: 0.9971 - binary_accuracy: 0.6220\n","Epoch 23/30\n","455/455 [==============================] - 0s 185us/step - loss: 1.0006 - binary_accuracy: 0.6198\n","Epoch 24/30\n","455/455 [==============================] - 0s 186us/step - loss: 0.9991 - binary_accuracy: 0.6220\n","Epoch 25/30\n","455/455 [==============================] - 0s 183us/step - loss: 0.9993 - binary_accuracy: 0.6220\n","Epoch 26/30\n","455/455 [==============================] - 0s 199us/step - loss: 0.9982 - binary_accuracy: 0.6242\n","Epoch 27/30\n","455/455 [==============================] - 0s 185us/step - loss: 0.9977 - binary_accuracy: 0.6220\n","Epoch 28/30\n","455/455 [==============================] - 0s 196us/step - loss: 1.0001 - binary_accuracy: 0.6220\n","Epoch 29/30\n","455/455 [==============================] - 0s 192us/step - loss: 1.0007 - binary_accuracy: 0.6220\n","Epoch 30/30\n","455/455 [==============================] - 0s 202us/step - loss: 0.9993 - binary_accuracy: 0.6220\n","Model: \"sequential_69\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_205 (Dense)            (None, 16)                496       \n","_________________________________________________________________\n","dropout_137 (Dropout)        (None, 16)                0         \n","_________________________________________________________________\n","dense_206 (Dense)            (None, 16)                272       \n","_________________________________________________________________\n","dropout_138 (Dropout)        (None, 16)                0         \n","_________________________________________________________________\n","dense_207 (Dense)            (None, 1)                 17        \n","=================================================================\n","Total params: 785\n","Trainable params: 785\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/30\n","455/455 [==============================] - 0s 458us/step - loss: 1.7259 - binary_accuracy: 0.5912\n","Epoch 2/30\n","455/455 [==============================] - 0s 186us/step - loss: 1.0814 - binary_accuracy: 0.5824\n","Epoch 3/30\n","455/455 [==============================] - 0s 188us/step - loss: 1.0198 - binary_accuracy: 0.5956\n","Epoch 4/30\n","455/455 [==============================] - 0s 223us/step - loss: 1.0478 - binary_accuracy: 0.5912\n","Epoch 5/30\n","455/455 [==============================] - 0s 237us/step - loss: 1.0001 - binary_accuracy: 0.5956\n","Epoch 6/30\n","455/455 [==============================] - 0s 260us/step - loss: 1.0290 - binary_accuracy: 0.5978\n","Epoch 7/30\n","455/455 [==============================] - 0s 196us/step - loss: 0.9866 - binary_accuracy: 0.6044\n","Epoch 8/30\n","455/455 [==============================] - 0s 187us/step - loss: 1.0028 - binary_accuracy: 0.5934\n","Epoch 9/30\n","455/455 [==============================] - 0s 195us/step - loss: 0.9957 - binary_accuracy: 0.5934\n","Epoch 10/30\n","455/455 [==============================] - 0s 200us/step - loss: 0.9929 - binary_accuracy: 0.5978\n","Epoch 11/30\n","455/455 [==============================] - 0s 192us/step - loss: 0.9970 - binary_accuracy: 0.6000\n","Epoch 12/30\n","455/455 [==============================] - 0s 199us/step - loss: 0.9954 - binary_accuracy: 0.5956\n","Epoch 13/30\n","455/455 [==============================] - 0s 192us/step - loss: 0.9952 - binary_accuracy: 0.5956\n","Epoch 14/30\n","455/455 [==============================] - 0s 197us/step - loss: 0.9921 - binary_accuracy: 0.5934\n","Epoch 15/30\n","455/455 [==============================] - 0s 191us/step - loss: 1.0093 - binary_accuracy: 0.5912\n","Epoch 16/30\n","455/455 [==============================] - 0s 199us/step - loss: 1.0030 - binary_accuracy: 0.5934\n","Epoch 17/30\n","455/455 [==============================] - 0s 195us/step - loss: 0.9958 - binary_accuracy: 0.5956\n","Epoch 18/30\n","455/455 [==============================] - 0s 181us/step - loss: 0.9967 - binary_accuracy: 0.5934\n","Epoch 19/30\n","455/455 [==============================] - 0s 192us/step - loss: 0.9780 - binary_accuracy: 0.6088\n","Epoch 20/30\n","455/455 [==============================] - 0s 189us/step - loss: 0.9798 - binary_accuracy: 0.6066\n","Epoch 21/30\n","455/455 [==============================] - 0s 189us/step - loss: 0.9780 - binary_accuracy: 0.6066\n","Epoch 22/30\n","455/455 [==============================] - 0s 216us/step - loss: 0.9995 - binary_accuracy: 0.5956\n","Epoch 23/30\n","455/455 [==============================] - 0s 191us/step - loss: 0.9960 - binary_accuracy: 0.5978\n","Epoch 24/30\n","455/455 [==============================] - 0s 215us/step - loss: 0.9884 - binary_accuracy: 0.6088\n","Epoch 25/30\n","455/455 [==============================] - 0s 271us/step - loss: 0.9812 - binary_accuracy: 0.6132\n","Epoch 26/30\n","455/455 [==============================] - 0s 200us/step - loss: 0.9969 - binary_accuracy: 0.5934\n","Epoch 27/30\n","455/455 [==============================] - 0s 199us/step - loss: 0.9933 - binary_accuracy: 0.6000\n","Epoch 28/30\n","455/455 [==============================] - 0s 193us/step - loss: 0.9993 - binary_accuracy: 0.5978\n","Epoch 29/30\n","455/455 [==============================] - 0s 186us/step - loss: 0.9872 - binary_accuracy: 0.5978\n","Epoch 30/30\n","455/455 [==============================] - 0s 190us/step - loss: 0.9785 - binary_accuracy: 0.6044\n","Model: \"sequential_70\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_208 (Dense)            (None, 16)                496       \n","_________________________________________________________________\n","dropout_139 (Dropout)        (None, 16)                0         \n","_________________________________________________________________\n","dense_209 (Dense)            (None, 16)                272       \n","_________________________________________________________________\n","dropout_140 (Dropout)        (None, 16)                0         \n","_________________________________________________________________\n","dense_210 (Dense)            (None, 1)                 17        \n","=================================================================\n","Total params: 785\n","Trainable params: 785\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/30\n","456/456 [==============================] - 0s 437us/step - loss: 1.0966 - binary_accuracy: 0.5789\n","Epoch 2/30\n","456/456 [==============================] - 0s 187us/step - loss: 1.0003 - binary_accuracy: 0.5877\n","Epoch 3/30\n","456/456 [==============================] - 0s 187us/step - loss: 0.9927 - binary_accuracy: 0.5833\n","Epoch 4/30\n","456/456 [==============================] - 0s 183us/step - loss: 0.9699 - binary_accuracy: 0.5987\n","Epoch 5/30\n","456/456 [==============================] - 0s 212us/step - loss: 0.9281 - binary_accuracy: 0.6557\n","Epoch 6/30\n","456/456 [==============================] - 0s 214us/step - loss: 0.8977 - binary_accuracy: 0.6513\n","Epoch 7/30\n","456/456 [==============================] - 0s 193us/step - loss: 0.8616 - binary_accuracy: 0.6316\n","Epoch 8/30\n","456/456 [==============================] - 0s 210us/step - loss: 0.8560 - binary_accuracy: 0.6601\n","Epoch 9/30\n","456/456 [==============================] - 0s 191us/step - loss: 0.8609 - binary_accuracy: 0.6404\n","Epoch 10/30\n","456/456 [==============================] - 0s 227us/step - loss: 0.8488 - binary_accuracy: 0.6645\n","Epoch 11/30\n","456/456 [==============================] - 0s 195us/step - loss: 0.8381 - binary_accuracy: 0.6930\n","Epoch 12/30\n","456/456 [==============================] - 0s 195us/step - loss: 0.8299 - binary_accuracy: 0.6996\n","Epoch 13/30\n","456/456 [==============================] - 0s 188us/step - loss: 0.8422 - binary_accuracy: 0.6886\n","Epoch 14/30\n","456/456 [==============================] - 0s 187us/step - loss: 0.8353 - binary_accuracy: 0.7149\n","Epoch 15/30\n","456/456 [==============================] - 0s 189us/step - loss: 0.8270 - binary_accuracy: 0.6689\n","Epoch 16/30\n","456/456 [==============================] - 0s 192us/step - loss: 0.8103 - binary_accuracy: 0.7566\n","Epoch 17/30\n","456/456 [==============================] - 0s 212us/step - loss: 0.8079 - binary_accuracy: 0.7763\n","Epoch 18/30\n","456/456 [==============================] - 0s 187us/step - loss: 0.7846 - binary_accuracy: 0.7719\n","Epoch 19/30\n","456/456 [==============================] - 0s 184us/step - loss: 0.8027 - binary_accuracy: 0.7610\n","Epoch 20/30\n","456/456 [==============================] - 0s 191us/step - loss: 0.7932 - binary_accuracy: 0.7895\n","Epoch 21/30\n","456/456 [==============================] - 0s 232us/step - loss: 0.7722 - binary_accuracy: 0.8158\n","Epoch 22/30\n","456/456 [==============================] - 0s 241us/step - loss: 0.7836 - binary_accuracy: 0.7917\n","Epoch 23/30\n","456/456 [==============================] - 0s 222us/step - loss: 0.7581 - binary_accuracy: 0.8246\n","Epoch 24/30\n","456/456 [==============================] - 0s 188us/step - loss: 0.7932 - binary_accuracy: 0.8465\n","Epoch 25/30\n","456/456 [==============================] - 0s 189us/step - loss: 0.7545 - binary_accuracy: 0.8618\n","Epoch 26/30\n","456/456 [==============================] - 0s 185us/step - loss: 0.7471 - binary_accuracy: 0.8421\n","Epoch 27/30\n","456/456 [==============================] - 0s 181us/step - loss: 0.7483 - binary_accuracy: 0.8421\n","Epoch 28/30\n","456/456 [==============================] - 0s 197us/step - loss: 0.7380 - binary_accuracy: 0.8487\n","Epoch 29/30\n","456/456 [==============================] - 0s 191us/step - loss: 0.7944 - binary_accuracy: 0.8553\n","Epoch 30/30\n","456/456 [==============================] - 0s 218us/step - loss: 0.7328 - binary_accuracy: 0.8728\n","Model: \"sequential_71\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_211 (Dense)            (None, 20)                620       \n","_________________________________________________________________\n","dropout_141 (Dropout)        (None, 20)                0         \n","_________________________________________________________________\n","dense_212 (Dense)            (None, 20)                420       \n","_________________________________________________________________\n","dropout_142 (Dropout)        (None, 20)                0         \n","_________________________________________________________________\n","dense_213 (Dense)            (None, 1)                 21        \n","=================================================================\n","Total params: 1,061\n","Trainable params: 1,061\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/30\n","455/455 [==============================] - 0s 336us/step - loss: 1.2724 - binary_accuracy: 0.6659\n","Epoch 2/30\n","455/455 [==============================] - 0s 144us/step - loss: 1.0258 - binary_accuracy: 0.6813\n","Epoch 3/30\n","455/455 [==============================] - 0s 147us/step - loss: 1.0000 - binary_accuracy: 0.6835\n","Epoch 4/30\n","455/455 [==============================] - 0s 155us/step - loss: 1.0000 - binary_accuracy: 0.6835\n","Epoch 5/30\n","455/455 [==============================] - 0s 179us/step - loss: 1.0000 - binary_accuracy: 0.6835\n","Epoch 6/30\n","455/455 [==============================] - 0s 150us/step - loss: 1.0000 - binary_accuracy: 0.6835\n","Epoch 7/30\n","455/455 [==============================] - 0s 150us/step - loss: 1.0000 - binary_accuracy: 0.6835\n","Epoch 8/30\n","455/455 [==============================] - 0s 162us/step - loss: 1.0000 - binary_accuracy: 0.6835\n","Epoch 9/30\n","455/455 [==============================] - 0s 171us/step - loss: 1.0000 - binary_accuracy: 0.6835\n","Epoch 10/30\n","455/455 [==============================] - 0s 154us/step - loss: 1.0000 - binary_accuracy: 0.6835\n","Epoch 11/30\n","455/455 [==============================] - 0s 148us/step - loss: 1.0000 - binary_accuracy: 0.6835\n","Epoch 12/30\n","455/455 [==============================] - 0s 156us/step - loss: 1.0000 - binary_accuracy: 0.6835\n","Epoch 13/30\n","455/455 [==============================] - 0s 160us/step - loss: 1.0000 - binary_accuracy: 0.6835\n","Epoch 14/30\n","455/455 [==============================] - 0s 158us/step - loss: 1.0000 - binary_accuracy: 0.6835\n","Epoch 15/30\n","455/455 [==============================] - 0s 154us/step - loss: 1.0000 - binary_accuracy: 0.6835\n","Epoch 16/30\n","455/455 [==============================] - 0s 150us/step - loss: 1.0000 - binary_accuracy: 0.6835\n","Epoch 17/30\n","455/455 [==============================] - 0s 152us/step - loss: 1.0000 - binary_accuracy: 0.6835\n","Epoch 18/30\n","455/455 [==============================] - 0s 176us/step - loss: 1.0000 - binary_accuracy: 0.6835\n","Epoch 19/30\n","455/455 [==============================] - 0s 156us/step - loss: 1.0000 - binary_accuracy: 0.6835\n","Epoch 20/30\n","455/455 [==============================] - 0s 199us/step - loss: 1.0000 - binary_accuracy: 0.6835\n","Epoch 21/30\n","455/455 [==============================] - 0s 187us/step - loss: 1.0000 - binary_accuracy: 0.6835\n","Epoch 22/30\n","455/455 [==============================] - 0s 172us/step - loss: 1.0000 - binary_accuracy: 0.6835\n","Epoch 23/30\n","455/455 [==============================] - 0s 147us/step - loss: 1.0000 - binary_accuracy: 0.6835\n","Epoch 24/30\n","455/455 [==============================] - 0s 155us/step - loss: 1.0000 - binary_accuracy: 0.6835\n","Epoch 25/30\n","455/455 [==============================] - 0s 156us/step - loss: 1.0000 - binary_accuracy: 0.6835\n","Epoch 26/30\n","455/455 [==============================] - 0s 155us/step - loss: 1.0000 - binary_accuracy: 0.6835\n","Epoch 27/30\n","455/455 [==============================] - 0s 157us/step - loss: 1.0000 - binary_accuracy: 0.6835\n","Epoch 28/30\n","455/455 [==============================] - 0s 186us/step - loss: 1.0000 - binary_accuracy: 0.6835\n","Epoch 29/30\n","455/455 [==============================] - 0s 184us/step - loss: 1.0000 - binary_accuracy: 0.6835\n","Epoch 30/30\n","455/455 [==============================] - 0s 192us/step - loss: 1.0000 - binary_accuracy: 0.6835\n","Model: \"sequential_72\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_214 (Dense)            (None, 20)                620       \n","_________________________________________________________________\n","dropout_143 (Dropout)        (None, 20)                0         \n","_________________________________________________________________\n","dense_215 (Dense)            (None, 20)                420       \n","_________________________________________________________________\n","dropout_144 (Dropout)        (None, 20)                0         \n","_________________________________________________________________\n","dense_216 (Dense)            (None, 1)                 21        \n","=================================================================\n","Total params: 1,061\n","Trainable params: 1,061\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/30\n","455/455 [==============================] - 0s 329us/step - loss: 1.1105 - binary_accuracy: 0.6374\n","Epoch 2/30\n","455/455 [==============================] - 0s 158us/step - loss: 1.0426 - binary_accuracy: 0.6374\n","Epoch 3/30\n","455/455 [==============================] - 0s 151us/step - loss: 1.0693 - binary_accuracy: 0.6352\n","Epoch 4/30\n","455/455 [==============================] - 0s 153us/step - loss: 1.0335 - binary_accuracy: 0.6396\n","Epoch 5/30\n","455/455 [==============================] - 0s 148us/step - loss: 1.0027 - binary_accuracy: 0.6396\n","Epoch 6/30\n","455/455 [==============================] - 0s 161us/step - loss: 1.0000 - binary_accuracy: 0.6418\n","Epoch 7/30\n","455/455 [==============================] - 0s 154us/step - loss: 1.0000 - binary_accuracy: 0.6418\n","Epoch 8/30\n","455/455 [==============================] - 0s 188us/step - loss: 1.0000 - binary_accuracy: 0.6418\n","Epoch 9/30\n","455/455 [==============================] - 0s 162us/step - loss: 1.0000 - binary_accuracy: 0.6418\n","Epoch 10/30\n","455/455 [==============================] - 0s 177us/step - loss: 1.0000 - binary_accuracy: 0.6418\n","Epoch 11/30\n","455/455 [==============================] - 0s 172us/step - loss: 1.0000 - binary_accuracy: 0.6418\n","Epoch 12/30\n","455/455 [==============================] - 0s 161us/step - loss: 1.0000 - binary_accuracy: 0.6418\n","Epoch 13/30\n","455/455 [==============================] - 0s 160us/step - loss: 1.0000 - binary_accuracy: 0.6418\n","Epoch 14/30\n","455/455 [==============================] - 0s 155us/step - loss: 1.0000 - binary_accuracy: 0.6418\n","Epoch 15/30\n","455/455 [==============================] - 0s 157us/step - loss: 1.0000 - binary_accuracy: 0.6418\n","Epoch 16/30\n","455/455 [==============================] - 0s 158us/step - loss: 1.0000 - binary_accuracy: 0.6418\n","Epoch 17/30\n","455/455 [==============================] - 0s 156us/step - loss: 1.0000 - binary_accuracy: 0.6418\n","Epoch 18/30\n","455/455 [==============================] - 0s 155us/step - loss: 1.0000 - binary_accuracy: 0.6418\n","Epoch 19/30\n","455/455 [==============================] - 0s 172us/step - loss: 1.0000 - binary_accuracy: 0.6418\n","Epoch 20/30\n","455/455 [==============================] - 0s 169us/step - loss: 1.0000 - binary_accuracy: 0.6418\n","Epoch 21/30\n","455/455 [==============================] - 0s 199us/step - loss: 1.0000 - binary_accuracy: 0.6418\n","Epoch 22/30\n","455/455 [==============================] - 0s 162us/step - loss: 1.0000 - binary_accuracy: 0.6418\n","Epoch 23/30\n","455/455 [==============================] - 0s 158us/step - loss: 1.0000 - binary_accuracy: 0.6418\n","Epoch 24/30\n","455/455 [==============================] - 0s 166us/step - loss: 1.0000 - binary_accuracy: 0.6418\n","Epoch 25/30\n","455/455 [==============================] - 0s 182us/step - loss: 1.0000 - binary_accuracy: 0.6418\n","Epoch 26/30\n","455/455 [==============================] - 0s 150us/step - loss: 1.0000 - binary_accuracy: 0.6418\n","Epoch 27/30\n","455/455 [==============================] - 0s 149us/step - loss: 0.9978 - binary_accuracy: 0.6440\n","Epoch 28/30\n","455/455 [==============================] - 0s 157us/step - loss: 1.0000 - binary_accuracy: 0.6418\n","Epoch 29/30\n","455/455 [==============================] - 0s 150us/step - loss: 1.0000 - binary_accuracy: 0.6418\n","Epoch 30/30\n","455/455 [==============================] - 0s 150us/step - loss: 1.0000 - binary_accuracy: 0.6418\n","Model: \"sequential_73\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_217 (Dense)            (None, 20)                620       \n","_________________________________________________________________\n","dropout_145 (Dropout)        (None, 20)                0         \n","_________________________________________________________________\n","dense_218 (Dense)            (None, 20)                420       \n","_________________________________________________________________\n","dropout_146 (Dropout)        (None, 20)                0         \n","_________________________________________________________________\n","dense_219 (Dense)            (None, 1)                 21        \n","=================================================================\n","Total params: 1,061\n","Trainable params: 1,061\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/30\n","455/455 [==============================] - 0s 353us/step - loss: 1.2256 - binary_accuracy: 0.5890\n","Epoch 2/30\n","455/455 [==============================] - 0s 165us/step - loss: 1.0000 - binary_accuracy: 0.6220\n","Epoch 3/30\n","455/455 [==============================] - 0s 150us/step - loss: 1.0005 - binary_accuracy: 0.6220\n","Epoch 4/30\n","455/455 [==============================] - 0s 184us/step - loss: 0.9999 - binary_accuracy: 0.6220\n","Epoch 5/30\n","455/455 [==============================] - 0s 180us/step - loss: 0.9996 - binary_accuracy: 0.6220\n","Epoch 6/30\n","455/455 [==============================] - 0s 177us/step - loss: 0.9989 - binary_accuracy: 0.6220\n","Epoch 7/30\n","455/455 [==============================] - 0s 192us/step - loss: 1.0005 - binary_accuracy: 0.6198\n","Epoch 8/30\n","455/455 [==============================] - 0s 189us/step - loss: 1.0000 - binary_accuracy: 0.6220\n","Epoch 9/30\n","455/455 [==============================] - 0s 188us/step - loss: 1.0000 - binary_accuracy: 0.6220\n","Epoch 10/30\n","455/455 [==============================] - 0s 191us/step - loss: 0.9997 - binary_accuracy: 0.6220\n","Epoch 11/30\n","455/455 [==============================] - 0s 172us/step - loss: 1.0002 - binary_accuracy: 0.6220\n","Epoch 12/30\n","455/455 [==============================] - 0s 153us/step - loss: 1.0000 - binary_accuracy: 0.6220\n","Epoch 13/30\n","455/455 [==============================] - 0s 158us/step - loss: 0.9983 - binary_accuracy: 0.6242\n","Epoch 14/30\n","455/455 [==============================] - 0s 166us/step - loss: 1.0000 - binary_accuracy: 0.6220\n","Epoch 15/30\n","455/455 [==============================] - 0s 156us/step - loss: 1.0315 - binary_accuracy: 0.6220\n","Epoch 16/30\n","455/455 [==============================] - 0s 146us/step - loss: 1.0031 - binary_accuracy: 0.6198\n","Epoch 17/30\n","455/455 [==============================] - 0s 147us/step - loss: 1.0000 - binary_accuracy: 0.6220\n","Epoch 18/30\n","455/455 [==============================] - 0s 165us/step - loss: 1.0004 - binary_accuracy: 0.6220\n","Epoch 19/30\n","455/455 [==============================] - 0s 162us/step - loss: 1.0000 - binary_accuracy: 0.6220\n","Epoch 20/30\n","455/455 [==============================] - 0s 148us/step - loss: 0.9989 - binary_accuracy: 0.6220\n","Epoch 21/30\n","455/455 [==============================] - 0s 148us/step - loss: 0.9994 - binary_accuracy: 0.6220\n","Epoch 22/30\n","455/455 [==============================] - 0s 152us/step - loss: 1.0000 - binary_accuracy: 0.6220\n","Epoch 23/30\n","455/455 [==============================] - 0s 166us/step - loss: 0.9993 - binary_accuracy: 0.6220\n","Epoch 24/30\n","455/455 [==============================] - 0s 213us/step - loss: 1.0001 - binary_accuracy: 0.6220\n","Epoch 25/30\n","455/455 [==============================] - 0s 186us/step - loss: 0.9989 - binary_accuracy: 0.6220\n","Epoch 26/30\n","455/455 [==============================] - 0s 159us/step - loss: 0.9993 - binary_accuracy: 0.6220\n","Epoch 27/30\n","455/455 [==============================] - 0s 163us/step - loss: 1.0000 - binary_accuracy: 0.6220\n","Epoch 28/30\n","455/455 [==============================] - 0s 149us/step - loss: 1.0332 - binary_accuracy: 0.6198\n","Epoch 29/30\n","455/455 [==============================] - 0s 156us/step - loss: 0.9989 - binary_accuracy: 0.6220\n","Epoch 30/30\n","455/455 [==============================] - 0s 148us/step - loss: 1.0004 - binary_accuracy: 0.6220\n","Model: \"sequential_74\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_220 (Dense)            (None, 20)                620       \n","_________________________________________________________________\n","dropout_147 (Dropout)        (None, 20)                0         \n","_________________________________________________________________\n","dense_221 (Dense)            (None, 20)                420       \n","_________________________________________________________________\n","dropout_148 (Dropout)        (None, 20)                0         \n","_________________________________________________________________\n","dense_222 (Dense)            (None, 1)                 21        \n","=================================================================\n","Total params: 1,061\n","Trainable params: 1,061\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/30\n","455/455 [==============================] - 0s 317us/step - loss: 1.0489 - binary_accuracy: 0.5956\n","Epoch 2/30\n","455/455 [==============================] - 0s 172us/step - loss: 1.0000 - binary_accuracy: 0.5978\n","Epoch 3/30\n","455/455 [==============================] - 0s 157us/step - loss: 1.0000 - binary_accuracy: 0.5978\n","Epoch 4/30\n","455/455 [==============================] - 0s 153us/step - loss: 1.0005 - binary_accuracy: 0.5978\n","Epoch 5/30\n","455/455 [==============================] - 0s 156us/step - loss: 1.0000 - binary_accuracy: 0.5978\n","Epoch 6/30\n","455/455 [==============================] - 0s 147us/step - loss: 1.0009 - binary_accuracy: 0.5956\n","Epoch 7/30\n","455/455 [==============================] - 0s 153us/step - loss: 1.0332 - binary_accuracy: 0.5956\n","Epoch 8/30\n","455/455 [==============================] - 0s 151us/step - loss: 1.0000 - binary_accuracy: 0.5978\n","Epoch 9/30\n","455/455 [==============================] - 0s 146us/step - loss: 1.0000 - binary_accuracy: 0.5978\n","Epoch 10/30\n","455/455 [==============================] - 0s 151us/step - loss: 1.0000 - binary_accuracy: 0.5978\n","Epoch 11/30\n","455/455 [==============================] - 0s 152us/step - loss: 1.0000 - binary_accuracy: 0.5978\n","Epoch 12/30\n","455/455 [==============================] - 0s 155us/step - loss: 1.0000 - binary_accuracy: 0.5978\n","Epoch 13/30\n","455/455 [==============================] - 0s 153us/step - loss: 1.0000 - binary_accuracy: 0.5978\n","Epoch 14/30\n","455/455 [==============================] - 0s 148us/step - loss: 1.0000 - binary_accuracy: 0.5978\n","Epoch 15/30\n","455/455 [==============================] - 0s 151us/step - loss: 1.0000 - binary_accuracy: 0.5978\n","Epoch 16/30\n","455/455 [==============================] - 0s 174us/step - loss: 1.0000 - binary_accuracy: 0.5978\n","Epoch 17/30\n","455/455 [==============================] - 0s 155us/step - loss: 1.0000 - binary_accuracy: 0.5978\n","Epoch 18/30\n","455/455 [==============================] - 0s 156us/step - loss: 1.0001 - binary_accuracy: 0.5978\n","Epoch 19/30\n","455/455 [==============================] - 0s 162us/step - loss: 1.0000 - binary_accuracy: 0.5978\n","Epoch 20/30\n","455/455 [==============================] - 0s 173us/step - loss: 1.0000 - binary_accuracy: 0.5978\n","Epoch 21/30\n","455/455 [==============================] - 0s 159us/step - loss: 1.0000 - binary_accuracy: 0.5978\n","Epoch 22/30\n","455/455 [==============================] - 0s 148us/step - loss: 1.0000 - binary_accuracy: 0.5978\n","Epoch 23/30\n","455/455 [==============================] - 0s 145us/step - loss: 1.0000 - binary_accuracy: 0.5978\n","Epoch 24/30\n","455/455 [==============================] - 0s 150us/step - loss: 1.0000 - binary_accuracy: 0.5978\n","Epoch 25/30\n","455/455 [==============================] - 0s 149us/step - loss: 1.0000 - binary_accuracy: 0.5978\n","Epoch 26/30\n","455/455 [==============================] - 0s 154us/step - loss: 1.0000 - binary_accuracy: 0.5978\n","Epoch 27/30\n","455/455 [==============================] - 0s 159us/step - loss: 1.0000 - binary_accuracy: 0.5978\n","Epoch 28/30\n","455/455 [==============================] - 0s 153us/step - loss: 1.0000 - binary_accuracy: 0.5978\n","Epoch 29/30\n","455/455 [==============================] - 0s 152us/step - loss: 1.0000 - binary_accuracy: 0.5978\n","Epoch 30/30\n","455/455 [==============================] - 0s 161us/step - loss: 1.0000 - binary_accuracy: 0.5978\n","Model: \"sequential_75\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_223 (Dense)            (None, 20)                620       \n","_________________________________________________________________\n","dropout_149 (Dropout)        (None, 20)                0         \n","_________________________________________________________________\n","dense_224 (Dense)            (None, 20)                420       \n","_________________________________________________________________\n","dropout_150 (Dropout)        (None, 20)                0         \n","_________________________________________________________________\n","dense_225 (Dense)            (None, 1)                 21        \n","=================================================================\n","Total params: 1,061\n","Trainable params: 1,061\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/30\n","456/456 [==============================] - 0s 382us/step - loss: 1.0849 - binary_accuracy: 0.5877\n","Epoch 2/30\n","456/456 [==============================] - 0s 186us/step - loss: 1.0040 - binary_accuracy: 0.5855\n","Epoch 3/30\n","456/456 [==============================] - 0s 198us/step - loss: 0.9986 - binary_accuracy: 0.5943\n","Epoch 4/30\n","456/456 [==============================] - 0s 187us/step - loss: 1.0003 - binary_accuracy: 0.5921\n","Epoch 5/30\n","456/456 [==============================] - 0s 203us/step - loss: 1.0010 - binary_accuracy: 0.5921\n","Epoch 6/30\n","456/456 [==============================] - 0s 173us/step - loss: 1.0032 - binary_accuracy: 0.5899\n","Epoch 7/30\n","456/456 [==============================] - 0s 154us/step - loss: 1.0007 - binary_accuracy: 0.5899\n","Epoch 8/30\n","456/456 [==============================] - 0s 175us/step - loss: 1.0005 - binary_accuracy: 0.5921\n","Epoch 9/30\n","456/456 [==============================] - 0s 150us/step - loss: 1.0008 - binary_accuracy: 0.5921\n","Epoch 10/30\n","456/456 [==============================] - 0s 152us/step - loss: 1.0016 - binary_accuracy: 0.5921\n","Epoch 11/30\n","456/456 [==============================] - 0s 145us/step - loss: 1.0009 - binary_accuracy: 0.5921\n","Epoch 12/30\n","456/456 [==============================] - 0s 146us/step - loss: 1.0008 - binary_accuracy: 0.5921\n","Epoch 13/30\n","456/456 [==============================] - 0s 149us/step - loss: 1.0263 - binary_accuracy: 0.5877\n","Epoch 14/30\n","456/456 [==============================] - 0s 151us/step - loss: 1.0004 - binary_accuracy: 0.5921\n","Epoch 15/30\n","456/456 [==============================] - 0s 149us/step - loss: 1.0000 - binary_accuracy: 0.5921\n","Epoch 16/30\n","456/456 [==============================] - 0s 147us/step - loss: 0.9994 - binary_accuracy: 0.5921\n","Epoch 17/30\n","456/456 [==============================] - 0s 146us/step - loss: 1.0000 - binary_accuracy: 0.5921\n","Epoch 18/30\n","456/456 [==============================] - 0s 146us/step - loss: 1.0000 - binary_accuracy: 0.5921\n","Epoch 19/30\n","456/456 [==============================] - 0s 179us/step - loss: 1.0000 - binary_accuracy: 0.5921\n","Epoch 20/30\n","456/456 [==============================] - 0s 164us/step - loss: 1.0000 - binary_accuracy: 0.5921\n","Epoch 21/30\n","456/456 [==============================] - 0s 156us/step - loss: 1.0000 - binary_accuracy: 0.5921\n","Epoch 22/30\n","456/456 [==============================] - 0s 163us/step - loss: 1.0000 - binary_accuracy: 0.5921\n","Epoch 23/30\n","456/456 [==============================] - 0s 151us/step - loss: 1.0000 - binary_accuracy: 0.5921\n","Epoch 24/30\n","456/456 [==============================] - 0s 143us/step - loss: 1.0000 - binary_accuracy: 0.5921\n","Epoch 25/30\n","456/456 [==============================] - 0s 150us/step - loss: 1.0000 - binary_accuracy: 0.5921\n","Epoch 26/30\n","456/456 [==============================] - 0s 156us/step - loss: 1.0000 - binary_accuracy: 0.5921\n","Epoch 27/30\n","456/456 [==============================] - 0s 142us/step - loss: 1.0000 - binary_accuracy: 0.5921\n","Epoch 28/30\n","456/456 [==============================] - 0s 146us/step - loss: 1.0000 - binary_accuracy: 0.5921\n","Epoch 29/30\n","456/456 [==============================] - 0s 157us/step - loss: 1.0000 - binary_accuracy: 0.5921\n","Epoch 30/30\n","456/456 [==============================] - 0s 160us/step - loss: 1.0004 - binary_accuracy: 0.5921\n","Model: \"sequential_76\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_226 (Dense)            (None, 20)                620       \n","_________________________________________________________________\n","dropout_151 (Dropout)        (None, 20)                0         \n","_________________________________________________________________\n","dense_227 (Dense)            (None, 20)                420       \n","_________________________________________________________________\n","dropout_152 (Dropout)        (None, 20)                0         \n","_________________________________________________________________\n","dense_228 (Dense)            (None, 1)                 21        \n","=================================================================\n","Total params: 1,061\n","Trainable params: 1,061\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/30\n","455/455 [==============================] - 0s 404us/step - loss: 1.8249 - binary_accuracy: 0.6154\n","Epoch 2/30\n","455/455 [==============================] - 0s 183us/step - loss: 1.0000 - binary_accuracy: 0.6835\n","Epoch 3/30\n","455/455 [==============================] - 0s 191us/step - loss: 1.0211 - binary_accuracy: 0.6791\n","Epoch 4/30\n","455/455 [==============================] - 0s 178us/step - loss: 1.0154 - binary_accuracy: 0.6813\n","Epoch 5/30\n","455/455 [==============================] - 0s 180us/step - loss: 1.0044 - binary_accuracy: 0.6813\n","Epoch 6/30\n","455/455 [==============================] - 0s 172us/step - loss: 1.0002 - binary_accuracy: 0.6835\n","Epoch 7/30\n","455/455 [==============================] - 0s 203us/step - loss: 1.0000 - binary_accuracy: 0.6835\n","Epoch 8/30\n","455/455 [==============================] - 0s 172us/step - loss: 1.0001 - binary_accuracy: 0.6835\n","Epoch 9/30\n","455/455 [==============================] - 0s 214us/step - loss: 1.0001 - binary_accuracy: 0.6835\n","Epoch 10/30\n","455/455 [==============================] - 0s 205us/step - loss: 1.0000 - binary_accuracy: 0.6835\n","Epoch 11/30\n","455/455 [==============================] - 0s 181us/step - loss: 1.0000 - binary_accuracy: 0.6835\n","Epoch 12/30\n","455/455 [==============================] - 0s 246us/step - loss: 1.0335 - binary_accuracy: 0.6813\n","Epoch 13/30\n","455/455 [==============================] - 0s 252us/step - loss: 1.0000 - binary_accuracy: 0.6835\n","Epoch 14/30\n","455/455 [==============================] - 0s 235us/step - loss: 0.9999 - binary_accuracy: 0.6835\n","Epoch 15/30\n","455/455 [==============================] - 0s 231us/step - loss: 0.9987 - binary_accuracy: 0.6857\n","Epoch 16/30\n","455/455 [==============================] - 0s 242us/step - loss: 1.0023 - binary_accuracy: 0.6813\n","Epoch 17/30\n","455/455 [==============================] - 0s 221us/step - loss: 1.0000 - binary_accuracy: 0.6835\n","Epoch 18/30\n","455/455 [==============================] - 0s 182us/step - loss: 1.0326 - binary_accuracy: 0.6813\n","Epoch 19/30\n","455/455 [==============================] - 0s 190us/step - loss: 1.0000 - binary_accuracy: 0.6835\n","Epoch 20/30\n","455/455 [==============================] - 0s 189us/step - loss: 1.0000 - binary_accuracy: 0.6835\n","Epoch 21/30\n","455/455 [==============================] - 0s 184us/step - loss: 1.0000 - binary_accuracy: 0.6835\n","Epoch 22/30\n","455/455 [==============================] - 0s 180us/step - loss: 1.0000 - binary_accuracy: 0.6835\n","Epoch 23/30\n","455/455 [==============================] - 0s 179us/step - loss: 1.0000 - binary_accuracy: 0.6835\n","Epoch 24/30\n","455/455 [==============================] - 0s 182us/step - loss: 1.0000 - binary_accuracy: 0.6835\n","Epoch 25/30\n","455/455 [==============================] - 0s 193us/step - loss: 1.0000 - binary_accuracy: 0.6835\n","Epoch 26/30\n","455/455 [==============================] - 0s 184us/step - loss: 1.0000 - binary_accuracy: 0.6835\n","Epoch 27/30\n","455/455 [==============================] - 0s 191us/step - loss: 1.0000 - binary_accuracy: 0.6835\n","Epoch 28/30\n","455/455 [==============================] - 0s 190us/step - loss: 1.0000 - binary_accuracy: 0.6835\n","Epoch 29/30\n","455/455 [==============================] - 0s 199us/step - loss: 1.0332 - binary_accuracy: 0.6813\n","Epoch 30/30\n","455/455 [==============================] - 0s 175us/step - loss: 1.0000 - binary_accuracy: 0.6835\n","Model: \"sequential_77\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_229 (Dense)            (None, 20)                620       \n","_________________________________________________________________\n","dropout_153 (Dropout)        (None, 20)                0         \n","_________________________________________________________________\n","dense_230 (Dense)            (None, 20)                420       \n","_________________________________________________________________\n","dropout_154 (Dropout)        (None, 20)                0         \n","_________________________________________________________________\n","dense_231 (Dense)            (None, 1)                 21        \n","=================================================================\n","Total params: 1,061\n","Trainable params: 1,061\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/30\n","455/455 [==============================] - 0s 463us/step - loss: 2.7262 - binary_accuracy: 0.5385\n","Epoch 2/30\n","455/455 [==============================] - 0s 228us/step - loss: 1.2420 - binary_accuracy: 0.6264\n","Epoch 3/30\n","455/455 [==============================] - 0s 186us/step - loss: 1.0471 - binary_accuracy: 0.6374\n","Epoch 4/30\n","455/455 [==============================] - 0s 187us/step - loss: 1.0136 - binary_accuracy: 0.6396\n","Epoch 5/30\n","455/455 [==============================] - 0s 198us/step - loss: 1.0531 - binary_accuracy: 0.6374\n","Epoch 6/30\n","455/455 [==============================] - 0s 181us/step - loss: 1.0001 - binary_accuracy: 0.6418\n","Epoch 7/30\n","455/455 [==============================] - 0s 227us/step - loss: 1.0024 - binary_accuracy: 0.6396\n","Epoch 8/30\n","455/455 [==============================] - 0s 238us/step - loss: 1.0294 - binary_accuracy: 0.6396\n","Epoch 9/30\n","455/455 [==============================] - 0s 261us/step - loss: 1.0000 - binary_accuracy: 0.6418\n","Epoch 10/30\n","455/455 [==============================] - 0s 233us/step - loss: 0.9999 - binary_accuracy: 0.6418\n","Epoch 11/30\n","455/455 [==============================] - 0s 186us/step - loss: 1.0144 - binary_accuracy: 0.6396\n","Epoch 12/30\n","455/455 [==============================] - 0s 188us/step - loss: 1.0002 - binary_accuracy: 0.6418\n","Epoch 13/30\n","455/455 [==============================] - 0s 197us/step - loss: 1.0000 - binary_accuracy: 0.6418\n","Epoch 14/30\n","455/455 [==============================] - 0s 194us/step - loss: 1.0000 - binary_accuracy: 0.6418\n","Epoch 15/30\n","455/455 [==============================] - 0s 192us/step - loss: 1.0328 - binary_accuracy: 0.6396\n","Epoch 16/30\n","455/455 [==============================] - 0s 180us/step - loss: 1.0000 - binary_accuracy: 0.6418\n","Epoch 17/30\n","455/455 [==============================] - 0s 181us/step - loss: 1.0091 - binary_accuracy: 0.6396\n","Epoch 18/30\n","455/455 [==============================] - 0s 187us/step - loss: 1.0000 - binary_accuracy: 0.6418\n","Epoch 19/30\n","455/455 [==============================] - 0s 182us/step - loss: 1.0000 - binary_accuracy: 0.6418\n","Epoch 20/30\n","455/455 [==============================] - 0s 188us/step - loss: 1.0000 - binary_accuracy: 0.6418\n","Epoch 21/30\n","455/455 [==============================] - 0s 186us/step - loss: 1.0000 - binary_accuracy: 0.6418\n","Epoch 22/30\n","455/455 [==============================] - 0s 202us/step - loss: 0.9981 - binary_accuracy: 0.6440\n","Epoch 23/30\n","455/455 [==============================] - 0s 197us/step - loss: 0.9977 - binary_accuracy: 0.6440\n","Epoch 24/30\n","455/455 [==============================] - 0s 212us/step - loss: 1.0004 - binary_accuracy: 0.6418\n","Epoch 25/30\n","455/455 [==============================] - 0s 185us/step - loss: 1.0000 - binary_accuracy: 0.6418\n","Epoch 26/30\n","455/455 [==============================] - 0s 194us/step - loss: 1.0000 - binary_accuracy: 0.6418\n","Epoch 27/30\n","455/455 [==============================] - 0s 188us/step - loss: 1.0000 - binary_accuracy: 0.6418\n","Epoch 28/30\n","455/455 [==============================] - 0s 184us/step - loss: 1.0022 - binary_accuracy: 0.6396\n","Epoch 29/30\n","455/455 [==============================] - 0s 181us/step - loss: 1.0000 - binary_accuracy: 0.6418\n","Epoch 30/30\n","455/455 [==============================] - 0s 208us/step - loss: 0.9996 - binary_accuracy: 0.6418\n","Model: \"sequential_78\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_232 (Dense)            (None, 20)                620       \n","_________________________________________________________________\n","dropout_155 (Dropout)        (None, 20)                0         \n","_________________________________________________________________\n","dense_233 (Dense)            (None, 20)                420       \n","_________________________________________________________________\n","dropout_156 (Dropout)        (None, 20)                0         \n","_________________________________________________________________\n","dense_234 (Dense)            (None, 1)                 21        \n","=================================================================\n","Total params: 1,061\n","Trainable params: 1,061\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/30\n","455/455 [==============================] - 0s 419us/step - loss: 1.7486 - binary_accuracy: 0.6066\n","Epoch 2/30\n","455/455 [==============================] - 0s 180us/step - loss: 1.0000 - binary_accuracy: 0.6220\n","Epoch 3/30\n","455/455 [==============================] - 0s 187us/step - loss: 1.0002 - binary_accuracy: 0.6220\n","Epoch 4/30\n","455/455 [==============================] - 0s 180us/step - loss: 1.0000 - binary_accuracy: 0.6220\n","Epoch 5/30\n","455/455 [==============================] - 0s 187us/step - loss: 0.9980 - binary_accuracy: 0.6242\n","Epoch 6/30\n","455/455 [==============================] - 0s 180us/step - loss: 1.0000 - binary_accuracy: 0.6220\n","Epoch 7/30\n","455/455 [==============================] - 0s 218us/step - loss: 1.0000 - binary_accuracy: 0.6220\n","Epoch 8/30\n","455/455 [==============================] - 0s 233us/step - loss: 1.0000 - binary_accuracy: 0.6220\n","Epoch 9/30\n","455/455 [==============================] - 0s 184us/step - loss: 1.0000 - binary_accuracy: 0.6220\n","Epoch 10/30\n","455/455 [==============================] - 0s 204us/step - loss: 1.0000 - binary_accuracy: 0.6220\n","Epoch 11/30\n","455/455 [==============================] - 0s 178us/step - loss: 1.0000 - binary_accuracy: 0.6220\n","Epoch 12/30\n","455/455 [==============================] - 0s 192us/step - loss: 1.0257 - binary_accuracy: 0.6198\n","Epoch 13/30\n","455/455 [==============================] - 0s 223us/step - loss: 1.0000 - binary_accuracy: 0.6220\n","Epoch 14/30\n","455/455 [==============================] - 0s 245us/step - loss: 0.9981 - binary_accuracy: 0.6242\n","Epoch 15/30\n","455/455 [==============================] - 0s 248us/step - loss: 1.0000 - binary_accuracy: 0.6220\n","Epoch 16/30\n","455/455 [==============================] - 0s 239us/step - loss: 1.0000 - binary_accuracy: 0.6220\n","Epoch 17/30\n","455/455 [==============================] - 0s 192us/step - loss: 1.0000 - binary_accuracy: 0.6220\n","Epoch 18/30\n","455/455 [==============================] - 0s 188us/step - loss: 1.0000 - binary_accuracy: 0.6220\n","Epoch 19/30\n","455/455 [==============================] - 0s 202us/step - loss: 1.0000 - binary_accuracy: 0.6220\n","Epoch 20/30\n","455/455 [==============================] - 0s 206us/step - loss: 1.0000 - binary_accuracy: 0.6220\n","Epoch 21/30\n","455/455 [==============================] - 0s 193us/step - loss: 1.0000 - binary_accuracy: 0.6220\n","Epoch 22/30\n","455/455 [==============================] - 0s 268us/step - loss: 1.0000 - binary_accuracy: 0.6220\n","Epoch 23/30\n","455/455 [==============================] - 0s 234us/step - loss: 1.0000 - binary_accuracy: 0.6220\n","Epoch 24/30\n","455/455 [==============================] - 0s 237us/step - loss: 0.9978 - binary_accuracy: 0.6242\n","Epoch 25/30\n","455/455 [==============================] - 0s 254us/step - loss: 1.0000 - binary_accuracy: 0.6220\n","Epoch 26/30\n","455/455 [==============================] - 0s 243us/step - loss: 1.0000 - binary_accuracy: 0.6220\n","Epoch 27/30\n","455/455 [==============================] - 0s 231us/step - loss: 1.0000 - binary_accuracy: 0.6220\n","Epoch 28/30\n","455/455 [==============================] - 0s 227us/step - loss: 1.0000 - binary_accuracy: 0.6220\n","Epoch 29/30\n","455/455 [==============================] - 0s 197us/step - loss: 1.0000 - binary_accuracy: 0.6220\n","Epoch 30/30\n","455/455 [==============================] - 0s 228us/step - loss: 1.0004 - binary_accuracy: 0.6220\n","Model: \"sequential_79\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_235 (Dense)            (None, 20)                620       \n","_________________________________________________________________\n","dropout_157 (Dropout)        (None, 20)                0         \n","_________________________________________________________________\n","dense_236 (Dense)            (None, 20)                420       \n","_________________________________________________________________\n","dropout_158 (Dropout)        (None, 20)                0         \n","_________________________________________________________________\n","dense_237 (Dense)            (None, 1)                 21        \n","=================================================================\n","Total params: 1,061\n","Trainable params: 1,061\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/30\n","455/455 [==============================] - 0s 424us/step - loss: 1.2010 - binary_accuracy: 0.5780\n","Epoch 2/30\n","455/455 [==============================] - 0s 228us/step - loss: 0.9990 - binary_accuracy: 0.5978\n","Epoch 3/30\n","455/455 [==============================] - 0s 278us/step - loss: 1.0007 - binary_accuracy: 0.5956\n","Epoch 4/30\n","455/455 [==============================] - 0s 201us/step - loss: 0.9934 - binary_accuracy: 0.6044\n","Epoch 5/30\n","455/455 [==============================] - 0s 195us/step - loss: 0.9956 - binary_accuracy: 0.6022\n","Epoch 6/30\n","455/455 [==============================] - 0s 186us/step - loss: 0.9979 - binary_accuracy: 0.6000\n","Epoch 7/30\n","455/455 [==============================] - 0s 216us/step - loss: 1.0343 - binary_accuracy: 0.5912\n","Epoch 8/30\n","455/455 [==============================] - 0s 259us/step - loss: 1.0000 - binary_accuracy: 0.5978\n","Epoch 9/30\n","455/455 [==============================] - 0s 192us/step - loss: 1.0003 - binary_accuracy: 0.5978\n","Epoch 10/30\n","455/455 [==============================] - 0s 237us/step - loss: 1.0011 - binary_accuracy: 0.5956\n","Epoch 11/30\n","455/455 [==============================] - 0s 220us/step - loss: 1.0002 - binary_accuracy: 0.5978\n","Epoch 12/30\n","455/455 [==============================] - 0s 200us/step - loss: 1.0000 - binary_accuracy: 0.5978\n","Epoch 13/30\n","455/455 [==============================] - 0s 231us/step - loss: 1.0000 - binary_accuracy: 0.5978\n","Epoch 14/30\n","455/455 [==============================] - 0s 203us/step - loss: 1.0000 - binary_accuracy: 0.5978\n","Epoch 15/30\n","455/455 [==============================] - 0s 197us/step - loss: 1.0000 - binary_accuracy: 0.5978\n","Epoch 16/30\n","455/455 [==============================] - 0s 184us/step - loss: 0.9996 - binary_accuracy: 0.5978\n","Epoch 17/30\n","455/455 [==============================] - 0s 183us/step - loss: 1.0001 - binary_accuracy: 0.5978\n","Epoch 18/30\n","455/455 [==============================] - 0s 187us/step - loss: 0.9999 - binary_accuracy: 0.5978\n","Epoch 19/30\n","455/455 [==============================] - 0s 239us/step - loss: 1.0038 - binary_accuracy: 0.5956\n","Epoch 20/30\n","455/455 [==============================] - 0s 197us/step - loss: 1.0000 - binary_accuracy: 0.5978\n","Epoch 21/30\n","455/455 [==============================] - 0s 184us/step - loss: 1.0000 - binary_accuracy: 0.5978\n","Epoch 22/30\n","455/455 [==============================] - 0s 183us/step - loss: 1.0003 - binary_accuracy: 0.5978\n","Epoch 23/30\n","455/455 [==============================] - 0s 183us/step - loss: 1.0000 - binary_accuracy: 0.5956\n","Epoch 24/30\n","455/455 [==============================] - 0s 197us/step - loss: 1.0000 - binary_accuracy: 0.5978\n","Epoch 25/30\n","455/455 [==============================] - 0s 191us/step - loss: 1.0000 - binary_accuracy: 0.5978\n","Epoch 26/30\n","455/455 [==============================] - 0s 180us/step - loss: 1.0000 - binary_accuracy: 0.5978\n","Epoch 27/30\n","455/455 [==============================] - 0s 183us/step - loss: 1.0000 - binary_accuracy: 0.5978\n","Epoch 28/30\n","455/455 [==============================] - 0s 185us/step - loss: 1.0000 - binary_accuracy: 0.5978\n","Epoch 29/30\n","455/455 [==============================] - 0s 206us/step - loss: 1.0000 - binary_accuracy: 0.5978\n","Epoch 30/30\n","455/455 [==============================] - 0s 221us/step - loss: 0.9995 - binary_accuracy: 0.5978\n","Model: \"sequential_80\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_238 (Dense)            (None, 20)                620       \n","_________________________________________________________________\n","dropout_159 (Dropout)        (None, 20)                0         \n","_________________________________________________________________\n","dense_239 (Dense)            (None, 20)                420       \n","_________________________________________________________________\n","dropout_160 (Dropout)        (None, 20)                0         \n","_________________________________________________________________\n","dense_240 (Dense)            (None, 1)                 21        \n","=================================================================\n","Total params: 1,061\n","Trainable params: 1,061\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/30\n","456/456 [==============================] - 0s 497us/step - loss: 1.8866 - binary_accuracy: 0.5132\n","Epoch 2/30\n","456/456 [==============================] - 0s 192us/step - loss: 1.0423 - binary_accuracy: 0.5789\n","Epoch 3/30\n","456/456 [==============================] - 0s 187us/step - loss: 1.0019 - binary_accuracy: 0.5899\n","Epoch 4/30\n","456/456 [==============================] - 0s 179us/step - loss: 1.0445 - binary_accuracy: 0.5833\n","Epoch 5/30\n","456/456 [==============================] - 0s 217us/step - loss: 1.0310 - binary_accuracy: 0.5921\n","Epoch 6/30\n","456/456 [==============================] - 0s 202us/step - loss: 1.0000 - binary_accuracy: 0.5921\n","Epoch 7/30\n","456/456 [==============================] - 0s 186us/step - loss: 1.0000 - binary_accuracy: 0.5921\n","Epoch 8/30\n","456/456 [==============================] - 0s 186us/step - loss: 1.0000 - binary_accuracy: 0.5921\n","Epoch 9/30\n","456/456 [==============================] - 0s 196us/step - loss: 1.0210 - binary_accuracy: 0.5899\n","Epoch 10/30\n","456/456 [==============================] - 0s 185us/step - loss: 1.0246 - binary_accuracy: 0.5899\n","Epoch 11/30\n","456/456 [==============================] - 0s 205us/step - loss: 1.0115 - binary_accuracy: 0.5899\n","Epoch 12/30\n","456/456 [==============================] - 0s 252us/step - loss: 1.0009 - binary_accuracy: 0.5899\n","Epoch 13/30\n","456/456 [==============================] - 0s 212us/step - loss: 1.0009 - binary_accuracy: 0.5899\n","Epoch 14/30\n","456/456 [==============================] - 0s 216us/step - loss: 1.0129 - binary_accuracy: 0.5899\n","Epoch 15/30\n","456/456 [==============================] - 0s 240us/step - loss: 0.9982 - binary_accuracy: 0.5943\n","Epoch 16/30\n","456/456 [==============================] - 0s 191us/step - loss: 1.0005 - binary_accuracy: 0.5921\n","Epoch 17/30\n","456/456 [==============================] - 0s 185us/step - loss: 0.9998 - binary_accuracy: 0.5921\n","Epoch 18/30\n","456/456 [==============================] - 0s 185us/step - loss: 1.0021 - binary_accuracy: 0.5899\n","Epoch 19/30\n","456/456 [==============================] - 0s 180us/step - loss: 1.0000 - binary_accuracy: 0.5921\n","Epoch 20/30\n","456/456 [==============================] - 0s 186us/step - loss: 1.0000 - binary_accuracy: 0.5921\n","Epoch 21/30\n","456/456 [==============================] - 0s 193us/step - loss: 1.0000 - binary_accuracy: 0.5921\n","Epoch 22/30\n","456/456 [==============================] - 0s 184us/step - loss: 0.9978 - binary_accuracy: 0.5943\n","Epoch 23/30\n","456/456 [==============================] - 0s 192us/step - loss: 1.0002 - binary_accuracy: 0.5921\n","Epoch 24/30\n","456/456 [==============================] - 0s 184us/step - loss: 1.0000 - binary_accuracy: 0.5921\n","Epoch 25/30\n","456/456 [==============================] - 0s 185us/step - loss: 1.0081 - binary_accuracy: 0.5899\n","Epoch 26/30\n","456/456 [==============================] - 0s 193us/step - loss: 1.0000 - binary_accuracy: 0.5921\n","Epoch 27/30\n","456/456 [==============================] - 0s 224us/step - loss: 1.0036 - binary_accuracy: 0.5899\n","Epoch 28/30\n","456/456 [==============================] - 0s 257us/step - loss: 1.0000 - binary_accuracy: 0.5921\n","Epoch 29/30\n","456/456 [==============================] - 0s 238us/step - loss: 1.0000 - binary_accuracy: 0.5921\n","Epoch 30/30\n","456/456 [==============================] - 0s 249us/step - loss: 1.0001 - binary_accuracy: 0.5921\n","Model: \"sequential_81\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_241 (Dense)            (None, 16)                496       \n","_________________________________________________________________\n","dropout_161 (Dropout)        (None, 16)                0         \n","_________________________________________________________________\n","dense_242 (Dense)            (None, 16)                272       \n","_________________________________________________________________\n","dropout_162 (Dropout)        (None, 16)                0         \n","_________________________________________________________________\n","dense_243 (Dense)            (None, 1)                 17        \n","=================================================================\n","Total params: 785\n","Trainable params: 785\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/50\n","455/455 [==============================] - 0s 387us/step - loss: 37.0100 - binary_accuracy: 0.6440\n","Epoch 2/50\n","455/455 [==============================] - 0s 168us/step - loss: 0.6306 - binary_accuracy: 0.6857\n","Epoch 3/50\n","455/455 [==============================] - 0s 158us/step - loss: 0.6675 - binary_accuracy: 0.6813\n","Epoch 4/50\n","455/455 [==============================] - 0s 154us/step - loss: 0.5965 - binary_accuracy: 0.6901\n","Epoch 5/50\n","455/455 [==============================] - 0s 155us/step - loss: 0.5996 - binary_accuracy: 0.6901\n","Epoch 6/50\n","455/455 [==============================] - 0s 161us/step - loss: 0.5985 - binary_accuracy: 0.6857\n","Epoch 7/50\n","455/455 [==============================] - 0s 160us/step - loss: 0.5708 - binary_accuracy: 0.6879\n","Epoch 8/50\n","455/455 [==============================] - 0s 167us/step - loss: 0.5595 - binary_accuracy: 0.6923\n","Epoch 9/50\n","455/455 [==============================] - 0s 167us/step - loss: 0.5674 - binary_accuracy: 0.6879\n","Epoch 10/50\n","455/455 [==============================] - 0s 167us/step - loss: 0.5369 - binary_accuracy: 0.6901\n","Epoch 11/50\n","455/455 [==============================] - 0s 164us/step - loss: 0.6004 - binary_accuracy: 0.6835\n","Epoch 12/50\n","455/455 [==============================] - 0s 155us/step - loss: 0.6116 - binary_accuracy: 0.6879\n","Epoch 13/50\n","455/455 [==============================] - 0s 180us/step - loss: 0.5672 - binary_accuracy: 0.6879\n","Epoch 14/50\n","455/455 [==============================] - 0s 162us/step - loss: 0.5649 - binary_accuracy: 0.6857\n","Epoch 15/50\n","455/455 [==============================] - 0s 175us/step - loss: 0.5622 - binary_accuracy: 0.6901\n","Epoch 16/50\n","455/455 [==============================] - 0s 166us/step - loss: 0.5559 - binary_accuracy: 0.6857\n","Epoch 17/50\n","455/455 [==============================] - 0s 156us/step - loss: 0.5711 - binary_accuracy: 0.6857\n","Epoch 18/50\n","455/455 [==============================] - 0s 155us/step - loss: 0.5493 - binary_accuracy: 0.6879\n","Epoch 19/50\n","455/455 [==============================] - 0s 165us/step - loss: 0.5430 - binary_accuracy: 0.6923\n","Epoch 20/50\n","455/455 [==============================] - 0s 162us/step - loss: 0.5350 - binary_accuracy: 0.6945\n","Epoch 21/50\n","455/455 [==============================] - 0s 171us/step - loss: 0.5392 - binary_accuracy: 0.6945\n","Epoch 22/50\n","455/455 [==============================] - 0s 193us/step - loss: 0.5546 - binary_accuracy: 0.6879\n","Epoch 23/50\n","455/455 [==============================] - 0s 195us/step - loss: 0.5399 - binary_accuracy: 0.6879\n","Epoch 24/50\n","455/455 [==============================] - 0s 200us/step - loss: 0.5255 - binary_accuracy: 0.6945\n","Epoch 25/50\n","455/455 [==============================] - 0s 196us/step - loss: 0.5463 - binary_accuracy: 0.6945\n","Epoch 26/50\n","455/455 [==============================] - 0s 200us/step - loss: 0.5571 - binary_accuracy: 0.6857\n","Epoch 27/50\n","455/455 [==============================] - 0s 207us/step - loss: 0.5437 - binary_accuracy: 0.6879\n","Epoch 28/50\n","455/455 [==============================] - 0s 210us/step - loss: 0.5175 - binary_accuracy: 0.6901\n","Epoch 29/50\n","455/455 [==============================] - 0s 197us/step - loss: 0.5698 - binary_accuracy: 0.6945\n","Epoch 30/50\n","455/455 [==============================] - 0s 194us/step - loss: 0.5463 - binary_accuracy: 0.6879\n","Epoch 31/50\n","455/455 [==============================] - 0s 201us/step - loss: 0.5230 - binary_accuracy: 0.6901\n","Epoch 32/50\n","455/455 [==============================] - 0s 180us/step - loss: 0.5365 - binary_accuracy: 0.6879\n","Epoch 33/50\n","455/455 [==============================] - 0s 156us/step - loss: 0.5382 - binary_accuracy: 0.6901\n","Epoch 34/50\n","455/455 [==============================] - 0s 162us/step - loss: 0.5442 - binary_accuracy: 0.6901\n","Epoch 35/50\n","455/455 [==============================] - 0s 156us/step - loss: 0.5376 - binary_accuracy: 0.6901\n","Epoch 36/50\n","455/455 [==============================] - 0s 157us/step - loss: 0.5415 - binary_accuracy: 0.6945\n","Epoch 37/50\n","455/455 [==============================] - 0s 166us/step - loss: 0.5518 - binary_accuracy: 0.6923\n","Epoch 38/50\n","455/455 [==============================] - 0s 157us/step - loss: 0.5305 - binary_accuracy: 0.6945\n","Epoch 39/50\n","455/455 [==============================] - 0s 183us/step - loss: 0.5429 - binary_accuracy: 0.6901\n","Epoch 40/50\n","455/455 [==============================] - 0s 167us/step - loss: 0.5428 - binary_accuracy: 0.6967\n","Epoch 41/50\n","455/455 [==============================] - 0s 156us/step - loss: 0.5216 - binary_accuracy: 0.6945\n","Epoch 42/50\n","455/455 [==============================] - 0s 156us/step - loss: 0.5407 - binary_accuracy: 0.6923\n","Epoch 43/50\n","455/455 [==============================] - 0s 161us/step - loss: 0.5215 - binary_accuracy: 0.6967\n","Epoch 44/50\n","455/455 [==============================] - 0s 164us/step - loss: 0.5460 - binary_accuracy: 0.6901\n","Epoch 45/50\n","455/455 [==============================] - 0s 167us/step - loss: 0.7132 - binary_accuracy: 0.6747\n","Epoch 46/50\n","455/455 [==============================] - 0s 201us/step - loss: 0.5325 - binary_accuracy: 0.6835\n","Epoch 47/50\n","455/455 [==============================] - 0s 217us/step - loss: 0.5323 - binary_accuracy: 0.6835\n","Epoch 48/50\n","455/455 [==============================] - 0s 181us/step - loss: 0.5494 - binary_accuracy: 0.6835\n","Epoch 49/50\n","455/455 [==============================] - 0s 157us/step - loss: 0.5477 - binary_accuracy: 0.6835\n","Epoch 50/50\n","455/455 [==============================] - 0s 154us/step - loss: 0.5413 - binary_accuracy: 0.6835\n","Model: \"sequential_82\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_244 (Dense)            (None, 16)                496       \n","_________________________________________________________________\n","dropout_163 (Dropout)        (None, 16)                0         \n","_________________________________________________________________\n","dense_245 (Dense)            (None, 16)                272       \n","_________________________________________________________________\n","dropout_164 (Dropout)        (None, 16)                0         \n","_________________________________________________________________\n","dense_246 (Dense)            (None, 1)                 17        \n","=================================================================\n","Total params: 785\n","Trainable params: 785\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/50\n","455/455 [==============================] - 0s 365us/step - loss: 14.2439 - binary_accuracy: 0.6176\n","Epoch 2/50\n","455/455 [==============================] - 0s 156us/step - loss: 0.6548 - binary_accuracy: 0.6418\n","Epoch 3/50\n","455/455 [==============================] - 0s 169us/step - loss: 0.6500 - binary_accuracy: 0.6418\n","Epoch 4/50\n","455/455 [==============================] - 0s 157us/step - loss: 0.6419 - binary_accuracy: 0.6418\n","Epoch 5/50\n","455/455 [==============================] - 0s 156us/step - loss: 0.6322 - binary_accuracy: 0.6418\n","Epoch 6/50\n","455/455 [==============================] - 0s 157us/step - loss: 0.6360 - binary_accuracy: 0.6418\n","Epoch 7/50\n","455/455 [==============================] - 0s 155us/step - loss: 0.6345 - binary_accuracy: 0.6418\n","Epoch 8/50\n","455/455 [==============================] - 0s 152us/step - loss: 0.6333 - binary_accuracy: 0.6418\n","Epoch 9/50\n","455/455 [==============================] - 0s 188us/step - loss: 0.6309 - binary_accuracy: 0.6418\n","Epoch 10/50\n","455/455 [==============================] - 0s 158us/step - loss: 0.6272 - binary_accuracy: 0.6418\n","Epoch 11/50\n","455/455 [==============================] - 0s 154us/step - loss: 0.6304 - binary_accuracy: 0.6418\n","Epoch 12/50\n","455/455 [==============================] - 0s 159us/step - loss: 0.6270 - binary_accuracy: 0.6418\n","Epoch 13/50\n","455/455 [==============================] - 0s 160us/step - loss: 0.6263 - binary_accuracy: 0.6418\n","Epoch 14/50\n","455/455 [==============================] - 0s 173us/step - loss: 0.6245 - binary_accuracy: 0.6418\n","Epoch 15/50\n","455/455 [==============================] - 0s 184us/step - loss: 0.6290 - binary_accuracy: 0.6418\n","Epoch 16/50\n","455/455 [==============================] - 0s 169us/step - loss: 0.6259 - binary_accuracy: 0.6418\n","Epoch 17/50\n","455/455 [==============================] - 0s 155us/step - loss: 0.6244 - binary_accuracy: 0.6418\n","Epoch 18/50\n","455/455 [==============================] - 0s 164us/step - loss: 0.6264 - binary_accuracy: 0.6418\n","Epoch 19/50\n","455/455 [==============================] - 0s 154us/step - loss: 0.6229 - binary_accuracy: 0.6418\n","Epoch 20/50\n","455/455 [==============================] - 0s 153us/step - loss: 0.6260 - binary_accuracy: 0.6418\n","Epoch 21/50\n","455/455 [==============================] - 0s 154us/step - loss: 0.6197 - binary_accuracy: 0.6418\n","Epoch 22/50\n","455/455 [==============================] - 0s 187us/step - loss: 0.6198 - binary_accuracy: 0.6418\n","Epoch 23/50\n","455/455 [==============================] - 0s 167us/step - loss: 0.6244 - binary_accuracy: 0.6418\n","Epoch 24/50\n","455/455 [==============================] - 0s 156us/step - loss: 0.6265 - binary_accuracy: 0.6418\n","Epoch 25/50\n","455/455 [==============================] - 0s 161us/step - loss: 0.6240 - binary_accuracy: 0.6418\n","Epoch 26/50\n","455/455 [==============================] - 0s 160us/step - loss: 0.6204 - binary_accuracy: 0.6418\n","Epoch 27/50\n","455/455 [==============================] - 0s 157us/step - loss: 0.6226 - binary_accuracy: 0.6418\n","Epoch 28/50\n","455/455 [==============================] - 0s 153us/step - loss: 0.6260 - binary_accuracy: 0.6418\n","Epoch 29/50\n","455/455 [==============================] - 0s 159us/step - loss: 0.6225 - binary_accuracy: 0.6418\n","Epoch 30/50\n","455/455 [==============================] - 0s 156us/step - loss: 0.6178 - binary_accuracy: 0.6418\n","Epoch 31/50\n","455/455 [==============================] - 0s 172us/step - loss: 0.6201 - binary_accuracy: 0.6418\n","Epoch 32/50\n","455/455 [==============================] - 0s 155us/step - loss: 0.6318 - binary_accuracy: 0.6396\n","Epoch 33/50\n","455/455 [==============================] - 0s 153us/step - loss: 0.6247 - binary_accuracy: 0.6418\n","Epoch 34/50\n","455/455 [==============================] - 0s 151us/step - loss: 0.6220 - binary_accuracy: 0.6418\n","Epoch 35/50\n","455/455 [==============================] - 0s 171us/step - loss: 0.6235 - binary_accuracy: 0.6418\n","Epoch 36/50\n","455/455 [==============================] - 0s 175us/step - loss: 0.6222 - binary_accuracy: 0.6418\n","Epoch 37/50\n","455/455 [==============================] - 0s 150us/step - loss: 0.6264 - binary_accuracy: 0.6418\n","Epoch 38/50\n","455/455 [==============================] - 0s 154us/step - loss: 0.6243 - binary_accuracy: 0.6418\n","Epoch 39/50\n","455/455 [==============================] - 0s 155us/step - loss: 0.6242 - binary_accuracy: 0.6418\n","Epoch 40/50\n","455/455 [==============================] - 0s 157us/step - loss: 0.6210 - binary_accuracy: 0.6418\n","Epoch 41/50\n","455/455 [==============================] - 0s 152us/step - loss: 0.6253 - binary_accuracy: 0.6418\n","Epoch 42/50\n","455/455 [==============================] - 0s 152us/step - loss: 0.6233 - binary_accuracy: 0.6418\n","Epoch 43/50\n","455/455 [==============================] - 0s 161us/step - loss: 0.6241 - binary_accuracy: 0.6418\n","Epoch 44/50\n","455/455 [==============================] - 0s 187us/step - loss: 0.6230 - binary_accuracy: 0.6418\n","Epoch 45/50\n","455/455 [==============================] - 0s 165us/step - loss: 0.6252 - binary_accuracy: 0.6418\n","Epoch 46/50\n","455/455 [==============================] - 0s 163us/step - loss: 0.6243 - binary_accuracy: 0.6418\n","Epoch 47/50\n","455/455 [==============================] - 0s 156us/step - loss: 0.6274 - binary_accuracy: 0.6418\n","Epoch 48/50\n","455/455 [==============================] - 0s 152us/step - loss: 0.6264 - binary_accuracy: 0.6418\n","Epoch 49/50\n","455/455 [==============================] - 0s 184us/step - loss: 0.6273 - binary_accuracy: 0.6418\n","Epoch 50/50\n","455/455 [==============================] - 0s 150us/step - loss: 0.6263 - binary_accuracy: 0.6418\n","Model: \"sequential_83\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_247 (Dense)            (None, 16)                496       \n","_________________________________________________________________\n","dropout_165 (Dropout)        (None, 16)                0         \n","_________________________________________________________________\n","dense_248 (Dense)            (None, 16)                272       \n","_________________________________________________________________\n","dropout_166 (Dropout)        (None, 16)                0         \n","_________________________________________________________________\n","dense_249 (Dense)            (None, 1)                 17        \n","=================================================================\n","Total params: 785\n","Trainable params: 785\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/50\n","455/455 [==============================] - 0s 365us/step - loss: 1829.1178 - binary_accuracy: 0.5956\n","Epoch 2/50\n","455/455 [==============================] - 0s 153us/step - loss: 0.6637 - binary_accuracy: 0.6220\n","Epoch 3/50\n","455/455 [==============================] - 0s 156us/step - loss: 0.6657 - binary_accuracy: 0.6220\n","Epoch 4/50\n","455/455 [==============================] - 0s 159us/step - loss: 0.6576 - binary_accuracy: 0.6220\n","Epoch 5/50\n","455/455 [==============================] - 0s 167us/step - loss: 0.6599 - binary_accuracy: 0.6220\n","Epoch 6/50\n","455/455 [==============================] - 0s 189us/step - loss: 0.6743 - binary_accuracy: 0.6198\n","Epoch 7/50\n","455/455 [==============================] - 0s 155us/step - loss: 0.6583 - binary_accuracy: 0.6220\n","Epoch 8/50\n","455/455 [==============================] - 0s 160us/step - loss: 0.6558 - binary_accuracy: 0.6220\n","Epoch 9/50\n","455/455 [==============================] - 0s 164us/step - loss: 0.6571 - binary_accuracy: 0.6220\n","Epoch 10/50\n","455/455 [==============================] - 0s 160us/step - loss: 0.6560 - binary_accuracy: 0.6220\n","Epoch 11/50\n","455/455 [==============================] - 0s 158us/step - loss: 0.6563 - binary_accuracy: 0.6220\n","Epoch 12/50\n","455/455 [==============================] - 0s 167us/step - loss: 0.6556 - binary_accuracy: 0.6220\n","Epoch 13/50\n","455/455 [==============================] - 0s 167us/step - loss: 0.6562 - binary_accuracy: 0.6220\n","Epoch 14/50\n","455/455 [==============================] - 0s 156us/step - loss: 0.6494 - binary_accuracy: 0.6220\n","Epoch 15/50\n","455/455 [==============================] - 0s 159us/step - loss: 0.6526 - binary_accuracy: 0.6220\n","Epoch 16/50\n","455/455 [==============================] - 0s 155us/step - loss: 0.6497 - binary_accuracy: 0.6220\n","Epoch 17/50\n","455/455 [==============================] - 0s 162us/step - loss: 0.6530 - binary_accuracy: 0.6220\n","Epoch 18/50\n","455/455 [==============================] - 0s 172us/step - loss: 0.6526 - binary_accuracy: 0.6220\n","Epoch 19/50\n","455/455 [==============================] - 0s 210us/step - loss: 0.6487 - binary_accuracy: 0.6220\n","Epoch 20/50\n","455/455 [==============================] - 0s 202us/step - loss: 0.6495 - binary_accuracy: 0.6220\n","Epoch 21/50\n","455/455 [==============================] - 0s 196us/step - loss: 0.6484 - binary_accuracy: 0.6220\n","Epoch 22/50\n","455/455 [==============================] - 0s 190us/step - loss: 0.6530 - binary_accuracy: 0.6220\n","Epoch 23/50\n","455/455 [==============================] - 0s 155us/step - loss: 0.6492 - binary_accuracy: 0.6220\n","Epoch 24/50\n","455/455 [==============================] - 0s 161us/step - loss: 0.6514 - binary_accuracy: 0.6220\n","Epoch 25/50\n","455/455 [==============================] - 0s 165us/step - loss: 0.6490 - binary_accuracy: 0.6220\n","Epoch 26/50\n","455/455 [==============================] - 0s 156us/step - loss: 0.6489 - binary_accuracy: 0.6220\n","Epoch 27/50\n","455/455 [==============================] - 0s 157us/step - loss: 0.6499 - binary_accuracy: 0.6220\n","Epoch 28/50\n","455/455 [==============================] - 0s 156us/step - loss: 0.6510 - binary_accuracy: 0.6220\n","Epoch 29/50\n","455/455 [==============================] - 0s 156us/step - loss: 0.6498 - binary_accuracy: 0.6220\n","Epoch 30/50\n","455/455 [==============================] - 0s 166us/step - loss: 0.6497 - binary_accuracy: 0.6220\n","Epoch 31/50\n","455/455 [==============================] - 0s 154us/step - loss: 0.6486 - binary_accuracy: 0.6220\n","Epoch 32/50\n","455/455 [==============================] - 0s 187us/step - loss: 0.6497 - binary_accuracy: 0.6220\n","Epoch 33/50\n","455/455 [==============================] - 0s 160us/step - loss: 0.6486 - binary_accuracy: 0.6220\n","Epoch 34/50\n","455/455 [==============================] - 0s 158us/step - loss: 0.6485 - binary_accuracy: 0.6220\n","Epoch 35/50\n","455/455 [==============================] - 0s 155us/step - loss: 0.6507 - binary_accuracy: 0.6220\n","Epoch 36/50\n","455/455 [==============================] - 0s 195us/step - loss: 0.6484 - binary_accuracy: 0.6220\n","Epoch 37/50\n","455/455 [==============================] - 0s 202us/step - loss: 0.6495 - binary_accuracy: 0.6220\n","Epoch 38/50\n","455/455 [==============================] - 0s 202us/step - loss: 0.6484 - binary_accuracy: 0.6220\n","Epoch 39/50\n","455/455 [==============================] - 0s 206us/step - loss: 0.6528 - binary_accuracy: 0.6220\n","Epoch 40/50\n","455/455 [==============================] - 0s 199us/step - loss: 0.6506 - binary_accuracy: 0.6220\n","Epoch 41/50\n","455/455 [==============================] - 0s 193us/step - loss: 0.6484 - binary_accuracy: 0.6220\n","Epoch 42/50\n","455/455 [==============================] - 0s 209us/step - loss: 0.6495 - binary_accuracy: 0.6220\n","Epoch 43/50\n","455/455 [==============================] - 0s 225us/step - loss: 0.6516 - binary_accuracy: 0.6220\n","Epoch 44/50\n","455/455 [==============================] - 0s 202us/step - loss: 0.6505 - binary_accuracy: 0.6220\n","Epoch 45/50\n","455/455 [==============================] - 0s 200us/step - loss: 0.6472 - binary_accuracy: 0.6220\n","Epoch 46/50\n","455/455 [==============================] - 0s 181us/step - loss: 0.6472 - binary_accuracy: 0.6220\n","Epoch 47/50\n","455/455 [==============================] - 0s 158us/step - loss: 0.6483 - binary_accuracy: 0.6220\n","Epoch 48/50\n","455/455 [==============================] - 0s 161us/step - loss: 0.6472 - binary_accuracy: 0.6220\n","Epoch 49/50\n","455/455 [==============================] - 0s 157us/step - loss: 0.6505 - binary_accuracy: 0.6220\n","Epoch 50/50\n","455/455 [==============================] - 0s 159us/step - loss: 0.6505 - binary_accuracy: 0.6220\n","Model: \"sequential_84\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_250 (Dense)            (None, 16)                496       \n","_________________________________________________________________\n","dropout_167 (Dropout)        (None, 16)                0         \n","_________________________________________________________________\n","dense_251 (Dense)            (None, 16)                272       \n","_________________________________________________________________\n","dropout_168 (Dropout)        (None, 16)                0         \n","_________________________________________________________________\n","dense_252 (Dense)            (None, 1)                 17        \n","=================================================================\n","Total params: 785\n","Trainable params: 785\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/50\n","455/455 [==============================] - 0s 403us/step - loss: 1.7200 - binary_accuracy: 0.5582\n","Epoch 2/50\n","455/455 [==============================] - 0s 166us/step - loss: 0.6212 - binary_accuracy: 0.5978\n","Epoch 3/50\n","455/455 [==============================] - 0s 196us/step - loss: 0.6224 - binary_accuracy: 0.5978\n","Epoch 4/50\n","455/455 [==============================] - 0s 199us/step - loss: 0.6169 - binary_accuracy: 0.5978\n","Epoch 5/50\n","455/455 [==============================] - 0s 153us/step - loss: 0.6182 - binary_accuracy: 0.5978\n","Epoch 6/50\n","455/455 [==============================] - 0s 154us/step - loss: 0.6163 - binary_accuracy: 0.5978\n","Epoch 7/50\n","455/455 [==============================] - 0s 163us/step - loss: 0.6175 - binary_accuracy: 0.5978\n","Epoch 8/50\n","455/455 [==============================] - 0s 162us/step - loss: 0.6159 - binary_accuracy: 0.5978\n","Epoch 9/50\n","455/455 [==============================] - 0s 169us/step - loss: 0.6156 - binary_accuracy: 0.5978\n","Epoch 10/50\n","455/455 [==============================] - 0s 187us/step - loss: 0.6168 - binary_accuracy: 0.5978\n","Epoch 11/50\n","455/455 [==============================] - 0s 164us/step - loss: 0.6153 - binary_accuracy: 0.5978\n","Epoch 12/50\n","455/455 [==============================] - 0s 195us/step - loss: 0.6158 - binary_accuracy: 0.5978\n","Epoch 13/50\n","455/455 [==============================] - 0s 178us/step - loss: 0.6149 - binary_accuracy: 0.5978\n","Epoch 14/50\n","455/455 [==============================] - 0s 163us/step - loss: 0.6177 - binary_accuracy: 0.5978\n","Epoch 15/50\n","455/455 [==============================] - 0s 159us/step - loss: 0.6175 - binary_accuracy: 0.5978\n","Epoch 16/50\n","455/455 [==============================] - 0s 159us/step - loss: 0.6148 - binary_accuracy: 0.5978\n","Epoch 17/50\n","455/455 [==============================] - 0s 191us/step - loss: 0.6148 - binary_accuracy: 0.5978\n","Epoch 18/50\n","455/455 [==============================] - 0s 188us/step - loss: 0.6169 - binary_accuracy: 0.5978\n","Epoch 19/50\n","455/455 [==============================] - 0s 158us/step - loss: 0.6157 - binary_accuracy: 0.5978\n","Epoch 20/50\n","455/455 [==============================] - 0s 159us/step - loss: 0.6148 - binary_accuracy: 0.5978\n","Epoch 21/50\n","455/455 [==============================] - 0s 156us/step - loss: 0.6145 - binary_accuracy: 0.5978\n","Epoch 22/50\n","455/455 [==============================] - 0s 158us/step - loss: 0.6160 - binary_accuracy: 0.5978\n","Epoch 23/50\n","455/455 [==============================] - 0s 157us/step - loss: 0.6165 - binary_accuracy: 0.5978\n","Epoch 24/50\n","455/455 [==============================] - 0s 168us/step - loss: 0.6144 - binary_accuracy: 0.5978\n","Epoch 25/50\n","455/455 [==============================] - 0s 194us/step - loss: 0.6144 - binary_accuracy: 0.5978\n","Epoch 26/50\n","455/455 [==============================] - 0s 162us/step - loss: 0.6158 - binary_accuracy: 0.5978\n","Epoch 27/50\n","455/455 [==============================] - 0s 166us/step - loss: 0.6158 - binary_accuracy: 0.5978\n","Epoch 28/50\n","455/455 [==============================] - 0s 194us/step - loss: 0.6159 - binary_accuracy: 0.5978\n","Epoch 29/50\n","455/455 [==============================] - 0s 192us/step - loss: 0.6142 - binary_accuracy: 0.5978\n","Epoch 30/50\n","455/455 [==============================] - 0s 157us/step - loss: 0.6142 - binary_accuracy: 0.5978\n","Epoch 31/50\n","455/455 [==============================] - 0s 158us/step - loss: 0.6155 - binary_accuracy: 0.5978\n","Epoch 32/50\n","455/455 [==============================] - 0s 156us/step - loss: 0.6143 - binary_accuracy: 0.5978\n","Epoch 33/50\n","455/455 [==============================] - 0s 183us/step - loss: 0.6142 - binary_accuracy: 0.5978\n","Epoch 34/50\n","455/455 [==============================] - 0s 155us/step - loss: 0.6154 - binary_accuracy: 0.5978\n","Epoch 35/50\n","455/455 [==============================] - 0s 153us/step - loss: 0.6143 - binary_accuracy: 0.5978\n","Epoch 36/50\n","455/455 [==============================] - 0s 170us/step - loss: 0.6143 - binary_accuracy: 0.5978\n","Epoch 37/50\n","455/455 [==============================] - 0s 154us/step - loss: 0.6143 - binary_accuracy: 0.5978\n","Epoch 38/50\n","455/455 [==============================] - 0s 181us/step - loss: 0.6142 - binary_accuracy: 0.5978\n","Epoch 39/50\n","455/455 [==============================] - 0s 161us/step - loss: 1.1088 - binary_accuracy: 0.5978\n","Epoch 40/50\n","455/455 [==============================] - 0s 159us/step - loss: 0.6546 - binary_accuracy: 0.5934\n","Epoch 41/50\n","455/455 [==============================] - 0s 156us/step - loss: 0.6157 - binary_accuracy: 0.5978\n","Epoch 42/50\n","455/455 [==============================] - 0s 165us/step - loss: 0.6157 - binary_accuracy: 0.5978\n","Epoch 43/50\n","455/455 [==============================] - 0s 167us/step - loss: 0.6171 - binary_accuracy: 0.5978\n","Epoch 44/50\n","455/455 [==============================] - 0s 152us/step - loss: 0.6208 - binary_accuracy: 0.5978\n","Epoch 45/50\n","455/455 [==============================] - 0s 153us/step - loss: 0.6171 - binary_accuracy: 0.5978\n","Epoch 46/50\n","455/455 [==============================] - 0s 158us/step - loss: 0.6170 - binary_accuracy: 0.5978\n","Epoch 47/50\n","455/455 [==============================] - 0s 154us/step - loss: 0.6179 - binary_accuracy: 0.5978\n","Epoch 48/50\n","455/455 [==============================] - 0s 156us/step - loss: 0.6154 - binary_accuracy: 0.5978\n","Epoch 49/50\n","455/455 [==============================] - 0s 160us/step - loss: 0.6168 - binary_accuracy: 0.5978\n","Epoch 50/50\n","455/455 [==============================] - 0s 163us/step - loss: 0.6197 - binary_accuracy: 0.5978\n","Model: \"sequential_85\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_253 (Dense)            (None, 16)                496       \n","_________________________________________________________________\n","dropout_169 (Dropout)        (None, 16)                0         \n","_________________________________________________________________\n","dense_254 (Dense)            (None, 16)                272       \n","_________________________________________________________________\n","dropout_170 (Dropout)        (None, 16)                0         \n","_________________________________________________________________\n","dense_255 (Dense)            (None, 1)                 17        \n","=================================================================\n","Total params: 785\n","Trainable params: 785\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/50\n","456/456 [==============================] - 0s 376us/step - loss: 13.2167 - binary_accuracy: 0.5811\n","Epoch 2/50\n","456/456 [==============================] - 0s 155us/step - loss: 0.6723 - binary_accuracy: 0.5943\n","Epoch 3/50\n","456/456 [==============================] - 0s 154us/step - loss: 0.7476 - binary_accuracy: 0.5899\n","Epoch 4/50\n","456/456 [==============================] - 0s 168us/step - loss: 0.6419 - binary_accuracy: 0.5921\n","Epoch 5/50\n","456/456 [==============================] - 0s 157us/step - loss: 0.6458 - binary_accuracy: 0.5921\n","Epoch 6/50\n","456/456 [==============================] - 0s 156us/step - loss: 0.6377 - binary_accuracy: 0.5921\n","Epoch 7/50\n","456/456 [==============================] - 0s 169us/step - loss: 0.6348 - binary_accuracy: 0.5921\n","Epoch 8/50\n","456/456 [==============================] - 0s 162us/step - loss: 0.6344 - binary_accuracy: 0.5921\n","Epoch 9/50\n","456/456 [==============================] - 0s 155us/step - loss: 0.6467 - binary_accuracy: 0.5921\n","Epoch 10/50\n","456/456 [==============================] - 0s 180us/step - loss: 0.6435 - binary_accuracy: 0.5921\n","Epoch 11/50\n","456/456 [==============================] - 0s 191us/step - loss: 0.6389 - binary_accuracy: 0.5965\n","Epoch 12/50\n","456/456 [==============================] - 0s 154us/step - loss: 0.6447 - binary_accuracy: 0.5899\n","Epoch 13/50\n","456/456 [==============================] - 0s 151us/step - loss: 0.6398 - binary_accuracy: 0.5921\n","Epoch 14/50\n","456/456 [==============================] - 0s 174us/step - loss: 0.6357 - binary_accuracy: 0.5921\n","Epoch 15/50\n","456/456 [==============================] - 0s 159us/step - loss: 0.6372 - binary_accuracy: 0.5921\n","Epoch 16/50\n","456/456 [==============================] - 0s 156us/step - loss: 0.6425 - binary_accuracy: 0.5921\n","Epoch 17/50\n","456/456 [==============================] - 0s 155us/step - loss: 0.6383 - binary_accuracy: 0.5921\n","Epoch 18/50\n","456/456 [==============================] - 0s 153us/step - loss: 0.6368 - binary_accuracy: 0.5921\n","Epoch 19/50\n","456/456 [==============================] - 0s 151us/step - loss: 0.6342 - binary_accuracy: 0.5921\n","Epoch 20/50\n","456/456 [==============================] - 0s 179us/step - loss: 0.6394 - binary_accuracy: 0.5921\n","Epoch 21/50\n","456/456 [==============================] - 0s 178us/step - loss: 0.6356 - binary_accuracy: 0.5921\n","Epoch 22/50\n","456/456 [==============================] - 0s 167us/step - loss: 0.6355 - binary_accuracy: 0.5921\n","Epoch 23/50\n","456/456 [==============================] - 0s 195us/step - loss: 0.6447 - binary_accuracy: 0.5921\n","Epoch 24/50\n","456/456 [==============================] - 0s 195us/step - loss: 0.8478 - binary_accuracy: 0.5877\n","Epoch 25/50\n","456/456 [==============================] - 0s 158us/step - loss: 0.6353 - binary_accuracy: 0.5921\n","Epoch 26/50\n","456/456 [==============================] - 0s 154us/step - loss: 0.6445 - binary_accuracy: 0.5899\n","Epoch 27/50\n","456/456 [==============================] - 0s 153us/step - loss: 0.6327 - binary_accuracy: 0.5921\n","Epoch 28/50\n","456/456 [==============================] - 0s 155us/step - loss: 0.6394 - binary_accuracy: 0.5899\n","Epoch 29/50\n","456/456 [==============================] - 0s 151us/step - loss: 0.6417 - binary_accuracy: 0.5921\n","Epoch 30/50\n","456/456 [==============================] - 0s 159us/step - loss: 0.6418 - binary_accuracy: 0.5921\n","Epoch 31/50\n","456/456 [==============================] - 0s 153us/step - loss: 0.6352 - binary_accuracy: 0.5921\n","Epoch 32/50\n","456/456 [==============================] - 0s 151us/step - loss: 0.6375 - binary_accuracy: 0.5921\n","Epoch 33/50\n","456/456 [==============================] - 0s 171us/step - loss: 0.6327 - binary_accuracy: 0.5921\n","Epoch 34/50\n","456/456 [==============================] - 0s 173us/step - loss: 0.6443 - binary_accuracy: 0.5921\n","Epoch 35/50\n","456/456 [==============================] - 0s 174us/step - loss: 0.6340 - binary_accuracy: 0.5921\n","Epoch 36/50\n","456/456 [==============================] - 0s 161us/step - loss: 0.6431 - binary_accuracy: 0.5921\n","Epoch 37/50\n","456/456 [==============================] - 0s 166us/step - loss: 0.6339 - binary_accuracy: 0.5921\n","Epoch 38/50\n","456/456 [==============================] - 0s 179us/step - loss: 0.6402 - binary_accuracy: 0.5921\n","Epoch 39/50\n","456/456 [==============================] - 0s 188us/step - loss: 0.6392 - binary_accuracy: 0.5921\n","Epoch 40/50\n","456/456 [==============================] - 0s 205us/step - loss: 0.6377 - binary_accuracy: 0.5921\n","Epoch 41/50\n","456/456 [==============================] - 0s 163us/step - loss: 0.6363 - binary_accuracy: 0.5921\n","Epoch 42/50\n","456/456 [==============================] - 0s 159us/step - loss: 0.6390 - binary_accuracy: 0.5921\n","Epoch 43/50\n","456/456 [==============================] - 0s 156us/step - loss: 0.6402 - binary_accuracy: 0.5921\n","Epoch 44/50\n","456/456 [==============================] - 0s 151us/step - loss: 0.6401 - binary_accuracy: 0.5921\n","Epoch 45/50\n","456/456 [==============================] - 0s 154us/step - loss: 0.6377 - binary_accuracy: 0.5921\n","Epoch 46/50\n","456/456 [==============================] - 0s 177us/step - loss: 0.6350 - binary_accuracy: 0.5921\n","Epoch 47/50\n","456/456 [==============================] - 0s 188us/step - loss: 0.6376 - binary_accuracy: 0.5921\n","Epoch 48/50\n","456/456 [==============================] - 0s 175us/step - loss: 0.6516 - binary_accuracy: 0.5921\n","Epoch 49/50\n","456/456 [==============================] - 0s 186us/step - loss: 0.6388 - binary_accuracy: 0.5921\n","Epoch 50/50\n","456/456 [==============================] - 0s 164us/step - loss: 0.6429 - binary_accuracy: 0.5921\n","Model: \"sequential_86\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_256 (Dense)            (None, 16)                496       \n","_________________________________________________________________\n","dropout_171 (Dropout)        (None, 16)                0         \n","_________________________________________________________________\n","dense_257 (Dense)            (None, 16)                272       \n","_________________________________________________________________\n","dropout_172 (Dropout)        (None, 16)                0         \n","_________________________________________________________________\n","dense_258 (Dense)            (None, 1)                 17        \n","=================================================================\n","Total params: 785\n","Trainable params: 785\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/50\n","455/455 [==============================] - 0s 524us/step - loss: 1.8217 - binary_accuracy: 0.6176\n","Epoch 2/50\n","455/455 [==============================] - 0s 192us/step - loss: 0.7152 - binary_accuracy: 0.6527\n","Epoch 3/50\n","455/455 [==============================] - 0s 204us/step - loss: 0.5549 - binary_accuracy: 0.6901\n","Epoch 4/50\n","455/455 [==============================] - 0s 194us/step - loss: 0.5359 - binary_accuracy: 0.7495\n","Epoch 5/50\n","455/455 [==============================] - 0s 198us/step - loss: 0.5114 - binary_accuracy: 0.7516\n","Epoch 6/50\n","455/455 [==============================] - 0s 184us/step - loss: 0.4724 - binary_accuracy: 0.7802\n","Epoch 7/50\n","455/455 [==============================] - 0s 190us/step - loss: 0.4557 - binary_accuracy: 0.8154\n","Epoch 8/50\n","455/455 [==============================] - 0s 193us/step - loss: 0.4445 - binary_accuracy: 0.7780\n","Epoch 9/50\n","455/455 [==============================] - 0s 207us/step - loss: 0.3864 - binary_accuracy: 0.7758\n","Epoch 10/50\n","455/455 [==============================] - 0s 192us/step - loss: 0.4098 - binary_accuracy: 0.8176\n","Epoch 11/50\n","455/455 [==============================] - 0s 207us/step - loss: 0.3722 - binary_accuracy: 0.8659\n","Epoch 12/50\n","455/455 [==============================] - 0s 220us/step - loss: 0.3737 - binary_accuracy: 0.8462\n","Epoch 13/50\n","455/455 [==============================] - 0s 268us/step - loss: 0.3358 - binary_accuracy: 0.8747\n","Epoch 14/50\n","455/455 [==============================] - 0s 224us/step - loss: 0.3366 - binary_accuracy: 0.8484\n","Epoch 15/50\n","455/455 [==============================] - 0s 198us/step - loss: 0.3301 - binary_accuracy: 0.8615\n","Epoch 16/50\n","455/455 [==============================] - 0s 195us/step - loss: 0.3465 - binary_accuracy: 0.8549\n","Epoch 17/50\n","455/455 [==============================] - 0s 193us/step - loss: 0.2894 - binary_accuracy: 0.8835\n","Epoch 18/50\n","455/455 [==============================] - 0s 204us/step - loss: 0.2957 - binary_accuracy: 0.8901\n","Epoch 19/50\n","455/455 [==============================] - 0s 195us/step - loss: 0.2763 - binary_accuracy: 0.8835\n","Epoch 20/50\n","455/455 [==============================] - 0s 192us/step - loss: 0.2655 - binary_accuracy: 0.9033\n","Epoch 21/50\n","455/455 [==============================] - 0s 219us/step - loss: 0.2610 - binary_accuracy: 0.8835\n","Epoch 22/50\n","455/455 [==============================] - 0s 209us/step - loss: 0.3248 - binary_accuracy: 0.8857\n","Epoch 23/50\n","455/455 [==============================] - 0s 194us/step - loss: 0.2716 - binary_accuracy: 0.8967\n","Epoch 24/50\n","455/455 [==============================] - 0s 239us/step - loss: 0.2688 - binary_accuracy: 0.9033\n","Epoch 25/50\n","455/455 [==============================] - 0s 261us/step - loss: 0.2735 - binary_accuracy: 0.8879\n","Epoch 26/50\n","455/455 [==============================] - 0s 240us/step - loss: 0.2435 - binary_accuracy: 0.9099\n","Epoch 27/50\n","455/455 [==============================] - 0s 284us/step - loss: 0.2221 - binary_accuracy: 0.9099\n","Epoch 28/50\n","455/455 [==============================] - 0s 260us/step - loss: 0.2194 - binary_accuracy: 0.9165\n","Epoch 29/50\n","455/455 [==============================] - 0s 251us/step - loss: 0.2235 - binary_accuracy: 0.9055\n","Epoch 30/50\n","455/455 [==============================] - 0s 285us/step - loss: 0.2482 - binary_accuracy: 0.8967\n","Epoch 31/50\n","455/455 [==============================] - 0s 288us/step - loss: 0.2294 - binary_accuracy: 0.9121\n","Epoch 32/50\n","455/455 [==============================] - 0s 244us/step - loss: 0.2446 - binary_accuracy: 0.9121\n","Epoch 33/50\n","455/455 [==============================] - 0s 253us/step - loss: 0.2487 - binary_accuracy: 0.9011\n","Epoch 34/50\n","455/455 [==============================] - 0s 261us/step - loss: 0.2204 - binary_accuracy: 0.9231\n","Epoch 35/50\n","455/455 [==============================] - 0s 198us/step - loss: 0.2995 - binary_accuracy: 0.9011\n","Epoch 36/50\n","455/455 [==============================] - 0s 191us/step - loss: 0.2013 - binary_accuracy: 0.9231\n","Epoch 37/50\n","455/455 [==============================] - 0s 189us/step - loss: 0.2016 - binary_accuracy: 0.9231\n","Epoch 38/50\n","455/455 [==============================] - 0s 195us/step - loss: 0.2044 - binary_accuracy: 0.9319\n","Epoch 39/50\n","455/455 [==============================] - 0s 203us/step - loss: 0.1905 - binary_accuracy: 0.9275\n","Epoch 40/50\n","455/455 [==============================] - 0s 219us/step - loss: 0.2014 - binary_accuracy: 0.9253\n","Epoch 41/50\n","455/455 [==============================] - 0s 222us/step - loss: 0.1902 - binary_accuracy: 0.9451\n","Epoch 42/50\n","455/455 [==============================] - 0s 202us/step - loss: 0.1892 - binary_accuracy: 0.9187\n","Epoch 43/50\n","455/455 [==============================] - 0s 200us/step - loss: 0.2535 - binary_accuracy: 0.9033\n","Epoch 44/50\n","455/455 [==============================] - 0s 189us/step - loss: 0.2237 - binary_accuracy: 0.9121\n","Epoch 45/50\n","455/455 [==============================] - 0s 193us/step - loss: 0.2020 - binary_accuracy: 0.9253\n","Epoch 46/50\n","455/455 [==============================] - 0s 195us/step - loss: 0.1901 - binary_accuracy: 0.9209\n","Epoch 47/50\n","455/455 [==============================] - 0s 202us/step - loss: 0.1877 - binary_accuracy: 0.9363\n","Epoch 48/50\n","455/455 [==============================] - 0s 191us/step - loss: 0.1971 - binary_accuracy: 0.9209\n","Epoch 49/50\n","455/455 [==============================] - 0s 190us/step - loss: 0.1882 - binary_accuracy: 0.9275\n","Epoch 50/50\n","455/455 [==============================] - 0s 195us/step - loss: 0.1733 - binary_accuracy: 0.9473\n","Model: \"sequential_87\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_259 (Dense)            (None, 16)                496       \n","_________________________________________________________________\n","dropout_173 (Dropout)        (None, 16)                0         \n","_________________________________________________________________\n","dense_260 (Dense)            (None, 16)                272       \n","_________________________________________________________________\n","dropout_174 (Dropout)        (None, 16)                0         \n","_________________________________________________________________\n","dense_261 (Dense)            (None, 1)                 17        \n","=================================================================\n","Total params: 785\n","Trainable params: 785\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/50\n","455/455 [==============================] - 0s 577us/step - loss: 1.3521 - binary_accuracy: 0.5692\n","Epoch 2/50\n","455/455 [==============================] - 0s 261us/step - loss: 0.6694 - binary_accuracy: 0.6154\n","Epoch 3/50\n","455/455 [==============================] - 0s 254us/step - loss: 0.5669 - binary_accuracy: 0.6637\n","Epoch 4/50\n","455/455 [==============================] - 0s 212us/step - loss: 0.5176 - binary_accuracy: 0.6857\n","Epoch 5/50\n","455/455 [==============================] - 0s 216us/step - loss: 0.5006 - binary_accuracy: 0.6923\n","Epoch 6/50\n","455/455 [==============================] - 0s 201us/step - loss: 0.5047 - binary_accuracy: 0.7253\n","Epoch 7/50\n","455/455 [==============================] - 0s 198us/step - loss: 0.4836 - binary_accuracy: 0.7385\n","Epoch 8/50\n","455/455 [==============================] - 0s 194us/step - loss: 0.5094 - binary_accuracy: 0.7209\n","Epoch 9/50\n","455/455 [==============================] - 0s 195us/step - loss: 0.4652 - binary_accuracy: 0.7429\n","Epoch 10/50\n","455/455 [==============================] - 0s 193us/step - loss: 0.4855 - binary_accuracy: 0.7143\n","Epoch 11/50\n","455/455 [==============================] - 0s 200us/step - loss: 0.4497 - binary_accuracy: 0.7670\n","Epoch 12/50\n","455/455 [==============================] - 0s 206us/step - loss: 0.4452 - binary_accuracy: 0.7824\n","Epoch 13/50\n","455/455 [==============================] - 0s 209us/step - loss: 0.4473 - binary_accuracy: 0.7846\n","Epoch 14/50\n","455/455 [==============================] - 0s 207us/step - loss: 0.4077 - binary_accuracy: 0.8066\n","Epoch 15/50\n","455/455 [==============================] - 0s 214us/step - loss: 0.3975 - binary_accuracy: 0.8374\n","Epoch 16/50\n","455/455 [==============================] - 0s 245us/step - loss: 0.3836 - binary_accuracy: 0.8242\n","Epoch 17/50\n","455/455 [==============================] - 0s 249us/step - loss: 0.3997 - binary_accuracy: 0.8484\n","Epoch 18/50\n","455/455 [==============================] - 0s 247us/step - loss: 0.3767 - binary_accuracy: 0.8440\n","Epoch 19/50\n","455/455 [==============================] - 0s 257us/step - loss: 0.3623 - binary_accuracy: 0.8352\n","Epoch 20/50\n","455/455 [==============================] - 0s 268us/step - loss: 0.3486 - binary_accuracy: 0.8637\n","Epoch 21/50\n","455/455 [==============================] - 0s 255us/step - loss: 0.3298 - binary_accuracy: 0.8813\n","Epoch 22/50\n","455/455 [==============================] - 0s 273us/step - loss: 0.3654 - binary_accuracy: 0.8418\n","Epoch 23/50\n","455/455 [==============================] - 0s 218us/step - loss: 0.3450 - binary_accuracy: 0.8637\n","Epoch 24/50\n","455/455 [==============================] - 0s 202us/step - loss: 0.3427 - binary_accuracy: 0.8593\n","Epoch 25/50\n","455/455 [==============================] - 0s 202us/step - loss: 0.2932 - binary_accuracy: 0.9055\n","Epoch 26/50\n","455/455 [==============================] - 0s 198us/step - loss: 0.3304 - binary_accuracy: 0.8725\n","Epoch 27/50\n","455/455 [==============================] - 0s 189us/step - loss: 0.2951 - binary_accuracy: 0.8681\n","Epoch 28/50\n","455/455 [==============================] - 0s 192us/step - loss: 0.2960 - binary_accuracy: 0.8703\n","Epoch 29/50\n","455/455 [==============================] - 0s 197us/step - loss: 0.3089 - binary_accuracy: 0.8769\n","Epoch 30/50\n","455/455 [==============================] - 0s 216us/step - loss: 0.2967 - binary_accuracy: 0.8703\n","Epoch 31/50\n","455/455 [==============================] - 0s 195us/step - loss: 0.2930 - binary_accuracy: 0.8923\n","Epoch 32/50\n","455/455 [==============================] - 0s 194us/step - loss: 0.2816 - binary_accuracy: 0.8835\n","Epoch 33/50\n","455/455 [==============================] - 0s 214us/step - loss: 0.2357 - binary_accuracy: 0.9011\n","Epoch 34/50\n","455/455 [==============================] - 0s 229us/step - loss: 0.2623 - binary_accuracy: 0.8967\n","Epoch 35/50\n","455/455 [==============================] - 0s 224us/step - loss: 0.2514 - binary_accuracy: 0.9055\n","Epoch 36/50\n","455/455 [==============================] - 0s 197us/step - loss: 0.2439 - binary_accuracy: 0.9055\n","Epoch 37/50\n","455/455 [==============================] - 0s 192us/step - loss: 0.2440 - binary_accuracy: 0.9077\n","Epoch 38/50\n","455/455 [==============================] - 0s 207us/step - loss: 0.2463 - binary_accuracy: 0.9121\n","Epoch 39/50\n","455/455 [==============================] - 0s 200us/step - loss: 0.2334 - binary_accuracy: 0.9099\n","Epoch 40/50\n","455/455 [==============================] - 0s 222us/step - loss: 0.2590 - binary_accuracy: 0.8945\n","Epoch 41/50\n","455/455 [==============================] - 0s 200us/step - loss: 0.2754 - binary_accuracy: 0.8945\n","Epoch 42/50\n","455/455 [==============================] - 0s 199us/step - loss: 0.2475 - binary_accuracy: 0.8967\n","Epoch 43/50\n","455/455 [==============================] - 0s 206us/step - loss: 0.2287 - binary_accuracy: 0.9121\n","Epoch 44/50\n","455/455 [==============================] - 0s 238us/step - loss: 0.2538 - binary_accuracy: 0.8945\n","Epoch 45/50\n","455/455 [==============================] - 0s 246us/step - loss: 0.2626 - binary_accuracy: 0.8989\n","Epoch 46/50\n","455/455 [==============================] - 0s 189us/step - loss: 0.2183 - binary_accuracy: 0.9077\n","Epoch 47/50\n","455/455 [==============================] - 0s 194us/step - loss: 0.2139 - binary_accuracy: 0.9143\n","Epoch 48/50\n","455/455 [==============================] - 0s 193us/step - loss: 0.2122 - binary_accuracy: 0.9099\n","Epoch 49/50\n","455/455 [==============================] - 0s 196us/step - loss: 0.2062 - binary_accuracy: 0.9275\n","Epoch 50/50\n","455/455 [==============================] - 0s 198us/step - loss: 0.2321 - binary_accuracy: 0.8923\n","Model: \"sequential_88\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_262 (Dense)            (None, 16)                496       \n","_________________________________________________________________\n","dropout_175 (Dropout)        (None, 16)                0         \n","_________________________________________________________________\n","dense_263 (Dense)            (None, 16)                272       \n","_________________________________________________________________\n","dropout_176 (Dropout)        (None, 16)                0         \n","_________________________________________________________________\n","dense_264 (Dense)            (None, 1)                 17        \n","=================================================================\n","Total params: 785\n","Trainable params: 785\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/50\n","455/455 [==============================] - 0s 492us/step - loss: 0.8596 - binary_accuracy: 0.6352\n","Epoch 2/50\n","455/455 [==============================] - 0s 203us/step - loss: 0.5624 - binary_accuracy: 0.6615\n","Epoch 3/50\n","455/455 [==============================] - 0s 196us/step - loss: 0.5257 - binary_accuracy: 0.7055\n","Epoch 4/50\n","455/455 [==============================] - 0s 187us/step - loss: 0.5499 - binary_accuracy: 0.6791\n","Epoch 5/50\n","455/455 [==============================] - 0s 192us/step - loss: 0.4830 - binary_accuracy: 0.7451\n","Epoch 6/50\n","455/455 [==============================] - 0s 205us/step - loss: 0.4844 - binary_accuracy: 0.7538\n","Epoch 7/50\n","455/455 [==============================] - 0s 208us/step - loss: 0.5035 - binary_accuracy: 0.7626\n","Epoch 8/50\n","455/455 [==============================] - 0s 194us/step - loss: 0.4406 - binary_accuracy: 0.8132\n","Epoch 9/50\n","455/455 [==============================] - 0s 214us/step - loss: 0.4179 - binary_accuracy: 0.7978\n","Epoch 10/50\n","455/455 [==============================] - 0s 191us/step - loss: 0.4335 - binary_accuracy: 0.7868\n","Epoch 11/50\n","455/455 [==============================] - 0s 194us/step - loss: 0.3866 - binary_accuracy: 0.8440\n","Epoch 12/50\n","455/455 [==============================] - 0s 195us/step - loss: 0.3930 - binary_accuracy: 0.8440\n","Epoch 13/50\n","455/455 [==============================] - 0s 193us/step - loss: 0.3577 - binary_accuracy: 0.8769\n","Epoch 14/50\n","455/455 [==============================] - 0s 191us/step - loss: 0.3663 - binary_accuracy: 0.8615\n","Epoch 15/50\n","455/455 [==============================] - 0s 196us/step - loss: 0.3711 - binary_accuracy: 0.8527\n","Epoch 16/50\n","455/455 [==============================] - 0s 206us/step - loss: 0.3583 - binary_accuracy: 0.8725\n","Epoch 17/50\n","455/455 [==============================] - 0s 196us/step - loss: 0.3580 - binary_accuracy: 0.8527\n","Epoch 18/50\n","455/455 [==============================] - 0s 267us/step - loss: 0.3823 - binary_accuracy: 0.8242\n","Epoch 19/50\n","455/455 [==============================] - 0s 244us/step - loss: 0.3139 - binary_accuracy: 0.8703\n","Epoch 20/50\n","455/455 [==============================] - 0s 198us/step - loss: 0.3256 - binary_accuracy: 0.8725\n","Epoch 21/50\n","455/455 [==============================] - 0s 195us/step - loss: 0.3156 - binary_accuracy: 0.8725\n","Epoch 22/50\n","455/455 [==============================] - 0s 239us/step - loss: 0.3244 - binary_accuracy: 0.8857\n","Epoch 23/50\n","455/455 [==============================] - 0s 245us/step - loss: 0.3054 - binary_accuracy: 0.8747\n","Epoch 24/50\n","455/455 [==============================] - 0s 252us/step - loss: 0.3505 - binary_accuracy: 0.8593\n","Epoch 25/50\n","455/455 [==============================] - 0s 266us/step - loss: 0.2968 - binary_accuracy: 0.8857\n","Epoch 26/50\n","455/455 [==============================] - 0s 257us/step - loss: 0.2628 - binary_accuracy: 0.9011\n","Epoch 27/50\n","455/455 [==============================] - 0s 216us/step - loss: 0.3196 - binary_accuracy: 0.8549\n","Epoch 28/50\n","455/455 [==============================] - 0s 197us/step - loss: 0.2789 - binary_accuracy: 0.8989\n","Epoch 29/50\n","455/455 [==============================] - 0s 267us/step - loss: 0.3098 - binary_accuracy: 0.8791\n","Epoch 30/50\n","455/455 [==============================] - 0s 245us/step - loss: 0.2824 - binary_accuracy: 0.8725\n","Epoch 31/50\n","455/455 [==============================] - 0s 205us/step - loss: 0.2603 - binary_accuracy: 0.8923\n","Epoch 32/50\n","455/455 [==============================] - 0s 194us/step - loss: 0.2883 - binary_accuracy: 0.8747\n","Epoch 33/50\n","455/455 [==============================] - 0s 197us/step - loss: 0.2969 - binary_accuracy: 0.8857\n","Epoch 34/50\n","455/455 [==============================] - 0s 184us/step - loss: 0.2654 - binary_accuracy: 0.8989\n","Epoch 35/50\n","455/455 [==============================] - 0s 203us/step - loss: 0.2602 - binary_accuracy: 0.8923\n","Epoch 36/50\n","455/455 [==============================] - 0s 197us/step - loss: 0.2441 - binary_accuracy: 0.8967\n","Epoch 37/50\n","455/455 [==============================] - 0s 206us/step - loss: 0.2617 - binary_accuracy: 0.8923\n","Epoch 38/50\n","455/455 [==============================] - 0s 194us/step - loss: 0.2408 - binary_accuracy: 0.9121\n","Epoch 39/50\n","455/455 [==============================] - 0s 221us/step - loss: 0.2801 - binary_accuracy: 0.8879\n","Epoch 40/50\n","455/455 [==============================] - 0s 204us/step - loss: 0.2675 - binary_accuracy: 0.8901\n","Epoch 41/50\n","455/455 [==============================] - 0s 194us/step - loss: 0.2734 - binary_accuracy: 0.8945\n","Epoch 42/50\n","455/455 [==============================] - 0s 194us/step - loss: 0.2721 - binary_accuracy: 0.9033\n","Epoch 43/50\n","455/455 [==============================] - 0s 198us/step - loss: 0.2490 - binary_accuracy: 0.9077\n","Epoch 44/50\n","455/455 [==============================] - 0s 199us/step - loss: 0.2472 - binary_accuracy: 0.8923\n","Epoch 45/50\n","455/455 [==============================] - 0s 198us/step - loss: 0.2324 - binary_accuracy: 0.9187\n","Epoch 46/50\n","455/455 [==============================] - 0s 193us/step - loss: 0.2262 - binary_accuracy: 0.9033\n","Epoch 47/50\n","455/455 [==============================] - 0s 225us/step - loss: 0.2280 - binary_accuracy: 0.9165\n","Epoch 48/50\n","455/455 [==============================] - 0s 236us/step - loss: 0.2595 - binary_accuracy: 0.8945\n","Epoch 49/50\n","455/455 [==============================] - 0s 200us/step - loss: 0.2367 - binary_accuracy: 0.8923\n","Epoch 50/50\n","455/455 [==============================] - 0s 215us/step - loss: 0.2459 - binary_accuracy: 0.8989\n","Model: \"sequential_89\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_265 (Dense)            (None, 16)                496       \n","_________________________________________________________________\n","dropout_177 (Dropout)        (None, 16)                0         \n","_________________________________________________________________\n","dense_266 (Dense)            (None, 16)                272       \n","_________________________________________________________________\n","dropout_178 (Dropout)        (None, 16)                0         \n","_________________________________________________________________\n","dense_267 (Dense)            (None, 1)                 17        \n","=================================================================\n","Total params: 785\n","Trainable params: 785\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/50\n","455/455 [==============================] - 0s 499us/step - loss: 0.9698 - binary_accuracy: 0.6220\n","Epoch 2/50\n","455/455 [==============================] - 0s 209us/step - loss: 0.5600 - binary_accuracy: 0.7231\n","Epoch 3/50\n","455/455 [==============================] - 0s 266us/step - loss: 0.5156 - binary_accuracy: 0.7077\n","Epoch 4/50\n","455/455 [==============================] - 0s 254us/step - loss: 0.4877 - binary_accuracy: 0.7407\n","Epoch 5/50\n","455/455 [==============================] - 0s 261us/step - loss: 0.4879 - binary_accuracy: 0.7429\n","Epoch 6/50\n","455/455 [==============================] - 0s 251us/step - loss: 0.4491 - binary_accuracy: 0.7868\n","Epoch 7/50\n","455/455 [==============================] - 0s 241us/step - loss: 0.4084 - binary_accuracy: 0.8198\n","Epoch 8/50\n","455/455 [==============================] - 0s 266us/step - loss: 0.4428 - binary_accuracy: 0.8132\n","Epoch 9/50\n","455/455 [==============================] - 0s 229us/step - loss: 0.4068 - binary_accuracy: 0.8154\n","Epoch 10/50\n","455/455 [==============================] - 0s 201us/step - loss: 0.3786 - binary_accuracy: 0.8352\n","Epoch 11/50\n","455/455 [==============================] - 0s 187us/step - loss: 0.3925 - binary_accuracy: 0.8022\n","Epoch 12/50\n","455/455 [==============================] - 0s 224us/step - loss: 0.3545 - binary_accuracy: 0.8286\n","Epoch 13/50\n","455/455 [==============================] - 0s 199us/step - loss: 0.3770 - binary_accuracy: 0.8396\n","Epoch 14/50\n","455/455 [==============================] - 0s 189us/step - loss: 0.3505 - binary_accuracy: 0.8484\n","Epoch 15/50\n","455/455 [==============================] - 0s 191us/step - loss: 0.3482 - binary_accuracy: 0.8462\n","Epoch 16/50\n","455/455 [==============================] - 0s 198us/step - loss: 0.3426 - binary_accuracy: 0.8440\n","Epoch 17/50\n","455/455 [==============================] - 0s 192us/step - loss: 0.3102 - binary_accuracy: 0.8659\n","Epoch 18/50\n","455/455 [==============================] - 0s 192us/step - loss: 0.2939 - binary_accuracy: 0.8813\n","Epoch 19/50\n","455/455 [==============================] - 0s 192us/step - loss: 0.2821 - binary_accuracy: 0.8725\n","Epoch 20/50\n","455/455 [==============================] - 0s 224us/step - loss: 0.3084 - binary_accuracy: 0.8769\n","Epoch 21/50\n","455/455 [==============================] - 0s 267us/step - loss: 0.3243 - binary_accuracy: 0.8681\n","Epoch 22/50\n","455/455 [==============================] - 0s 271us/step - loss: 0.2868 - binary_accuracy: 0.8813\n","Epoch 23/50\n","455/455 [==============================] - 0s 250us/step - loss: 0.3090 - binary_accuracy: 0.8769\n","Epoch 24/50\n","455/455 [==============================] - 0s 193us/step - loss: 0.3027 - binary_accuracy: 0.8659\n","Epoch 25/50\n","455/455 [==============================] - 0s 190us/step - loss: 0.2987 - binary_accuracy: 0.8747\n","Epoch 26/50\n","455/455 [==============================] - 0s 193us/step - loss: 0.2816 - binary_accuracy: 0.8901\n","Epoch 27/50\n","455/455 [==============================] - 0s 202us/step - loss: 0.2805 - binary_accuracy: 0.8835\n","Epoch 28/50\n","455/455 [==============================] - 0s 195us/step - loss: 0.2821 - binary_accuracy: 0.8857\n","Epoch 29/50\n","455/455 [==============================] - 0s 192us/step - loss: 0.2721 - binary_accuracy: 0.8769\n","Epoch 30/50\n","455/455 [==============================] - 0s 203us/step - loss: 0.2605 - binary_accuracy: 0.8989\n","Epoch 31/50\n","455/455 [==============================] - 0s 209us/step - loss: 0.2607 - binary_accuracy: 0.8989\n","Epoch 32/50\n","455/455 [==============================] - 0s 194us/step - loss: 0.2491 - binary_accuracy: 0.9011\n","Epoch 33/50\n","455/455 [==============================] - 0s 210us/step - loss: 0.2545 - binary_accuracy: 0.8879\n","Epoch 34/50\n","455/455 [==============================] - 0s 189us/step - loss: 0.2339 - binary_accuracy: 0.9165\n","Epoch 35/50\n","455/455 [==============================] - 0s 190us/step - loss: 0.2484 - binary_accuracy: 0.8901\n","Epoch 36/50\n","455/455 [==============================] - 0s 194us/step - loss: 0.2624 - binary_accuracy: 0.8879\n","Epoch 37/50\n","455/455 [==============================] - 0s 190us/step - loss: 0.2291 - binary_accuracy: 0.9011\n","Epoch 38/50\n","455/455 [==============================] - 0s 192us/step - loss: 0.2741 - binary_accuracy: 0.8923\n","Epoch 39/50\n","455/455 [==============================] - 0s 199us/step - loss: 0.2635 - binary_accuracy: 0.9055\n","Epoch 40/50\n","455/455 [==============================] - 0s 195us/step - loss: 0.2446 - binary_accuracy: 0.8835\n","Epoch 41/50\n","455/455 [==============================] - 0s 213us/step - loss: 0.2121 - binary_accuracy: 0.9121\n","Epoch 42/50\n","455/455 [==============================] - 0s 209us/step - loss: 0.2395 - binary_accuracy: 0.9055\n","Epoch 43/50\n","455/455 [==============================] - 0s 198us/step - loss: 0.2506 - binary_accuracy: 0.8901\n","Epoch 44/50\n","455/455 [==============================] - 0s 213us/step - loss: 0.2253 - binary_accuracy: 0.9055\n","Epoch 45/50\n","455/455 [==============================] - 0s 198us/step - loss: 0.2191 - binary_accuracy: 0.9209\n","Epoch 46/50\n","455/455 [==============================] - 0s 190us/step - loss: 0.2315 - binary_accuracy: 0.9011\n","Epoch 47/50\n","455/455 [==============================] - 0s 201us/step - loss: 0.2158 - binary_accuracy: 0.9099\n","Epoch 48/50\n","455/455 [==============================] - 0s 193us/step - loss: 0.2623 - binary_accuracy: 0.9011\n","Epoch 49/50\n","455/455 [==============================] - 0s 204us/step - loss: 0.2210 - binary_accuracy: 0.9143\n","Epoch 50/50\n","455/455 [==============================] - 0s 198us/step - loss: 0.2280 - binary_accuracy: 0.9011\n","Model: \"sequential_90\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_268 (Dense)            (None, 16)                496       \n","_________________________________________________________________\n","dropout_179 (Dropout)        (None, 16)                0         \n","_________________________________________________________________\n","dense_269 (Dense)            (None, 16)                272       \n","_________________________________________________________________\n","dropout_180 (Dropout)        (None, 16)                0         \n","_________________________________________________________________\n","dense_270 (Dense)            (None, 1)                 17        \n","=================================================================\n","Total params: 785\n","Trainable params: 785\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/50\n","456/456 [==============================] - 0s 464us/step - loss: 1.7808 - binary_accuracy: 0.5789\n","Epoch 2/50\n","456/456 [==============================] - 0s 186us/step - loss: 0.7308 - binary_accuracy: 0.6294\n","Epoch 3/50\n","456/456 [==============================] - 0s 200us/step - loss: 0.6293 - binary_accuracy: 0.6228\n","Epoch 4/50\n","456/456 [==============================] - 0s 191us/step - loss: 0.5613 - binary_accuracy: 0.6711\n","Epoch 5/50\n","456/456 [==============================] - 0s 211us/step - loss: 0.5545 - binary_accuracy: 0.6689\n","Epoch 6/50\n","456/456 [==============================] - 0s 258us/step - loss: 0.5424 - binary_accuracy: 0.6360\n","Epoch 7/50\n","456/456 [==============================] - 0s 197us/step - loss: 0.5119 - binary_accuracy: 0.6776\n","Epoch 8/50\n","456/456 [==============================] - 0s 203us/step - loss: 0.4970 - binary_accuracy: 0.6820\n","Epoch 9/50\n","456/456 [==============================] - 0s 186us/step - loss: 0.5137 - binary_accuracy: 0.6886\n","Epoch 10/50\n","456/456 [==============================] - 0s 195us/step - loss: 0.4893 - binary_accuracy: 0.6930\n","Epoch 11/50\n","456/456 [==============================] - 0s 197us/step - loss: 0.4952 - binary_accuracy: 0.6864\n","Epoch 12/50\n","456/456 [==============================] - 0s 199us/step - loss: 0.4677 - binary_accuracy: 0.7281\n","Epoch 13/50\n","456/456 [==============================] - 0s 226us/step - loss: 0.4989 - binary_accuracy: 0.7434\n","Epoch 14/50\n","456/456 [==============================] - 0s 212us/step - loss: 0.4296 - binary_accuracy: 0.7982\n","Epoch 15/50\n","456/456 [==============================] - 0s 199us/step - loss: 0.4575 - binary_accuracy: 0.7719\n","Epoch 16/50\n","456/456 [==============================] - 0s 197us/step - loss: 0.4323 - binary_accuracy: 0.7939\n","Epoch 17/50\n","456/456 [==============================] - 0s 203us/step - loss: 0.4192 - binary_accuracy: 0.7961\n","Epoch 18/50\n","456/456 [==============================] - 0s 190us/step - loss: 0.4043 - binary_accuracy: 0.8004\n","Epoch 19/50\n","456/456 [==============================] - 0s 221us/step - loss: 0.3674 - binary_accuracy: 0.8443\n","Epoch 20/50\n","456/456 [==============================] - 0s 192us/step - loss: 0.3987 - binary_accuracy: 0.8311\n","Epoch 21/50\n","456/456 [==============================] - 0s 187us/step - loss: 0.3627 - binary_accuracy: 0.8399\n","Epoch 22/50\n","456/456 [==============================] - 0s 198us/step - loss: 0.3573 - binary_accuracy: 0.8399\n","Epoch 23/50\n","456/456 [==============================] - 0s 191us/step - loss: 0.3326 - binary_accuracy: 0.8531\n","Epoch 24/50\n","456/456 [==============================] - 0s 196us/step - loss: 0.3271 - binary_accuracy: 0.8596\n","Epoch 25/50\n","456/456 [==============================] - 0s 200us/step - loss: 0.3057 - binary_accuracy: 0.8662\n","Epoch 26/50\n","456/456 [==============================] - 0s 234us/step - loss: 0.3545 - binary_accuracy: 0.8421\n","Epoch 27/50\n","456/456 [==============================] - 0s 258us/step - loss: 0.3200 - binary_accuracy: 0.8706\n","Epoch 28/50\n","456/456 [==============================] - 0s 265us/step - loss: 0.2967 - binary_accuracy: 0.8772\n","Epoch 29/50\n","456/456 [==============================] - 0s 251us/step - loss: 0.3157 - binary_accuracy: 0.8596\n","Epoch 30/50\n","456/456 [==============================] - 0s 191us/step - loss: 0.3014 - binary_accuracy: 0.8816\n","Epoch 31/50\n","456/456 [==============================] - 0s 191us/step - loss: 0.2780 - binary_accuracy: 0.8904\n","Epoch 32/50\n","456/456 [==============================] - 0s 195us/step - loss: 0.2889 - binary_accuracy: 0.8618\n","Epoch 33/50\n","456/456 [==============================] - 0s 203us/step - loss: 0.2954 - binary_accuracy: 0.8794\n","Epoch 34/50\n","456/456 [==============================] - 0s 199us/step - loss: 0.2949 - binary_accuracy: 0.8816\n","Epoch 35/50\n","456/456 [==============================] - 0s 191us/step - loss: 0.2867 - binary_accuracy: 0.8838\n","Epoch 36/50\n","456/456 [==============================] - 0s 198us/step - loss: 0.2601 - binary_accuracy: 0.8838\n","Epoch 37/50\n","456/456 [==============================] - 0s 224us/step - loss: 0.2672 - binary_accuracy: 0.8991\n","Epoch 38/50\n","456/456 [==============================] - 0s 255us/step - loss: 0.2742 - binary_accuracy: 0.8662\n","Epoch 39/50\n","456/456 [==============================] - 0s 269us/step - loss: 0.2575 - binary_accuracy: 0.8772\n","Epoch 40/50\n","456/456 [==============================] - 0s 192us/step - loss: 0.2230 - binary_accuracy: 0.9057\n","Epoch 41/50\n","456/456 [==============================] - 0s 189us/step - loss: 0.2466 - binary_accuracy: 0.9057\n","Epoch 42/50\n","456/456 [==============================] - 0s 198us/step - loss: 0.2327 - binary_accuracy: 0.9123\n","Epoch 43/50\n","456/456 [==============================] - 0s 188us/step - loss: 0.2476 - binary_accuracy: 0.8991\n","Epoch 44/50\n","456/456 [==============================] - 0s 193us/step - loss: 0.2755 - binary_accuracy: 0.8860\n","Epoch 45/50\n","456/456 [==============================] - 0s 204us/step - loss: 0.2517 - binary_accuracy: 0.8838\n","Epoch 46/50\n","456/456 [==============================] - 0s 246us/step - loss: 0.2254 - binary_accuracy: 0.9101\n","Epoch 47/50\n","456/456 [==============================] - 0s 241us/step - loss: 0.2350 - binary_accuracy: 0.9079\n","Epoch 48/50\n","456/456 [==============================] - 0s 192us/step - loss: 0.2335 - binary_accuracy: 0.9101\n","Epoch 49/50\n","456/456 [==============================] - 0s 193us/step - loss: 0.2359 - binary_accuracy: 0.9079\n","Epoch 50/50\n","456/456 [==============================] - 0s 214us/step - loss: 0.2559 - binary_accuracy: 0.8925\n","Model: \"sequential_91\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_271 (Dense)            (None, 20)                620       \n","_________________________________________________________________\n","dropout_181 (Dropout)        (None, 20)                0         \n","_________________________________________________________________\n","dense_272 (Dense)            (None, 20)                420       \n","_________________________________________________________________\n","dropout_182 (Dropout)        (None, 20)                0         \n","_________________________________________________________________\n","dense_273 (Dense)            (None, 1)                 21        \n","=================================================================\n","Total params: 1,061\n","Trainable params: 1,061\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/50\n","455/455 [==============================] - 0s 395us/step - loss: 199.6128 - binary_accuracy: 0.6637\n","Epoch 2/50\n","455/455 [==============================] - 0s 160us/step - loss: 0.6176 - binary_accuracy: 0.6835\n","Epoch 3/50\n","455/455 [==============================] - 0s 168us/step - loss: 0.6239 - binary_accuracy: 0.6791\n","Epoch 4/50\n","455/455 [==============================] - 0s 158us/step - loss: 0.9886 - binary_accuracy: 0.6813\n","Epoch 5/50\n","455/455 [==============================] - 0s 157us/step - loss: 0.6083 - binary_accuracy: 0.6835\n","Epoch 6/50\n","455/455 [==============================] - 0s 180us/step - loss: 0.7954 - binary_accuracy: 0.6813\n","Epoch 7/50\n","455/455 [==============================] - 0s 163us/step - loss: 0.6042 - binary_accuracy: 0.6835\n","Epoch 8/50\n","455/455 [==============================] - 0s 176us/step - loss: 0.6007 - binary_accuracy: 0.6835\n","Epoch 9/50\n","455/455 [==============================] - 0s 161us/step - loss: 0.6000 - binary_accuracy: 0.6835\n","Epoch 10/50\n","455/455 [==============================] - 0s 159us/step - loss: 0.5984 - binary_accuracy: 0.6835\n","Epoch 11/50\n","455/455 [==============================] - 0s 161us/step - loss: 0.5968 - binary_accuracy: 0.6835\n","Epoch 12/50\n","455/455 [==============================] - 0s 173us/step - loss: 0.5968 - binary_accuracy: 0.6835\n","Epoch 13/50\n","455/455 [==============================] - 0s 188us/step - loss: 0.5933 - binary_accuracy: 0.6835\n","Epoch 14/50\n","455/455 [==============================] - 0s 195us/step - loss: 0.5910 - binary_accuracy: 0.6835\n","Epoch 15/50\n","455/455 [==============================] - 0s 188us/step - loss: 0.7384 - binary_accuracy: 0.6813\n","Epoch 16/50\n","455/455 [==============================] - 0s 155us/step - loss: 0.5895 - binary_accuracy: 0.6835\n","Epoch 17/50\n","455/455 [==============================] - 0s 158us/step - loss: 0.5888 - binary_accuracy: 0.6835\n","Epoch 18/50\n","455/455 [==============================] - 0s 168us/step - loss: 0.5883 - binary_accuracy: 0.6835\n","Epoch 19/50\n","455/455 [==============================] - 0s 200us/step - loss: 0.5879 - binary_accuracy: 0.6835\n","Epoch 20/50\n","455/455 [==============================] - 0s 166us/step - loss: 0.5907 - binary_accuracy: 0.6835\n","Epoch 21/50\n","455/455 [==============================] - 0s 171us/step - loss: 0.5870 - binary_accuracy: 0.6835\n","Epoch 22/50\n","455/455 [==============================] - 0s 163us/step - loss: 0.5877 - binary_accuracy: 0.6835\n","Epoch 23/50\n","455/455 [==============================] - 0s 164us/step - loss: 0.5864 - binary_accuracy: 0.6835\n","Epoch 24/50\n","455/455 [==============================] - 0s 163us/step - loss: 0.5871 - binary_accuracy: 0.6835\n","Epoch 25/50\n","455/455 [==============================] - 0s 158us/step - loss: 0.5879 - binary_accuracy: 0.6835\n","Epoch 26/50\n","455/455 [==============================] - 0s 163us/step - loss: 0.5887 - binary_accuracy: 0.6835\n","Epoch 27/50\n","455/455 [==============================] - 0s 188us/step - loss: 0.5853 - binary_accuracy: 0.6835\n","Epoch 28/50\n","455/455 [==============================] - 0s 224us/step - loss: 0.5863 - binary_accuracy: 0.6835\n","Epoch 29/50\n","455/455 [==============================] - 0s 163us/step - loss: 0.5861 - binary_accuracy: 0.6835\n","Epoch 30/50\n","455/455 [==============================] - 0s 172us/step - loss: 0.5870 - binary_accuracy: 0.6835\n","Epoch 31/50\n","455/455 [==============================] - 0s 177us/step - loss: 0.5859 - binary_accuracy: 0.6835\n","Epoch 32/50\n","455/455 [==============================] - 0s 190us/step - loss: 0.5860 - binary_accuracy: 0.6835\n","Epoch 33/50\n","455/455 [==============================] - 0s 172us/step - loss: 1.0047 - binary_accuracy: 0.6813\n","Epoch 34/50\n","455/455 [==============================] - 0s 170us/step - loss: 0.5856 - binary_accuracy: 0.6835\n","Epoch 35/50\n","455/455 [==============================] - 0s 177us/step - loss: 0.5846 - binary_accuracy: 0.6835\n","Epoch 36/50\n","455/455 [==============================] - 0s 164us/step - loss: 0.5855 - binary_accuracy: 0.6835\n","Epoch 37/50\n","455/455 [==============================] - 0s 177us/step - loss: 0.5855 - binary_accuracy: 0.6835\n","Epoch 38/50\n","455/455 [==============================] - 0s 184us/step - loss: 0.5854 - binary_accuracy: 0.6835\n","Epoch 39/50\n","455/455 [==============================] - 0s 175us/step - loss: 0.5854 - binary_accuracy: 0.6835\n","Epoch 40/50\n","455/455 [==============================] - 0s 253us/step - loss: 0.5874 - binary_accuracy: 0.6835\n","Epoch 41/50\n","455/455 [==============================] - 0s 211us/step - loss: 0.5843 - binary_accuracy: 0.6835\n","Epoch 42/50\n","455/455 [==============================] - 0s 160us/step - loss: 0.5843 - binary_accuracy: 0.6835\n","Epoch 43/50\n","455/455 [==============================] - 0s 194us/step - loss: 0.5862 - binary_accuracy: 0.6835\n","Epoch 44/50\n","455/455 [==============================] - 0s 188us/step - loss: 0.5863 - binary_accuracy: 0.6835\n","Epoch 45/50\n","455/455 [==============================] - 0s 162us/step - loss: 0.5852 - binary_accuracy: 0.6835\n","Epoch 46/50\n","455/455 [==============================] - 0s 152us/step - loss: 0.5852 - binary_accuracy: 0.6835\n","Epoch 47/50\n","455/455 [==============================] - 0s 155us/step - loss: 0.5843 - binary_accuracy: 0.6835\n","Epoch 48/50\n","455/455 [==============================] - 0s 150us/step - loss: 0.5842 - binary_accuracy: 0.6835\n","Epoch 49/50\n","455/455 [==============================] - 0s 179us/step - loss: 0.5852 - binary_accuracy: 0.6835\n","Epoch 50/50\n","455/455 [==============================] - 0s 175us/step - loss: 0.5881 - binary_accuracy: 0.6835\n","Model: \"sequential_92\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_274 (Dense)            (None, 20)                620       \n","_________________________________________________________________\n","dropout_183 (Dropout)        (None, 20)                0         \n","_________________________________________________________________\n","dense_275 (Dense)            (None, 20)                420       \n","_________________________________________________________________\n","dropout_184 (Dropout)        (None, 20)                0         \n","_________________________________________________________________\n","dense_276 (Dense)            (None, 1)                 21        \n","=================================================================\n","Total params: 1,061\n","Trainable params: 1,061\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/50\n","455/455 [==============================] - 0s 380us/step - loss: 21.4071 - binary_accuracy: 0.5934\n","Epoch 2/50\n","455/455 [==============================] - 0s 158us/step - loss: 0.6314 - binary_accuracy: 0.6418\n","Epoch 3/50\n","455/455 [==============================] - 0s 162us/step - loss: 0.6226 - binary_accuracy: 0.6418\n","Epoch 4/50\n","455/455 [==============================] - 0s 182us/step - loss: 0.6202 - binary_accuracy: 0.6418\n","Epoch 5/50\n","455/455 [==============================] - 0s 187us/step - loss: 0.6221 - binary_accuracy: 0.6418\n","Epoch 6/50\n","455/455 [==============================] - 0s 197us/step - loss: 0.6167 - binary_accuracy: 0.6418\n","Epoch 7/50\n","455/455 [==============================] - 0s 194us/step - loss: 0.6167 - binary_accuracy: 0.6418\n","Epoch 8/50\n","455/455 [==============================] - 0s 171us/step - loss: 0.6125 - binary_accuracy: 0.6418\n","Epoch 9/50\n","455/455 [==============================] - 0s 158us/step - loss: 0.6087 - binary_accuracy: 0.6418\n","Epoch 10/50\n","455/455 [==============================] - 0s 158us/step - loss: 0.6071 - binary_accuracy: 0.6418\n","Epoch 11/50\n","455/455 [==============================] - 0s 151us/step - loss: 0.6063 - binary_accuracy: 0.6418\n","Epoch 12/50\n","455/455 [==============================] - 0s 172us/step - loss: 0.6884 - binary_accuracy: 0.6396\n","Epoch 13/50\n","455/455 [==============================] - 0s 152us/step - loss: 0.6105 - binary_accuracy: 0.6418\n","Epoch 14/50\n","455/455 [==============================] - 0s 162us/step - loss: 0.6123 - binary_accuracy: 0.6418\n","Epoch 15/50\n","455/455 [==============================] - 0s 166us/step - loss: 0.6098 - binary_accuracy: 0.6418\n","Epoch 16/50\n","455/455 [==============================] - 0s 162us/step - loss: 1.3951 - binary_accuracy: 0.6418\n","Epoch 17/50\n","455/455 [==============================] - 0s 154us/step - loss: 0.6442 - binary_accuracy: 0.6418\n","Epoch 18/50\n","455/455 [==============================] - 0s 156us/step - loss: 0.6431 - binary_accuracy: 0.6418\n","Epoch 19/50\n","455/455 [==============================] - 0s 167us/step - loss: 0.6453 - binary_accuracy: 0.6418\n","Epoch 20/50\n","455/455 [==============================] - 0s 160us/step - loss: 0.6457 - binary_accuracy: 0.6418\n","Epoch 21/50\n","455/455 [==============================] - 0s 182us/step - loss: 0.6405 - binary_accuracy: 0.6418\n","Epoch 22/50\n","455/455 [==============================] - 0s 161us/step - loss: 0.6391 - binary_accuracy: 0.6418\n","Epoch 23/50\n","455/455 [==============================] - 0s 155us/step - loss: 0.6360 - binary_accuracy: 0.6418\n","Epoch 24/50\n","455/455 [==============================] - 0s 160us/step - loss: 0.6390 - binary_accuracy: 0.6418\n","Epoch 25/50\n","455/455 [==============================] - 0s 192us/step - loss: 0.6351 - binary_accuracy: 0.6418\n","Epoch 26/50\n","455/455 [==============================] - 0s 154us/step - loss: 0.6384 - binary_accuracy: 0.6418\n","Epoch 27/50\n","455/455 [==============================] - 0s 153us/step - loss: 0.6336 - binary_accuracy: 0.6418\n","Epoch 28/50\n","455/455 [==============================] - 0s 154us/step - loss: 0.6373 - binary_accuracy: 0.6418\n","Epoch 29/50\n","455/455 [==============================] - 0s 158us/step - loss: 0.6310 - binary_accuracy: 0.6418\n","Epoch 30/50\n","455/455 [==============================] - 0s 163us/step - loss: 0.6418 - binary_accuracy: 0.6418\n","Epoch 31/50\n","455/455 [==============================] - 0s 157us/step - loss: 0.6322 - binary_accuracy: 0.6418\n","Epoch 32/50\n","455/455 [==============================] - 0s 160us/step - loss: 0.6332 - binary_accuracy: 0.6418\n","Epoch 33/50\n","455/455 [==============================] - 0s 155us/step - loss: 0.6307 - binary_accuracy: 0.6418\n","Epoch 34/50\n","455/455 [==============================] - 0s 187us/step - loss: 0.6146 - binary_accuracy: 0.6418\n","Epoch 35/50\n","455/455 [==============================] - 0s 210us/step - loss: 0.6021 - binary_accuracy: 0.6418\n","Epoch 36/50\n","455/455 [==============================] - 0s 175us/step - loss: 0.6073 - binary_accuracy: 0.6418\n","Epoch 37/50\n","455/455 [==============================] - 0s 165us/step - loss: 0.6071 - binary_accuracy: 0.6418\n","Epoch 38/50\n","455/455 [==============================] - 0s 182us/step - loss: 0.6063 - binary_accuracy: 0.6418\n","Epoch 39/50\n","455/455 [==============================] - 0s 170us/step - loss: 0.6093 - binary_accuracy: 0.6418\n","Epoch 40/50\n","455/455 [==============================] - 0s 188us/step - loss: 0.6057 - binary_accuracy: 0.6418\n","Epoch 41/50\n","455/455 [==============================] - 0s 180us/step - loss: 0.6093 - binary_accuracy: 0.6418\n","Epoch 42/50\n","455/455 [==============================] - 0s 161us/step - loss: 0.6107 - binary_accuracy: 0.6418\n","Epoch 43/50\n","455/455 [==============================] - 0s 168us/step - loss: 0.6089 - binary_accuracy: 0.6418\n","Epoch 44/50\n","455/455 [==============================] - 0s 195us/step - loss: 0.6058 - binary_accuracy: 0.6418\n","Epoch 45/50\n","455/455 [==============================] - 0s 183us/step - loss: 0.6057 - binary_accuracy: 0.6418\n","Epoch 46/50\n","455/455 [==============================] - 0s 194us/step - loss: 0.6045 - binary_accuracy: 0.6418\n","Epoch 47/50\n","455/455 [==============================] - 0s 214us/step - loss: 0.6057 - binary_accuracy: 0.6418\n","Epoch 48/50\n","455/455 [==============================] - 0s 181us/step - loss: 0.6102 - binary_accuracy: 0.6418\n","Epoch 49/50\n","455/455 [==============================] - 0s 156us/step - loss: 0.6059 - binary_accuracy: 0.6418\n","Epoch 50/50\n","455/455 [==============================] - 0s 167us/step - loss: 0.6096 - binary_accuracy: 0.6418\n","Model: \"sequential_93\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_277 (Dense)            (None, 20)                620       \n","_________________________________________________________________\n","dropout_185 (Dropout)        (None, 20)                0         \n","_________________________________________________________________\n","dense_278 (Dense)            (None, 20)                420       \n","_________________________________________________________________\n","dropout_186 (Dropout)        (None, 20)                0         \n","_________________________________________________________________\n","dense_279 (Dense)            (None, 1)                 21        \n","=================================================================\n","Total params: 1,061\n","Trainable params: 1,061\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/50\n","455/455 [==============================] - 0s 409us/step - loss: 143.3813 - binary_accuracy: 0.5846\n","Epoch 2/50\n","455/455 [==============================] - 0s 207us/step - loss: 0.6832 - binary_accuracy: 0.6220\n","Epoch 3/50\n","455/455 [==============================] - 0s 200us/step - loss: 0.6815 - binary_accuracy: 0.6220\n","Epoch 4/50\n","455/455 [==============================] - 0s 159us/step - loss: 0.6788 - binary_accuracy: 0.6220\n","Epoch 5/50\n","455/455 [==============================] - 0s 154us/step - loss: 0.6752 - binary_accuracy: 0.6220\n","Epoch 6/50\n","455/455 [==============================] - 0s 175us/step - loss: 0.7270 - binary_accuracy: 0.6198\n","Epoch 7/50\n","455/455 [==============================] - 0s 158us/step - loss: 0.6729 - binary_accuracy: 0.6220\n","Epoch 8/50\n","455/455 [==============================] - 0s 176us/step - loss: 0.6713 - binary_accuracy: 0.6220\n","Epoch 9/50\n","455/455 [==============================] - 0s 164us/step - loss: 0.6711 - binary_accuracy: 0.6220\n","Epoch 10/50\n","455/455 [==============================] - 0s 158us/step - loss: 0.6673 - binary_accuracy: 0.6220\n","Epoch 11/50\n","455/455 [==============================] - 0s 155us/step - loss: 0.6674 - binary_accuracy: 0.6220\n","Epoch 12/50\n","455/455 [==============================] - 0s 155us/step - loss: 0.6679 - binary_accuracy: 0.6220\n","Epoch 13/50\n","455/455 [==============================] - 0s 170us/step - loss: 0.6660 - binary_accuracy: 0.6220\n","Epoch 14/50\n","455/455 [==============================] - 0s 166us/step - loss: 0.6782 - binary_accuracy: 0.6198\n","Epoch 15/50\n","455/455 [==============================] - 0s 167us/step - loss: 0.6671 - binary_accuracy: 0.6220\n","Epoch 16/50\n","455/455 [==============================] - 0s 154us/step - loss: 0.6642 - binary_accuracy: 0.6220\n","Epoch 17/50\n","455/455 [==============================] - 0s 162us/step - loss: 0.6649 - binary_accuracy: 0.6220\n","Epoch 18/50\n","455/455 [==============================] - 0s 162us/step - loss: 0.6634 - binary_accuracy: 0.6220\n","Epoch 19/50\n","455/455 [==============================] - 0s 157us/step - loss: 0.6631 - binary_accuracy: 0.6220\n","Epoch 20/50\n","455/455 [==============================] - 0s 171us/step - loss: 0.6616 - binary_accuracy: 0.6220\n","Epoch 21/50\n","455/455 [==============================] - 0s 157us/step - loss: 0.6649 - binary_accuracy: 0.6220\n","Epoch 22/50\n","455/455 [==============================] - 0s 170us/step - loss: 0.6612 - binary_accuracy: 0.6220\n","Epoch 23/50\n","455/455 [==============================] - 0s 155us/step - loss: 0.6611 - binary_accuracy: 0.6220\n","Epoch 24/50\n","455/455 [==============================] - 0s 159us/step - loss: 0.6621 - binary_accuracy: 0.6220\n","Epoch 25/50\n","455/455 [==============================] - 0s 169us/step - loss: 0.6620 - binary_accuracy: 0.6220\n","Epoch 26/50\n","455/455 [==============================] - 0s 189us/step - loss: 0.6618 - binary_accuracy: 0.6220\n","Epoch 27/50\n","455/455 [==============================] - 0s 177us/step - loss: 0.6617 - binary_accuracy: 0.6220\n","Epoch 28/50\n","455/455 [==============================] - 0s 167us/step - loss: 0.6616 - binary_accuracy: 0.6220\n","Epoch 29/50\n","455/455 [==============================] - 0s 153us/step - loss: 0.6626 - binary_accuracy: 0.6220\n","Epoch 30/50\n","455/455 [==============================] - 0s 159us/step - loss: 0.6626 - binary_accuracy: 0.6220\n","Epoch 31/50\n","455/455 [==============================] - 0s 158us/step - loss: 0.6614 - binary_accuracy: 0.6220\n","Epoch 32/50\n","455/455 [==============================] - 0s 179us/step - loss: 0.6614 - binary_accuracy: 0.6220\n","Epoch 33/50\n","455/455 [==============================] - 0s 222us/step - loss: 0.6614 - binary_accuracy: 0.6220\n","Epoch 34/50\n","455/455 [==============================] - 0s 191us/step - loss: 0.6624 - binary_accuracy: 0.6220\n","Epoch 35/50\n","455/455 [==============================] - 0s 196us/step - loss: 0.6613 - binary_accuracy: 0.6220\n","Epoch 36/50\n","455/455 [==============================] - 0s 194us/step - loss: 0.6635 - binary_accuracy: 0.6220\n","Epoch 37/50\n","455/455 [==============================] - 0s 153us/step - loss: 0.6613 - binary_accuracy: 0.6220\n","Epoch 38/50\n","455/455 [==============================] - 0s 181us/step - loss: 0.6601 - binary_accuracy: 0.6220\n","Epoch 39/50\n","455/455 [==============================] - 0s 158us/step - loss: 0.6612 - binary_accuracy: 0.6220\n","Epoch 40/50\n","455/455 [==============================] - 0s 163us/step - loss: 0.6612 - binary_accuracy: 0.6220\n","Epoch 41/50\n","455/455 [==============================] - 0s 167us/step - loss: 0.6622 - binary_accuracy: 0.6220\n","Epoch 42/50\n","455/455 [==============================] - 0s 158us/step - loss: 0.6612 - binary_accuracy: 0.6220\n","Epoch 43/50\n","455/455 [==============================] - 0s 157us/step - loss: 0.6611 - binary_accuracy: 0.6220\n","Epoch 44/50\n","455/455 [==============================] - 0s 158us/step - loss: 0.6622 - binary_accuracy: 0.6220\n","Epoch 45/50\n","455/455 [==============================] - 0s 169us/step - loss: 0.6611 - binary_accuracy: 0.6220\n","Epoch 46/50\n","455/455 [==============================] - 0s 150us/step - loss: 0.6622 - binary_accuracy: 0.6220\n","Epoch 47/50\n","455/455 [==============================] - 0s 157us/step - loss: 0.6622 - binary_accuracy: 0.6220\n","Epoch 48/50\n","455/455 [==============================] - 0s 164us/step - loss: 0.6622 - binary_accuracy: 0.6220\n","Epoch 49/50\n","455/455 [==============================] - 0s 156us/step - loss: 0.6611 - binary_accuracy: 0.6220\n","Epoch 50/50\n","455/455 [==============================] - 0s 194us/step - loss: 0.6611 - binary_accuracy: 0.6220\n","Model: \"sequential_94\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_280 (Dense)            (None, 20)                620       \n","_________________________________________________________________\n","dropout_187 (Dropout)        (None, 20)                0         \n","_________________________________________________________________\n","dense_281 (Dense)            (None, 20)                420       \n","_________________________________________________________________\n","dropout_188 (Dropout)        (None, 20)                0         \n","_________________________________________________________________\n","dense_282 (Dense)            (None, 1)                 21        \n","=================================================================\n","Total params: 1,061\n","Trainable params: 1,061\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/50\n","455/455 [==============================] - 0s 348us/step - loss: 34.7248 - binary_accuracy: 0.6066\n","Epoch 2/50\n","455/455 [==============================] - 0s 209us/step - loss: 0.6355 - binary_accuracy: 0.5582\n","Epoch 3/50\n","455/455 [==============================] - 0s 195us/step - loss: 0.6217 - binary_accuracy: 0.5956\n","Epoch 4/50\n","455/455 [==============================] - 0s 191us/step - loss: 0.6342 - binary_accuracy: 0.5846\n","Epoch 5/50\n","455/455 [==============================] - 0s 180us/step - loss: 1.3533 - binary_accuracy: 0.5934\n","Epoch 6/50\n","455/455 [==============================] - 0s 162us/step - loss: 0.6226 - binary_accuracy: 0.5934\n","Epoch 7/50\n","455/455 [==============================] - 0s 159us/step - loss: 0.6256 - binary_accuracy: 0.5934\n","Epoch 8/50\n","455/455 [==============================] - 0s 156us/step - loss: 0.6177 - binary_accuracy: 0.5956\n","Epoch 9/50\n","455/455 [==============================] - 0s 154us/step - loss: 0.6243 - binary_accuracy: 0.5824\n","Epoch 10/50\n","455/455 [==============================] - 0s 173us/step - loss: 0.6175 - binary_accuracy: 0.5934\n","Epoch 11/50\n","455/455 [==============================] - 0s 170us/step - loss: 0.6215 - binary_accuracy: 0.6000\n","Epoch 12/50\n","455/455 [==============================] - 0s 162us/step - loss: 0.6180 - binary_accuracy: 0.5956\n","Epoch 13/50\n","455/455 [==============================] - 0s 148us/step - loss: 0.6294 - binary_accuracy: 0.5890\n","Epoch 14/50\n","455/455 [==============================] - 0s 154us/step - loss: 0.6176 - binary_accuracy: 0.6022\n","Epoch 15/50\n","455/455 [==============================] - 0s 195us/step - loss: 0.6213 - binary_accuracy: 0.5912\n","Epoch 16/50\n","455/455 [==============================] - 0s 215us/step - loss: 0.6189 - binary_accuracy: 0.5934\n","Epoch 17/50\n","455/455 [==============================] - 0s 200us/step - loss: 0.6148 - binary_accuracy: 0.5934\n","Epoch 18/50\n","455/455 [==============================] - 0s 192us/step - loss: 0.6151 - binary_accuracy: 0.6066\n","Epoch 19/50\n","455/455 [==============================] - 0s 198us/step - loss: 0.6171 - binary_accuracy: 0.5956\n","Epoch 20/50\n","455/455 [==============================] - 0s 164us/step - loss: 0.6216 - binary_accuracy: 0.5978\n","Epoch 21/50\n","455/455 [==============================] - 0s 156us/step - loss: 0.6237 - binary_accuracy: 0.5978\n","Epoch 22/50\n","455/455 [==============================] - 0s 169us/step - loss: 0.6193 - binary_accuracy: 0.6044\n","Epoch 23/50\n","455/455 [==============================] - 0s 159us/step - loss: 0.6193 - binary_accuracy: 0.6066\n","Epoch 24/50\n","455/455 [==============================] - 0s 154us/step - loss: 0.6271 - binary_accuracy: 0.6022\n","Epoch 25/50\n","455/455 [==============================] - 0s 154us/step - loss: 0.6216 - binary_accuracy: 0.6000\n","Epoch 26/50\n","455/455 [==============================] - 0s 157us/step - loss: 0.6224 - binary_accuracy: 0.5956\n","Epoch 27/50\n","455/455 [==============================] - 0s 177us/step - loss: 0.6220 - binary_accuracy: 0.6000\n","Epoch 28/50\n","455/455 [==============================] - 0s 158us/step - loss: 0.6232 - binary_accuracy: 0.6000\n","Epoch 29/50\n","455/455 [==============================] - 0s 152us/step - loss: 0.6255 - binary_accuracy: 0.5978\n","Epoch 30/50\n","455/455 [==============================] - 0s 157us/step - loss: 0.6209 - binary_accuracy: 0.6066\n","Epoch 31/50\n","455/455 [==============================] - 0s 158us/step - loss: 0.6233 - binary_accuracy: 0.6000\n","Epoch 32/50\n","455/455 [==============================] - 0s 160us/step - loss: 0.6263 - binary_accuracy: 0.5912\n","Epoch 33/50\n","455/455 [==============================] - 0s 185us/step - loss: 0.6211 - binary_accuracy: 0.6066\n","Epoch 34/50\n","455/455 [==============================] - 0s 192us/step - loss: 0.6180 - binary_accuracy: 0.6022\n","Epoch 35/50\n","455/455 [==============================] - 0s 206us/step - loss: 0.6246 - binary_accuracy: 0.6000\n","Epoch 36/50\n","455/455 [==============================] - 0s 161us/step - loss: 0.6117 - binary_accuracy: 0.6198\n","Epoch 37/50\n","455/455 [==============================] - 0s 155us/step - loss: 0.6217 - binary_accuracy: 0.6000\n","Epoch 38/50\n","455/455 [==============================] - 0s 154us/step - loss: 0.6210 - binary_accuracy: 0.6066\n","Epoch 39/50\n","455/455 [==============================] - 0s 188us/step - loss: 0.7735 - binary_accuracy: 0.6088\n","Epoch 40/50\n","455/455 [==============================] - 0s 168us/step - loss: 0.6208 - binary_accuracy: 0.6066\n","Epoch 41/50\n","455/455 [==============================] - 0s 164us/step - loss: 0.6203 - binary_accuracy: 0.5956\n","Epoch 42/50\n","455/455 [==============================] - 0s 206us/step - loss: 0.6211 - binary_accuracy: 0.5956\n","Epoch 43/50\n","455/455 [==============================] - 0s 194us/step - loss: 0.6476 - binary_accuracy: 0.6000\n","Epoch 44/50\n","455/455 [==============================] - 0s 192us/step - loss: 0.6200 - binary_accuracy: 0.6110\n","Epoch 45/50\n","455/455 [==============================] - 0s 159us/step - loss: 0.6192 - binary_accuracy: 0.6044\n","Epoch 46/50\n","455/455 [==============================] - 0s 159us/step - loss: 0.6265 - binary_accuracy: 0.6044\n","Epoch 47/50\n","455/455 [==============================] - 0s 161us/step - loss: 0.6235 - binary_accuracy: 0.6000\n","Epoch 48/50\n","455/455 [==============================] - 0s 167us/step - loss: 0.6253 - binary_accuracy: 0.6000\n","Epoch 49/50\n","455/455 [==============================] - 0s 158us/step - loss: 0.6196 - binary_accuracy: 0.6110\n","Epoch 50/50\n","455/455 [==============================] - 0s 162us/step - loss: 0.6181 - binary_accuracy: 0.6044\n","Model: \"sequential_95\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_283 (Dense)            (None, 20)                620       \n","_________________________________________________________________\n","dropout_189 (Dropout)        (None, 20)                0         \n","_________________________________________________________________\n","dense_284 (Dense)            (None, 20)                420       \n","_________________________________________________________________\n","dropout_190 (Dropout)        (None, 20)                0         \n","_________________________________________________________________\n","dense_285 (Dense)            (None, 1)                 21        \n","=================================================================\n","Total params: 1,061\n","Trainable params: 1,061\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/50\n","456/456 [==============================] - 0s 345us/step - loss: 9.4855 - binary_accuracy: 0.5526\n","Epoch 2/50\n","456/456 [==============================] - 0s 190us/step - loss: 0.6730 - binary_accuracy: 0.5899\n","Epoch 3/50\n","456/456 [==============================] - 0s 158us/step - loss: 0.6720 - binary_accuracy: 0.5899\n","Epoch 4/50\n","456/456 [==============================] - 0s 171us/step - loss: 0.6671 - binary_accuracy: 0.5921\n","Epoch 5/50\n","456/456 [==============================] - 0s 158us/step - loss: 0.6703 - binary_accuracy: 0.5921\n","Epoch 6/50\n","456/456 [==============================] - 0s 156us/step - loss: 0.6697 - binary_accuracy: 0.5899\n","Epoch 7/50\n","456/456 [==============================] - 0s 162us/step - loss: 0.9265 - binary_accuracy: 0.5899\n","Epoch 8/50\n","456/456 [==============================] - 0s 156us/step - loss: 0.6691 - binary_accuracy: 0.5921\n","Epoch 9/50\n","456/456 [==============================] - 0s 173us/step - loss: 0.6867 - binary_accuracy: 0.5899\n","Epoch 10/50\n","456/456 [==============================] - 0s 158us/step - loss: 0.6666 - binary_accuracy: 0.5921\n","Epoch 11/50\n","456/456 [==============================] - 0s 161us/step - loss: 0.6649 - binary_accuracy: 0.5921\n","Epoch 12/50\n","456/456 [==============================] - 0s 185us/step - loss: 0.6645 - binary_accuracy: 0.5921\n","Epoch 13/50\n","456/456 [==============================] - 0s 190us/step - loss: 0.6669 - binary_accuracy: 0.5921\n","Epoch 14/50\n","456/456 [==============================] - 0s 163us/step - loss: 0.6679 - binary_accuracy: 0.5921\n","Epoch 15/50\n","456/456 [==============================] - 0s 155us/step - loss: 0.6638 - binary_accuracy: 0.5921\n","Epoch 16/50\n","456/456 [==============================] - 0s 152us/step - loss: 0.6674 - binary_accuracy: 0.5921\n","Epoch 17/50\n","456/456 [==============================] - 0s 168us/step - loss: 0.6648 - binary_accuracy: 0.5921\n","Epoch 18/50\n","456/456 [==============================] - 0s 152us/step - loss: 0.6644 - binary_accuracy: 0.5921\n","Epoch 19/50\n","456/456 [==============================] - 0s 154us/step - loss: 0.6630 - binary_accuracy: 0.5921\n","Epoch 20/50\n","456/456 [==============================] - 0s 155us/step - loss: 0.6640 - binary_accuracy: 0.5921\n","Epoch 21/50\n","456/456 [==============================] - 0s 190us/step - loss: 0.6654 - binary_accuracy: 0.5921\n","Epoch 22/50\n","456/456 [==============================] - 0s 219us/step - loss: 0.6628 - binary_accuracy: 0.5921\n","Epoch 23/50\n","456/456 [==============================] - 0s 190us/step - loss: 0.6677 - binary_accuracy: 0.5921\n","Epoch 24/50\n","456/456 [==============================] - 0s 173us/step - loss: 0.6650 - binary_accuracy: 0.5921\n","Epoch 25/50\n","456/456 [==============================] - 0s 165us/step - loss: 0.6637 - binary_accuracy: 0.5921\n","Epoch 26/50\n","456/456 [==============================] - 0s 172us/step - loss: 0.6649 - binary_accuracy: 0.5921\n","Epoch 27/50\n","456/456 [==============================] - 0s 152us/step - loss: 0.6651 - binary_accuracy: 0.5921\n","Epoch 28/50\n","456/456 [==============================] - 0s 154us/step - loss: 0.6637 - binary_accuracy: 0.5921\n","Epoch 29/50\n","456/456 [==============================] - 0s 156us/step - loss: 0.6637 - binary_accuracy: 0.5921\n","Epoch 30/50\n","456/456 [==============================] - 0s 170us/step - loss: 0.6647 - binary_accuracy: 0.5921\n","Epoch 31/50\n","456/456 [==============================] - 0s 152us/step - loss: 0.6623 - binary_accuracy: 0.5921\n","Epoch 32/50\n","456/456 [==============================] - 0s 155us/step - loss: 0.6647 - binary_accuracy: 0.5921\n","Epoch 33/50\n","456/456 [==============================] - 0s 161us/step - loss: 0.6610 - binary_accuracy: 0.5921\n","Epoch 34/50\n","456/456 [==============================] - 0s 153us/step - loss: 0.6623 - binary_accuracy: 0.5921\n","Epoch 35/50\n","456/456 [==============================] - 0s 182us/step - loss: 0.6633 - binary_accuracy: 0.5921\n","Epoch 36/50\n","456/456 [==============================] - 0s 156us/step - loss: 0.6634 - binary_accuracy: 0.5921\n","Epoch 37/50\n","456/456 [==============================] - 0s 156us/step - loss: 0.6647 - binary_accuracy: 0.5921\n","Epoch 38/50\n","456/456 [==============================] - 0s 151us/step - loss: 0.6671 - binary_accuracy: 0.5921\n","Epoch 39/50\n","456/456 [==============================] - 0s 162us/step - loss: 0.6624 - binary_accuracy: 0.5921\n","Epoch 40/50\n","456/456 [==============================] - 0s 163us/step - loss: 0.6659 - binary_accuracy: 0.5921\n","Epoch 41/50\n","456/456 [==============================] - 0s 160us/step - loss: 0.6646 - binary_accuracy: 0.5921\n","Epoch 42/50\n","456/456 [==============================] - 0s 160us/step - loss: 0.6634 - binary_accuracy: 0.5921\n","Epoch 43/50\n","456/456 [==============================] - 0s 173us/step - loss: 0.6634 - binary_accuracy: 0.5921\n","Epoch 44/50\n","456/456 [==============================] - 0s 170us/step - loss: 0.6658 - binary_accuracy: 0.5921\n","Epoch 45/50\n","456/456 [==============================] - 0s 152us/step - loss: 0.6657 - binary_accuracy: 0.5921\n","Epoch 46/50\n","456/456 [==============================] - 0s 155us/step - loss: 0.6622 - binary_accuracy: 0.5921\n","Epoch 47/50\n","456/456 [==============================] - 0s 154us/step - loss: 0.6634 - binary_accuracy: 0.5921\n","Epoch 48/50\n","456/456 [==============================] - 0s 161us/step - loss: 0.6658 - binary_accuracy: 0.5921\n","Epoch 49/50\n","456/456 [==============================] - 0s 162us/step - loss: 0.6645 - binary_accuracy: 0.5921\n","Epoch 50/50\n","456/456 [==============================] - 0s 159us/step - loss: 0.6645 - binary_accuracy: 0.5921\n","Model: \"sequential_96\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_286 (Dense)            (None, 20)                620       \n","_________________________________________________________________\n","dropout_191 (Dropout)        (None, 20)                0         \n","_________________________________________________________________\n","dense_287 (Dense)            (None, 20)                420       \n","_________________________________________________________________\n","dropout_192 (Dropout)        (None, 20)                0         \n","_________________________________________________________________\n","dense_288 (Dense)            (None, 1)                 21        \n","=================================================================\n","Total params: 1,061\n","Trainable params: 1,061\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/50\n","455/455 [==============================] - 0s 441us/step - loss: 1.3104 - binary_accuracy: 0.5626\n","Epoch 2/50\n","455/455 [==============================] - 0s 190us/step - loss: 0.5520 - binary_accuracy: 0.7363\n","Epoch 3/50\n","455/455 [==============================] - 0s 248us/step - loss: 0.5877 - binary_accuracy: 0.7407\n","Epoch 4/50\n","455/455 [==============================] - 0s 194us/step - loss: 0.4646 - binary_accuracy: 0.7802\n","Epoch 5/50\n","455/455 [==============================] - 0s 191us/step - loss: 0.4248 - binary_accuracy: 0.8022\n","Epoch 6/50\n","455/455 [==============================] - 0s 188us/step - loss: 0.3789 - binary_accuracy: 0.8527\n","Epoch 7/50\n","455/455 [==============================] - 0s 183us/step - loss: 0.3585 - binary_accuracy: 0.8725\n","Epoch 8/50\n","455/455 [==============================] - 0s 192us/step - loss: 0.3490 - binary_accuracy: 0.8527\n","Epoch 9/50\n","455/455 [==============================] - 0s 222us/step - loss: 0.2967 - binary_accuracy: 0.8813\n","Epoch 10/50\n","455/455 [==============================] - 0s 198us/step - loss: 0.2775 - binary_accuracy: 0.8923\n","Epoch 11/50\n","455/455 [==============================] - 0s 192us/step - loss: 0.3223 - binary_accuracy: 0.8637\n","Epoch 12/50\n","455/455 [==============================] - 0s 185us/step - loss: 0.2911 - binary_accuracy: 0.8967\n","Epoch 13/50\n","455/455 [==============================] - 0s 191us/step - loss: 0.2951 - binary_accuracy: 0.8879\n","Epoch 14/50\n","455/455 [==============================] - 0s 211us/step - loss: 0.2469 - binary_accuracy: 0.9033\n","Epoch 15/50\n","455/455 [==============================] - 0s 196us/step - loss: 0.2613 - binary_accuracy: 0.8967\n","Epoch 16/50\n","455/455 [==============================] - 0s 192us/step - loss: 0.2594 - binary_accuracy: 0.8967\n","Epoch 17/50\n","455/455 [==============================] - 0s 208us/step - loss: 0.3379 - binary_accuracy: 0.8549\n","Epoch 18/50\n","455/455 [==============================] - 0s 190us/step - loss: 0.2992 - binary_accuracy: 0.8923\n","Epoch 19/50\n","455/455 [==============================] - 0s 187us/step - loss: 0.2776 - binary_accuracy: 0.8967\n","Epoch 20/50\n","455/455 [==============================] - 0s 213us/step - loss: 0.2482 - binary_accuracy: 0.9033\n","Epoch 21/50\n","455/455 [==============================] - 0s 194us/step - loss: 0.2472 - binary_accuracy: 0.8989\n","Epoch 22/50\n","455/455 [==============================] - 0s 189us/step - loss: 0.2850 - binary_accuracy: 0.8681\n","Epoch 23/50\n","455/455 [==============================] - 0s 187us/step - loss: 0.2480 - binary_accuracy: 0.9165\n","Epoch 24/50\n","455/455 [==============================] - 0s 190us/step - loss: 0.2381 - binary_accuracy: 0.9143\n","Epoch 25/50\n","455/455 [==============================] - 0s 211us/step - loss: 0.2098 - binary_accuracy: 0.9341\n","Epoch 26/50\n","455/455 [==============================] - 0s 196us/step - loss: 0.2195 - binary_accuracy: 0.9187\n","Epoch 27/50\n","455/455 [==============================] - 0s 189us/step - loss: 0.2022 - binary_accuracy: 0.9253\n","Epoch 28/50\n","455/455 [==============================] - 0s 190us/step - loss: 0.2495 - binary_accuracy: 0.9011\n","Epoch 29/50\n","455/455 [==============================] - 0s 189us/step - loss: 0.2235 - binary_accuracy: 0.9209\n","Epoch 30/50\n","455/455 [==============================] - 0s 182us/step - loss: 0.1938 - binary_accuracy: 0.9187\n","Epoch 31/50\n","455/455 [==============================] - 0s 215us/step - loss: 0.2232 - binary_accuracy: 0.9121\n","Epoch 32/50\n","455/455 [==============================] - 0s 202us/step - loss: 0.1997 - binary_accuracy: 0.9319\n","Epoch 33/50\n","455/455 [==============================] - 0s 195us/step - loss: 0.1767 - binary_accuracy: 0.9297\n","Epoch 34/50\n","455/455 [==============================] - 0s 189us/step - loss: 0.2125 - binary_accuracy: 0.9209\n","Epoch 35/50\n","455/455 [==============================] - 0s 200us/step - loss: 0.2159 - binary_accuracy: 0.9165\n","Epoch 36/50\n","455/455 [==============================] - 0s 214us/step - loss: 0.1827 - binary_accuracy: 0.9407\n","Epoch 37/50\n","455/455 [==============================] - 0s 202us/step - loss: 0.1847 - binary_accuracy: 0.9341\n","Epoch 38/50\n","455/455 [==============================] - 0s 194us/step - loss: 0.2636 - binary_accuracy: 0.9033\n","Epoch 39/50\n","455/455 [==============================] - 0s 188us/step - loss: 0.2126 - binary_accuracy: 0.9055\n","Epoch 40/50\n","455/455 [==============================] - 0s 187us/step - loss: 0.2032 - binary_accuracy: 0.9231\n","Epoch 41/50\n","455/455 [==============================] - 0s 213us/step - loss: 0.2016 - binary_accuracy: 0.9187\n","Epoch 42/50\n","455/455 [==============================] - 0s 206us/step - loss: 0.2089 - binary_accuracy: 0.9099\n","Epoch 43/50\n","455/455 [==============================] - 0s 188us/step - loss: 0.2232 - binary_accuracy: 0.9033\n","Epoch 44/50\n","455/455 [==============================] - 0s 189us/step - loss: 0.1917 - binary_accuracy: 0.9319\n","Epoch 45/50\n","455/455 [==============================] - 0s 186us/step - loss: 0.1863 - binary_accuracy: 0.9319\n","Epoch 46/50\n","455/455 [==============================] - 0s 194us/step - loss: 0.1975 - binary_accuracy: 0.9341\n","Epoch 47/50\n","455/455 [==============================] - 0s 209us/step - loss: 0.1764 - binary_accuracy: 0.9253\n","Epoch 48/50\n","455/455 [==============================] - 0s 191us/step - loss: 0.2044 - binary_accuracy: 0.9143\n","Epoch 49/50\n","455/455 [==============================] - 0s 264us/step - loss: 0.2304 - binary_accuracy: 0.9121\n","Epoch 50/50\n","455/455 [==============================] - 0s 208us/step - loss: 0.1731 - binary_accuracy: 0.9319\n","Model: \"sequential_97\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_289 (Dense)            (None, 20)                620       \n","_________________________________________________________________\n","dropout_193 (Dropout)        (None, 20)                0         \n","_________________________________________________________________\n","dense_290 (Dense)            (None, 20)                420       \n","_________________________________________________________________\n","dropout_194 (Dropout)        (None, 20)                0         \n","_________________________________________________________________\n","dense_291 (Dense)            (None, 1)                 21        \n","=================================================================\n","Total params: 1,061\n","Trainable params: 1,061\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/50\n","455/455 [==============================] - 0s 505us/step - loss: 1.9953 - binary_accuracy: 0.5582\n","Epoch 2/50\n","455/455 [==============================] - 0s 215us/step - loss: 0.7534 - binary_accuracy: 0.5890\n","Epoch 3/50\n","455/455 [==============================] - 0s 188us/step - loss: 0.5676 - binary_accuracy: 0.7253\n","Epoch 4/50\n","455/455 [==============================] - 0s 190us/step - loss: 0.5706 - binary_accuracy: 0.6747\n","Epoch 5/50\n","455/455 [==============================] - 0s 196us/step - loss: 0.5223 - binary_accuracy: 0.7604\n","Epoch 6/50\n","455/455 [==============================] - 0s 195us/step - loss: 0.4653 - binary_accuracy: 0.7758\n","Epoch 7/50\n","455/455 [==============================] - 0s 225us/step - loss: 0.4697 - binary_accuracy: 0.7670\n","Epoch 8/50\n","455/455 [==============================] - 0s 236us/step - loss: 0.4574 - binary_accuracy: 0.8000\n","Epoch 9/50\n","455/455 [==============================] - 0s 250us/step - loss: 0.3995 - binary_accuracy: 0.8022\n","Epoch 10/50\n","455/455 [==============================] - 0s 247us/step - loss: 0.4125 - binary_accuracy: 0.7912\n","Epoch 11/50\n","455/455 [==============================] - 0s 255us/step - loss: 0.4257 - binary_accuracy: 0.8066\n","Epoch 12/50\n","455/455 [==============================] - 0s 273us/step - loss: 0.4145 - binary_accuracy: 0.8022\n","Epoch 13/50\n","455/455 [==============================] - 0s 249us/step - loss: 0.3632 - binary_accuracy: 0.8396\n","Epoch 14/50\n","455/455 [==============================] - 0s 218us/step - loss: 0.3610 - binary_accuracy: 0.8352\n","Epoch 15/50\n","455/455 [==============================] - 0s 196us/step - loss: 0.3622 - binary_accuracy: 0.8593\n","Epoch 16/50\n","455/455 [==============================] - 0s 214us/step - loss: 0.3389 - binary_accuracy: 0.8725\n","Epoch 17/50\n","455/455 [==============================] - 0s 193us/step - loss: 0.3387 - binary_accuracy: 0.8593\n","Epoch 18/50\n","455/455 [==============================] - 0s 217us/step - loss: 0.3453 - binary_accuracy: 0.8462\n","Epoch 19/50\n","455/455 [==============================] - 0s 214us/step - loss: 0.3234 - binary_accuracy: 0.8549\n","Epoch 20/50\n","455/455 [==============================] - 0s 229us/step - loss: 0.3240 - binary_accuracy: 0.8791\n","Epoch 21/50\n","455/455 [==============================] - 0s 198us/step - loss: 0.3467 - binary_accuracy: 0.8527\n","Epoch 22/50\n","455/455 [==============================] - 0s 208us/step - loss: 0.2884 - binary_accuracy: 0.8879\n","Epoch 23/50\n","455/455 [==============================] - 0s 191us/step - loss: 0.2862 - binary_accuracy: 0.8901\n","Epoch 24/50\n","455/455 [==============================] - 0s 182us/step - loss: 0.3078 - binary_accuracy: 0.8835\n","Epoch 25/50\n","455/455 [==============================] - 0s 190us/step - loss: 0.2683 - binary_accuracy: 0.9077\n","Epoch 26/50\n","455/455 [==============================] - 0s 196us/step - loss: 0.2671 - binary_accuracy: 0.8923\n","Epoch 27/50\n","455/455 [==============================] - 0s 269us/step - loss: 0.2586 - binary_accuracy: 0.8945\n","Epoch 28/50\n","455/455 [==============================] - 0s 218us/step - loss: 0.2821 - binary_accuracy: 0.8835\n","Epoch 29/50\n","455/455 [==============================] - 0s 186us/step - loss: 0.2695 - binary_accuracy: 0.8813\n","Epoch 30/50\n","455/455 [==============================] - 0s 193us/step - loss: 0.2900 - binary_accuracy: 0.8835\n","Epoch 31/50\n","455/455 [==============================] - 0s 203us/step - loss: 0.2310 - binary_accuracy: 0.9231\n","Epoch 32/50\n","455/455 [==============================] - 0s 207us/step - loss: 0.2409 - binary_accuracy: 0.9077\n","Epoch 33/50\n","455/455 [==============================] - 0s 192us/step - loss: 0.2262 - binary_accuracy: 0.9033\n","Epoch 34/50\n","455/455 [==============================] - 0s 192us/step - loss: 0.2434 - binary_accuracy: 0.9055\n","Epoch 35/50\n","455/455 [==============================] - 0s 195us/step - loss: 0.2053 - binary_accuracy: 0.9297\n","Epoch 36/50\n","455/455 [==============================] - 0s 190us/step - loss: 0.2539 - binary_accuracy: 0.8945\n","Epoch 37/50\n","455/455 [==============================] - 0s 190us/step - loss: 0.2394 - binary_accuracy: 0.9055\n","Epoch 38/50\n","455/455 [==============================] - 0s 221us/step - loss: 0.2501 - binary_accuracy: 0.8857\n","Epoch 39/50\n","455/455 [==============================] - 0s 208us/step - loss: 0.2158 - binary_accuracy: 0.9165\n","Epoch 40/50\n","455/455 [==============================] - 0s 196us/step - loss: 0.2136 - binary_accuracy: 0.9187\n","Epoch 41/50\n","455/455 [==============================] - 0s 191us/step - loss: 0.2183 - binary_accuracy: 0.9121\n","Epoch 42/50\n","455/455 [==============================] - 0s 194us/step - loss: 0.2307 - binary_accuracy: 0.9055\n","Epoch 43/50\n","455/455 [==============================] - 0s 212us/step - loss: 0.2183 - binary_accuracy: 0.9011\n","Epoch 44/50\n","455/455 [==============================] - 0s 193us/step - loss: 0.1955 - binary_accuracy: 0.9099\n","Epoch 45/50\n","455/455 [==============================] - 0s 191us/step - loss: 0.2477 - binary_accuracy: 0.8989\n","Epoch 46/50\n","455/455 [==============================] - 0s 201us/step - loss: 0.2465 - binary_accuracy: 0.9033\n","Epoch 47/50\n","455/455 [==============================] - 0s 194us/step - loss: 0.2222 - binary_accuracy: 0.8967\n","Epoch 48/50\n","455/455 [==============================] - 0s 240us/step - loss: 0.2258 - binary_accuracy: 0.9099\n","Epoch 49/50\n","455/455 [==============================] - 0s 236us/step - loss: 0.2164 - binary_accuracy: 0.9077\n","Epoch 50/50\n","455/455 [==============================] - 0s 199us/step - loss: 0.2210 - binary_accuracy: 0.9033\n","Model: \"sequential_98\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_292 (Dense)            (None, 20)                620       \n","_________________________________________________________________\n","dropout_195 (Dropout)        (None, 20)                0         \n","_________________________________________________________________\n","dense_293 (Dense)            (None, 20)                420       \n","_________________________________________________________________\n","dropout_196 (Dropout)        (None, 20)                0         \n","_________________________________________________________________\n","dense_294 (Dense)            (None, 1)                 21        \n","=================================================================\n","Total params: 1,061\n","Trainable params: 1,061\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/50\n","455/455 [==============================] - 0s 512us/step - loss: 1.4449 - binary_accuracy: 0.5319\n","Epoch 2/50\n","455/455 [==============================] - 0s 229us/step - loss: 0.7969 - binary_accuracy: 0.5934\n","Epoch 3/50\n","455/455 [==============================] - 0s 191us/step - loss: 0.6085 - binary_accuracy: 0.6088\n","Epoch 4/50\n","455/455 [==============================] - 0s 189us/step - loss: 0.5766 - binary_accuracy: 0.6374\n","Epoch 5/50\n","455/455 [==============================] - 0s 197us/step - loss: 0.5926 - binary_accuracy: 0.6352\n","Epoch 6/50\n","455/455 [==============================] - 0s 203us/step - loss: 0.5484 - binary_accuracy: 0.6615\n","Epoch 7/50\n","455/455 [==============================] - 0s 203us/step - loss: 0.5324 - binary_accuracy: 0.7077\n","Epoch 8/50\n","455/455 [==============================] - 0s 193us/step - loss: 0.5346 - binary_accuracy: 0.6923\n","Epoch 9/50\n","455/455 [==============================] - 0s 199us/step - loss: 0.5235 - binary_accuracy: 0.6989\n","Epoch 10/50\n","455/455 [==============================] - 0s 194us/step - loss: 0.5161 - binary_accuracy: 0.7363\n","Epoch 11/50\n","455/455 [==============================] - 0s 201us/step - loss: 0.5266 - binary_accuracy: 0.7011\n","Epoch 12/50\n","455/455 [==============================] - 0s 186us/step - loss: 0.4681 - binary_accuracy: 0.7934\n","Epoch 13/50\n","455/455 [==============================] - 0s 209us/step - loss: 0.4377 - binary_accuracy: 0.7912\n","Epoch 14/50\n","455/455 [==============================] - 0s 191us/step - loss: 0.4467 - binary_accuracy: 0.8022\n","Epoch 15/50\n","455/455 [==============================] - 0s 203us/step - loss: 0.4091 - binary_accuracy: 0.8198\n","Epoch 16/50\n","455/455 [==============================] - 0s 203us/step - loss: 0.4016 - binary_accuracy: 0.8308\n","Epoch 17/50\n","455/455 [==============================] - 0s 191us/step - loss: 0.3860 - binary_accuracy: 0.8352\n","Epoch 18/50\n","455/455 [==============================] - 0s 201us/step - loss: 0.3690 - binary_accuracy: 0.8418\n","Epoch 19/50\n","455/455 [==============================] - 0s 194us/step - loss: 0.3596 - binary_accuracy: 0.8462\n","Epoch 20/50\n","455/455 [==============================] - 0s 192us/step - loss: 0.3521 - binary_accuracy: 0.8593\n","Epoch 21/50\n","455/455 [==============================] - 0s 193us/step - loss: 0.3453 - binary_accuracy: 0.8484\n","Epoch 22/50\n","455/455 [==============================] - 0s 193us/step - loss: 0.3206 - binary_accuracy: 0.8813\n","Epoch 23/50\n","455/455 [==============================] - 0s 188us/step - loss: 0.3415 - binary_accuracy: 0.8615\n","Epoch 24/50\n","455/455 [==============================] - 0s 205us/step - loss: 0.3116 - binary_accuracy: 0.8703\n","Epoch 25/50\n","455/455 [==============================] - 0s 189us/step - loss: 0.2952 - binary_accuracy: 0.8813\n","Epoch 26/50\n","455/455 [==============================] - 0s 192us/step - loss: 0.2795 - binary_accuracy: 0.8769\n","Epoch 27/50\n","455/455 [==============================] - 0s 192us/step - loss: 0.2980 - binary_accuracy: 0.8769\n","Epoch 28/50\n","455/455 [==============================] - 0s 192us/step - loss: 0.3035 - binary_accuracy: 0.8659\n","Epoch 29/50\n","455/455 [==============================] - 0s 217us/step - loss: 0.2879 - binary_accuracy: 0.8725\n","Epoch 30/50\n","455/455 [==============================] - 0s 194us/step - loss: 0.2722 - binary_accuracy: 0.8835\n","Epoch 31/50\n","455/455 [==============================] - 0s 191us/step - loss: 0.3471 - binary_accuracy: 0.8637\n","Epoch 32/50\n","455/455 [==============================] - 0s 197us/step - loss: 0.3166 - binary_accuracy: 0.8813\n","Epoch 33/50\n","455/455 [==============================] - 0s 207us/step - loss: 0.2827 - binary_accuracy: 0.9077\n","Epoch 34/50\n","455/455 [==============================] - 0s 240us/step - loss: 0.2647 - binary_accuracy: 0.8989\n","Epoch 35/50\n","455/455 [==============================] - 0s 246us/step - loss: 0.2726 - binary_accuracy: 0.8857\n","Epoch 36/50\n","455/455 [==============================] - 0s 189us/step - loss: 0.2749 - binary_accuracy: 0.8879\n","Epoch 37/50\n","455/455 [==============================] - 0s 192us/step - loss: 0.2766 - binary_accuracy: 0.8879\n","Epoch 38/50\n","455/455 [==============================] - 0s 193us/step - loss: 0.2612 - binary_accuracy: 0.8835\n","Epoch 39/50\n","455/455 [==============================] - 0s 186us/step - loss: 0.2700 - binary_accuracy: 0.8989\n","Epoch 40/50\n","455/455 [==============================] - 0s 217us/step - loss: 0.2777 - binary_accuracy: 0.9055\n","Epoch 41/50\n","455/455 [==============================] - 0s 191us/step - loss: 0.2626 - binary_accuracy: 0.8901\n","Epoch 42/50\n","455/455 [==============================] - 0s 194us/step - loss: 0.2544 - binary_accuracy: 0.9055\n","Epoch 43/50\n","455/455 [==============================] - 0s 188us/step - loss: 0.2507 - binary_accuracy: 0.8989\n","Epoch 44/50\n","455/455 [==============================] - 0s 195us/step - loss: 0.3131 - binary_accuracy: 0.8725\n","Epoch 45/50\n","455/455 [==============================] - 0s 199us/step - loss: 0.2730 - binary_accuracy: 0.8857\n","Epoch 46/50\n","455/455 [==============================] - 0s 249us/step - loss: 0.2562 - binary_accuracy: 0.8857\n","Epoch 47/50\n","455/455 [==============================] - 0s 262us/step - loss: 0.2484 - binary_accuracy: 0.9055\n","Epoch 48/50\n","455/455 [==============================] - 0s 294us/step - loss: 0.2276 - binary_accuracy: 0.9143\n","Epoch 49/50\n","455/455 [==============================] - 0s 194us/step - loss: 0.2495 - binary_accuracy: 0.8945\n","Epoch 50/50\n","455/455 [==============================] - 0s 206us/step - loss: 0.2218 - binary_accuracy: 0.9165\n","Model: \"sequential_99\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_295 (Dense)            (None, 20)                620       \n","_________________________________________________________________\n","dropout_197 (Dropout)        (None, 20)                0         \n","_________________________________________________________________\n","dense_296 (Dense)            (None, 20)                420       \n","_________________________________________________________________\n","dropout_198 (Dropout)        (None, 20)                0         \n","_________________________________________________________________\n","dense_297 (Dense)            (None, 1)                 21        \n","=================================================================\n","Total params: 1,061\n","Trainable params: 1,061\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/50\n","455/455 [==============================] - 0s 586us/step - loss: 1.6593 - binary_accuracy: 0.5604\n","Epoch 2/50\n","455/455 [==============================] - 0s 267us/step - loss: 0.6003 - binary_accuracy: 0.6440\n","Epoch 3/50\n","455/455 [==============================] - 0s 254us/step - loss: 0.5760 - binary_accuracy: 0.6593\n","Epoch 4/50\n","455/455 [==============================] - 0s 266us/step - loss: 0.5364 - binary_accuracy: 0.6659\n","Epoch 5/50\n","455/455 [==============================] - 0s 235us/step - loss: 0.5291 - binary_accuracy: 0.6945\n","Epoch 6/50\n","455/455 [==============================] - 0s 194us/step - loss: 0.5125 - binary_accuracy: 0.6813\n","Epoch 7/50\n","455/455 [==============================] - 0s 214us/step - loss: 0.4998 - binary_accuracy: 0.6989\n","Epoch 8/50\n","455/455 [==============================] - 0s 185us/step - loss: 0.4814 - binary_accuracy: 0.7121\n","Epoch 9/50\n","455/455 [==============================] - 0s 188us/step - loss: 0.4753 - binary_accuracy: 0.7582\n","Epoch 10/50\n","455/455 [==============================] - 0s 193us/step - loss: 0.4497 - binary_accuracy: 0.7319\n","Epoch 11/50\n","455/455 [==============================] - 0s 188us/step - loss: 0.4387 - binary_accuracy: 0.7670\n","Epoch 12/50\n","455/455 [==============================] - 0s 188us/step - loss: 0.4742 - binary_accuracy: 0.7451\n","Epoch 13/50\n","455/455 [==============================] - 0s 200us/step - loss: 0.4354 - binary_accuracy: 0.7648\n","Epoch 14/50\n","455/455 [==============================] - 0s 193us/step - loss: 0.4338 - binary_accuracy: 0.7670\n","Epoch 15/50\n","455/455 [==============================] - 0s 187us/step - loss: 0.4271 - binary_accuracy: 0.7692\n","Epoch 16/50\n","455/455 [==============================] - 0s 191us/step - loss: 0.4297 - binary_accuracy: 0.7824\n","Epoch 17/50\n","455/455 [==============================] - 0s 199us/step - loss: 0.3902 - binary_accuracy: 0.8220\n","Epoch 18/50\n","455/455 [==============================] - 0s 200us/step - loss: 0.3949 - binary_accuracy: 0.7978\n","Epoch 19/50\n","455/455 [==============================] - 0s 206us/step - loss: 0.3800 - binary_accuracy: 0.8308\n","Epoch 20/50\n","455/455 [==============================] - 0s 194us/step - loss: 0.3764 - binary_accuracy: 0.8396\n","Epoch 21/50\n","455/455 [==============================] - 0s 208us/step - loss: 0.3608 - binary_accuracy: 0.8418\n","Epoch 22/50\n","455/455 [==============================] - 0s 191us/step - loss: 0.3296 - binary_accuracy: 0.8593\n","Epoch 23/50\n","455/455 [==============================] - 0s 189us/step - loss: 0.3222 - binary_accuracy: 0.8659\n","Epoch 24/50\n","455/455 [==============================] - 0s 206us/step - loss: 0.3266 - binary_accuracy: 0.8615\n","Epoch 25/50\n","455/455 [==============================] - 0s 254us/step - loss: 0.2893 - binary_accuracy: 0.8769\n","Epoch 26/50\n","455/455 [==============================] - 0s 247us/step - loss: 0.2918 - binary_accuracy: 0.8769\n","Epoch 27/50\n","455/455 [==============================] - 0s 218us/step - loss: 0.2890 - binary_accuracy: 0.8923\n","Epoch 28/50\n","455/455 [==============================] - 0s 202us/step - loss: 0.2755 - binary_accuracy: 0.8835\n","Epoch 29/50\n","455/455 [==============================] - 0s 212us/step - loss: 0.3156 - binary_accuracy: 0.8725\n","Epoch 30/50\n","455/455 [==============================] - 0s 201us/step - loss: 0.2690 - binary_accuracy: 0.8945\n","Epoch 31/50\n","455/455 [==============================] - 0s 200us/step - loss: 0.3080 - binary_accuracy: 0.8637\n","Epoch 32/50\n","455/455 [==============================] - 0s 189us/step - loss: 0.3155 - binary_accuracy: 0.8659\n","Epoch 33/50\n","455/455 [==============================] - 0s 193us/step - loss: 0.2882 - binary_accuracy: 0.8725\n","Epoch 34/50\n","455/455 [==============================] - 0s 208us/step - loss: 0.2544 - binary_accuracy: 0.9077\n","Epoch 35/50\n","455/455 [==============================] - 0s 196us/step - loss: 0.2580 - binary_accuracy: 0.9055\n","Epoch 36/50\n","455/455 [==============================] - 0s 199us/step - loss: 0.2757 - binary_accuracy: 0.8769\n","Epoch 37/50\n","455/455 [==============================] - 0s 211us/step - loss: 0.2533 - binary_accuracy: 0.8945\n","Epoch 38/50\n","455/455 [==============================] - 0s 192us/step - loss: 0.2450 - binary_accuracy: 0.8989\n","Epoch 39/50\n","455/455 [==============================] - 0s 275us/step - loss: 0.2719 - binary_accuracy: 0.8923\n","Epoch 40/50\n","455/455 [==============================] - 0s 250us/step - loss: 0.2661 - binary_accuracy: 0.8879\n","Epoch 41/50\n","455/455 [==============================] - 0s 189us/step - loss: 0.2745 - binary_accuracy: 0.8879\n","Epoch 42/50\n","455/455 [==============================] - 0s 195us/step - loss: 0.2732 - binary_accuracy: 0.9033\n","Epoch 43/50\n","455/455 [==============================] - 0s 222us/step - loss: 0.2553 - binary_accuracy: 0.8923\n","Epoch 44/50\n","455/455 [==============================] - 0s 274us/step - loss: 0.2440 - binary_accuracy: 0.8989\n","Epoch 45/50\n","455/455 [==============================] - 0s 259us/step - loss: 0.2509 - binary_accuracy: 0.8967\n","Epoch 46/50\n","455/455 [==============================] - 0s 228us/step - loss: 0.2352 - binary_accuracy: 0.9033\n","Epoch 47/50\n","455/455 [==============================] - 0s 192us/step - loss: 0.2421 - binary_accuracy: 0.9033\n","Epoch 48/50\n","455/455 [==============================] - 0s 192us/step - loss: 0.2401 - binary_accuracy: 0.9011\n","Epoch 49/50\n","455/455 [==============================] - 0s 207us/step - loss: 0.2329 - binary_accuracy: 0.8967\n","Epoch 50/50\n","455/455 [==============================] - 0s 192us/step - loss: 0.2280 - binary_accuracy: 0.9143\n","Model: \"sequential_100\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_298 (Dense)            (None, 20)                620       \n","_________________________________________________________________\n","dropout_199 (Dropout)        (None, 20)                0         \n","_________________________________________________________________\n","dense_299 (Dense)            (None, 20)                420       \n","_________________________________________________________________\n","dropout_200 (Dropout)        (None, 20)                0         \n","_________________________________________________________________\n","dense_300 (Dense)            (None, 1)                 21        \n","=================================================================\n","Total params: 1,061\n","Trainable params: 1,061\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/50\n","456/456 [==============================] - 0s 561us/step - loss: 1.5596 - binary_accuracy: 0.5570\n","Epoch 2/50\n","456/456 [==============================] - 0s 184us/step - loss: 0.7584 - binary_accuracy: 0.5943\n","Epoch 3/50\n","456/456 [==============================] - 0s 207us/step - loss: 0.6327 - binary_accuracy: 0.5987\n","Epoch 4/50\n","456/456 [==============================] - 0s 182us/step - loss: 0.6053 - binary_accuracy: 0.5987\n","Epoch 5/50\n","456/456 [==============================] - 0s 190us/step - loss: 0.5850 - binary_accuracy: 0.6557\n","Epoch 6/50\n","456/456 [==============================] - 0s 197us/step - loss: 0.5604 - binary_accuracy: 0.6557\n","Epoch 7/50\n","456/456 [==============================] - 0s 201us/step - loss: 0.5365 - binary_accuracy: 0.6711\n","Epoch 8/50\n","456/456 [==============================] - 0s 189us/step - loss: 0.5115 - binary_accuracy: 0.7039\n","Epoch 9/50\n","456/456 [==============================] - 0s 219us/step - loss: 0.5344 - binary_accuracy: 0.6601\n","Epoch 10/50\n","456/456 [==============================] - 0s 191us/step - loss: 0.5080 - binary_accuracy: 0.6754\n","Epoch 11/50\n","456/456 [==============================] - 0s 190us/step - loss: 0.4967 - binary_accuracy: 0.7171\n","Epoch 12/50\n","456/456 [==============================] - 0s 192us/step - loss: 0.4459 - binary_accuracy: 0.7412\n","Epoch 13/50\n","456/456 [==============================] - 0s 187us/step - loss: 0.5056 - binary_accuracy: 0.7368\n","Epoch 14/50\n","456/456 [==============================] - 0s 202us/step - loss: 0.4912 - binary_accuracy: 0.7193\n","Epoch 15/50\n","456/456 [==============================] - 0s 188us/step - loss: 0.4798 - binary_accuracy: 0.7500\n","Epoch 16/50\n","456/456 [==============================] - 0s 192us/step - loss: 0.4425 - binary_accuracy: 0.8004\n","Epoch 17/50\n","456/456 [==============================] - 0s 204us/step - loss: 0.4378 - binary_accuracy: 0.7763\n","Epoch 18/50\n","456/456 [==============================] - 0s 209us/step - loss: 0.4010 - binary_accuracy: 0.8311\n","Epoch 19/50\n","456/456 [==============================] - 0s 196us/step - loss: 0.3632 - binary_accuracy: 0.8640\n","Epoch 20/50\n","456/456 [==============================] - 0s 192us/step - loss: 0.3736 - binary_accuracy: 0.8333\n","Epoch 21/50\n","456/456 [==============================] - 0s 215us/step - loss: 0.4121 - binary_accuracy: 0.8070\n","Epoch 22/50\n","456/456 [==============================] - 0s 255us/step - loss: 0.3581 - binary_accuracy: 0.8377\n","Epoch 23/50\n","456/456 [==============================] - 0s 193us/step - loss: 0.3431 - binary_accuracy: 0.8596\n","Epoch 24/50\n","456/456 [==============================] - 0s 192us/step - loss: 0.3344 - binary_accuracy: 0.8706\n","Epoch 25/50\n","456/456 [==============================] - 0s 197us/step - loss: 0.3433 - binary_accuracy: 0.8465\n","Epoch 26/50\n","456/456 [==============================] - 0s 191us/step - loss: 0.2984 - binary_accuracy: 0.8925\n","Epoch 27/50\n","456/456 [==============================] - 0s 188us/step - loss: 0.3262 - binary_accuracy: 0.8684\n","Epoch 28/50\n","456/456 [==============================] - 0s 202us/step - loss: 0.3010 - binary_accuracy: 0.8684\n","Epoch 29/50\n","456/456 [==============================] - 0s 203us/step - loss: 0.3268 - binary_accuracy: 0.8596\n","Epoch 30/50\n","456/456 [==============================] - 0s 198us/step - loss: 0.2728 - binary_accuracy: 0.9035\n","Epoch 31/50\n","456/456 [==============================] - 0s 193us/step - loss: 0.3035 - binary_accuracy: 0.8925\n","Epoch 32/50\n","456/456 [==============================] - 0s 198us/step - loss: 0.2926 - binary_accuracy: 0.8904\n","Epoch 33/50\n","456/456 [==============================] - 0s 200us/step - loss: 0.3185 - binary_accuracy: 0.8838\n","Epoch 34/50\n","456/456 [==============================] - 0s 192us/step - loss: 0.3188 - binary_accuracy: 0.8750\n","Epoch 35/50\n","456/456 [==============================] - 0s 190us/step - loss: 0.3603 - binary_accuracy: 0.8575\n","Epoch 36/50\n","456/456 [==============================] - 0s 213us/step - loss: 0.2758 - binary_accuracy: 0.8991\n","Epoch 37/50\n","456/456 [==============================] - 0s 191us/step - loss: 0.2847 - binary_accuracy: 0.8969\n","Epoch 38/50\n","456/456 [==============================] - 0s 190us/step - loss: 0.2587 - binary_accuracy: 0.8925\n","Epoch 39/50\n","456/456 [==============================] - 0s 198us/step - loss: 0.2492 - binary_accuracy: 0.8969\n","Epoch 40/50\n","456/456 [==============================] - 0s 198us/step - loss: 0.2560 - binary_accuracy: 0.8969\n","Epoch 41/50\n","456/456 [==============================] - 0s 254us/step - loss: 0.2504 - binary_accuracy: 0.8991\n","Epoch 42/50\n","456/456 [==============================] - 0s 246us/step - loss: 0.2522 - binary_accuracy: 0.9079\n","Epoch 43/50\n","456/456 [==============================] - 0s 246us/step - loss: 0.2798 - binary_accuracy: 0.8838\n","Epoch 44/50\n","456/456 [==============================] - 0s 181us/step - loss: 0.2431 - binary_accuracy: 0.9101\n","Epoch 45/50\n","456/456 [==============================] - 0s 197us/step - loss: 0.2345 - binary_accuracy: 0.8947\n","Epoch 46/50\n","456/456 [==============================] - 0s 207us/step - loss: 0.2937 - binary_accuracy: 0.8684\n","Epoch 47/50\n","456/456 [==============================] - 0s 196us/step - loss: 0.2300 - binary_accuracy: 0.9123\n","Epoch 48/50\n","456/456 [==============================] - 0s 190us/step - loss: 0.2063 - binary_accuracy: 0.9298\n","Epoch 49/50\n","456/456 [==============================] - 0s 191us/step - loss: 0.2354 - binary_accuracy: 0.9167\n","Epoch 50/50\n","456/456 [==============================] - 0s 202us/step - loss: 0.2235 - binary_accuracy: 0.9101\n","Model: \"sequential_101\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_301 (Dense)            (None, 16)                496       \n","_________________________________________________________________\n","dropout_201 (Dropout)        (None, 16)                0         \n","_________________________________________________________________\n","dense_302 (Dense)            (None, 16)                272       \n","_________________________________________________________________\n","dropout_202 (Dropout)        (None, 16)                0         \n","_________________________________________________________________\n","dense_303 (Dense)            (None, 1)                 17        \n","=================================================================\n","Total params: 785\n","Trainable params: 785\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/50\n","455/455 [==============================] - 0s 369us/step - loss: 1.0635 - binary_accuracy: 0.6769\n","Epoch 2/50\n","455/455 [==============================] - 0s 159us/step - loss: 1.0000 - binary_accuracy: 0.6835\n","Epoch 3/50\n","455/455 [==============================] - 0s 156us/step - loss: 1.0000 - binary_accuracy: 0.6835\n","Epoch 4/50\n","455/455 [==============================] - 0s 148us/step - loss: 0.9996 - binary_accuracy: 0.6857\n","Epoch 5/50\n","455/455 [==============================] - 0s 149us/step - loss: 1.0001 - binary_accuracy: 0.6835\n","Epoch 6/50\n","455/455 [==============================] - 0s 145us/step - loss: 1.0282 - binary_accuracy: 0.6813\n","Epoch 7/50\n","455/455 [==============================] - 0s 157us/step - loss: 1.0000 - binary_accuracy: 0.6835\n","Epoch 8/50\n","455/455 [==============================] - 0s 156us/step - loss: 1.0001 - binary_accuracy: 0.6835\n","Epoch 9/50\n","455/455 [==============================] - 0s 152us/step - loss: 1.0000 - binary_accuracy: 0.6835\n","Epoch 10/50\n","455/455 [==============================] - 0s 164us/step - loss: 1.0000 - binary_accuracy: 0.6835\n","Epoch 11/50\n","455/455 [==============================] - 0s 197us/step - loss: 0.9999 - binary_accuracy: 0.6835\n","Epoch 12/50\n","455/455 [==============================] - 0s 185us/step - loss: 1.0000 - binary_accuracy: 0.6835\n","Epoch 13/50\n","455/455 [==============================] - 0s 186us/step - loss: 1.0005 - binary_accuracy: 0.6835\n","Epoch 14/50\n","455/455 [==============================] - 0s 180us/step - loss: 1.0000 - binary_accuracy: 0.6835\n","Epoch 15/50\n","455/455 [==============================] - 0s 183us/step - loss: 1.0000 - binary_accuracy: 0.6835\n","Epoch 16/50\n","455/455 [==============================] - 0s 167us/step - loss: 1.0000 - binary_accuracy: 0.6835\n","Epoch 17/50\n","455/455 [==============================] - 0s 156us/step - loss: 1.0002 - binary_accuracy: 0.6835\n","Epoch 18/50\n","455/455 [==============================] - 0s 151us/step - loss: 1.0000 - binary_accuracy: 0.6835\n","Epoch 19/50\n","455/455 [==============================] - 0s 152us/step - loss: 1.0004 - binary_accuracy: 0.6835\n","Epoch 20/50\n","455/455 [==============================] - 0s 172us/step - loss: 1.0002 - binary_accuracy: 0.6835\n","Epoch 21/50\n","455/455 [==============================] - 0s 174us/step - loss: 1.0004 - binary_accuracy: 0.6835\n","Epoch 22/50\n","455/455 [==============================] - 0s 157us/step - loss: 0.9989 - binary_accuracy: 0.6835\n","Epoch 23/50\n","455/455 [==============================] - 0s 152us/step - loss: 1.0000 - binary_accuracy: 0.6835\n","Epoch 24/50\n","455/455 [==============================] - 0s 148us/step - loss: 1.0000 - binary_accuracy: 0.6835\n","Epoch 25/50\n","455/455 [==============================] - 0s 148us/step - loss: 0.9992 - binary_accuracy: 0.6835\n","Epoch 26/50\n","455/455 [==============================] - 0s 147us/step - loss: 1.0004 - binary_accuracy: 0.6835\n","Epoch 27/50\n","455/455 [==============================] - 0s 150us/step - loss: 1.0000 - binary_accuracy: 0.6835\n","Epoch 28/50\n","455/455 [==============================] - 0s 149us/step - loss: 1.0000 - binary_accuracy: 0.6835\n","Epoch 29/50\n","455/455 [==============================] - 0s 164us/step - loss: 1.0006 - binary_accuracy: 0.6835\n","Epoch 30/50\n","455/455 [==============================] - 0s 145us/step - loss: 1.0001 - binary_accuracy: 0.6835\n","Epoch 31/50\n","455/455 [==============================] - 0s 146us/step - loss: 1.0000 - binary_accuracy: 0.6835\n","Epoch 32/50\n","455/455 [==============================] - 0s 152us/step - loss: 0.9999 - binary_accuracy: 0.6835\n","Epoch 33/50\n","455/455 [==============================] - 0s 147us/step - loss: 1.0002 - binary_accuracy: 0.6835\n","Epoch 34/50\n","455/455 [==============================] - 0s 168us/step - loss: 1.0000 - binary_accuracy: 0.6835\n","Epoch 35/50\n","455/455 [==============================] - 0s 152us/step - loss: 0.9999 - binary_accuracy: 0.6835\n","Epoch 36/50\n","455/455 [==============================] - 0s 149us/step - loss: 1.0000 - binary_accuracy: 0.6835\n","Epoch 37/50\n","455/455 [==============================] - 0s 146us/step - loss: 1.0000 - binary_accuracy: 0.6835\n","Epoch 38/50\n","455/455 [==============================] - 0s 146us/step - loss: 1.0000 - binary_accuracy: 0.6835\n","Epoch 39/50\n","455/455 [==============================] - 0s 153us/step - loss: 1.0104 - binary_accuracy: 0.6813\n","Epoch 40/50\n","455/455 [==============================] - 0s 149us/step - loss: 1.0000 - binary_accuracy: 0.6835\n","Epoch 41/50\n","455/455 [==============================] - 0s 148us/step - loss: 1.0000 - binary_accuracy: 0.6835\n","Epoch 42/50\n","455/455 [==============================] - 0s 178us/step - loss: 1.0000 - binary_accuracy: 0.6835\n","Epoch 43/50\n","455/455 [==============================] - 0s 202us/step - loss: 0.9997 - binary_accuracy: 0.6835\n","Epoch 44/50\n","455/455 [==============================] - 0s 154us/step - loss: 1.0004 - binary_accuracy: 0.6835\n","Epoch 45/50\n","455/455 [==============================] - 0s 149us/step - loss: 1.0000 - binary_accuracy: 0.6835\n","Epoch 46/50\n","455/455 [==============================] - 0s 153us/step - loss: 0.9999 - binary_accuracy: 0.6835\n","Epoch 47/50\n","455/455 [==============================] - 0s 149us/step - loss: 1.0004 - binary_accuracy: 0.6835\n","Epoch 48/50\n","455/455 [==============================] - 0s 173us/step - loss: 1.0000 - binary_accuracy: 0.6835\n","Epoch 49/50\n","455/455 [==============================] - 0s 160us/step - loss: 1.0004 - binary_accuracy: 0.6835\n","Epoch 50/50\n","455/455 [==============================] - 0s 155us/step - loss: 0.9989 - binary_accuracy: 0.6835\n","Model: \"sequential_102\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_304 (Dense)            (None, 16)                496       \n","_________________________________________________________________\n","dropout_203 (Dropout)        (None, 16)                0         \n","_________________________________________________________________\n","dense_305 (Dense)            (None, 16)                272       \n","_________________________________________________________________\n","dropout_204 (Dropout)        (None, 16)                0         \n","_________________________________________________________________\n","dense_306 (Dense)            (None, 1)                 17        \n","=================================================================\n","Total params: 785\n","Trainable params: 785\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/50\n","455/455 [==============================] - 0s 370us/step - loss: 1.0111 - binary_accuracy: 0.6374\n","Epoch 2/50\n","455/455 [==============================] - 0s 150us/step - loss: 0.9997 - binary_accuracy: 0.6396\n","Epoch 3/50\n","455/455 [==============================] - 0s 146us/step - loss: 1.0004 - binary_accuracy: 0.6418\n","Epoch 4/50\n","455/455 [==============================] - 0s 149us/step - loss: 1.0007 - binary_accuracy: 0.6396\n","Epoch 5/50\n","455/455 [==============================] - 0s 165us/step - loss: 1.0002 - binary_accuracy: 0.6418\n","Epoch 6/50\n","455/455 [==============================] - 0s 151us/step - loss: 0.9999 - binary_accuracy: 0.6418\n","Epoch 7/50\n","455/455 [==============================] - 0s 173us/step - loss: 1.0001 - binary_accuracy: 0.6418\n","Epoch 8/50\n","455/455 [==============================] - 0s 192us/step - loss: 0.9992 - binary_accuracy: 0.6418\n","Epoch 9/50\n","455/455 [==============================] - 0s 170us/step - loss: 1.0000 - binary_accuracy: 0.6418\n","Epoch 10/50\n","455/455 [==============================] - 0s 150us/step - loss: 1.0000 - binary_accuracy: 0.6418\n","Epoch 11/50\n","455/455 [==============================] - 0s 146us/step - loss: 1.0000 - binary_accuracy: 0.6418\n","Epoch 12/50\n","455/455 [==============================] - 0s 149us/step - loss: 0.9997 - binary_accuracy: 0.6418\n","Epoch 13/50\n","455/455 [==============================] - 0s 156us/step - loss: 0.9974 - binary_accuracy: 0.6440\n","Epoch 14/50\n","455/455 [==============================] - 0s 172us/step - loss: 0.9986 - binary_accuracy: 0.6418\n","Epoch 15/50\n","455/455 [==============================] - 0s 148us/step - loss: 1.0000 - binary_accuracy: 0.6418\n","Epoch 16/50\n","455/455 [==============================] - 0s 150us/step - loss: 0.9998 - binary_accuracy: 0.6418\n","Epoch 17/50\n","455/455 [==============================] - 0s 154us/step - loss: 0.9980 - binary_accuracy: 0.6418\n","Epoch 18/50\n","455/455 [==============================] - 0s 162us/step - loss: 0.9972 - binary_accuracy: 0.6418\n","Epoch 19/50\n","455/455 [==============================] - 0s 165us/step - loss: 1.0008 - binary_accuracy: 0.6418\n","Epoch 20/50\n","455/455 [==============================] - 0s 156us/step - loss: 0.9999 - binary_accuracy: 0.6418\n","Epoch 21/50\n","455/455 [==============================] - 0s 151us/step - loss: 0.9984 - binary_accuracy: 0.6418\n","Epoch 22/50\n","455/455 [==============================] - 0s 157us/step - loss: 1.0007 - binary_accuracy: 0.6418\n","Epoch 23/50\n","455/455 [==============================] - 0s 153us/step - loss: 0.9997 - binary_accuracy: 0.6418\n","Epoch 24/50\n","455/455 [==============================] - 0s 159us/step - loss: 0.9986 - binary_accuracy: 0.6418\n","Epoch 25/50\n","455/455 [==============================] - 0s 155us/step - loss: 0.9956 - binary_accuracy: 0.6440\n","Epoch 26/50\n","455/455 [==============================] - 0s 143us/step - loss: 0.9972 - binary_accuracy: 0.6418\n","Epoch 27/50\n","455/455 [==============================] - 0s 143us/step - loss: 0.9960 - binary_accuracy: 0.6418\n","Epoch 28/50\n","455/455 [==============================] - 0s 164us/step - loss: 0.9916 - binary_accuracy: 0.6418\n","Epoch 29/50\n","455/455 [==============================] - 0s 184us/step - loss: 0.9972 - binary_accuracy: 0.6418\n","Epoch 30/50\n","455/455 [==============================] - 0s 188us/step - loss: 0.9966 - binary_accuracy: 0.6418\n","Epoch 31/50\n","455/455 [==============================] - 0s 190us/step - loss: 0.9949 - binary_accuracy: 0.6440\n","Epoch 32/50\n","455/455 [==============================] - 0s 206us/step - loss: 0.9917 - binary_accuracy: 0.6440\n","Epoch 33/50\n","455/455 [==============================] - 0s 191us/step - loss: 0.9956 - binary_accuracy: 0.6396\n","Epoch 34/50\n","455/455 [==============================] - 0s 193us/step - loss: 0.9997 - binary_accuracy: 0.6418\n","Epoch 35/50\n","455/455 [==============================] - 0s 205us/step - loss: 0.9921 - binary_accuracy: 0.6440\n","Epoch 36/50\n","455/455 [==============================] - 0s 196us/step - loss: 0.9948 - binary_accuracy: 0.6418\n","Epoch 37/50\n","455/455 [==============================] - 0s 186us/step - loss: 0.9986 - binary_accuracy: 0.6396\n","Epoch 38/50\n","455/455 [==============================] - 0s 190us/step - loss: 0.9808 - binary_accuracy: 0.6462\n","Epoch 39/50\n","455/455 [==============================] - 0s 209us/step - loss: 0.9742 - binary_accuracy: 0.6418\n","Epoch 40/50\n","455/455 [==============================] - 0s 181us/step - loss: 0.9761 - binary_accuracy: 0.6418\n","Epoch 41/50\n","455/455 [==============================] - 0s 186us/step - loss: 0.9845 - binary_accuracy: 0.6418\n","Epoch 42/50\n","455/455 [==============================] - 0s 182us/step - loss: 0.9829 - binary_accuracy: 0.6418\n","Epoch 43/50\n","455/455 [==============================] - 0s 218us/step - loss: 0.9828 - binary_accuracy: 0.6418\n","Epoch 44/50\n","455/455 [==============================] - 0s 177us/step - loss: 0.9799 - binary_accuracy: 0.6549\n","Epoch 45/50\n","455/455 [==============================] - 0s 154us/step - loss: 0.9800 - binary_accuracy: 0.6396\n","Epoch 46/50\n","455/455 [==============================] - 0s 153us/step - loss: 0.9966 - binary_accuracy: 0.6374\n","Epoch 47/50\n","455/455 [==============================] - 0s 154us/step - loss: 0.9944 - binary_accuracy: 0.6396\n","Epoch 48/50\n","455/455 [==============================] - 0s 152us/step - loss: 0.9952 - binary_accuracy: 0.6418\n","Epoch 49/50\n","455/455 [==============================] - 0s 153us/step - loss: 0.9846 - binary_accuracy: 0.6462\n","Epoch 50/50\n","455/455 [==============================] - 0s 170us/step - loss: 0.9647 - binary_accuracy: 0.6879\n","Model: \"sequential_103\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_307 (Dense)            (None, 16)                496       \n","_________________________________________________________________\n","dropout_205 (Dropout)        (None, 16)                0         \n","_________________________________________________________________\n","dense_308 (Dense)            (None, 16)                272       \n","_________________________________________________________________\n","dropout_206 (Dropout)        (None, 16)                0         \n","_________________________________________________________________\n","dense_309 (Dense)            (None, 1)                 17        \n","=================================================================\n","Total params: 785\n","Trainable params: 785\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/50\n","455/455 [==============================] - 0s 395us/step - loss: 1.2185 - binary_accuracy: 0.6154\n","Epoch 2/50\n","455/455 [==============================] - 0s 196us/step - loss: 1.0009 - binary_accuracy: 0.6220\n","Epoch 3/50\n","455/455 [==============================] - 0s 191us/step - loss: 0.9979 - binary_accuracy: 0.6198\n","Epoch 4/50\n","455/455 [==============================] - 0s 162us/step - loss: 1.0046 - binary_accuracy: 0.6176\n","Epoch 5/50\n","455/455 [==============================] - 0s 150us/step - loss: 0.9996 - binary_accuracy: 0.6220\n","Epoch 6/50\n","455/455 [==============================] - 0s 154us/step - loss: 0.9965 - binary_accuracy: 0.6220\n","Epoch 7/50\n","455/455 [==============================] - 0s 154us/step - loss: 0.9946 - binary_accuracy: 0.6220\n","Epoch 8/50\n","455/455 [==============================] - 0s 164us/step - loss: 0.9936 - binary_accuracy: 0.6176\n","Epoch 9/50\n","455/455 [==============================] - 0s 183us/step - loss: 0.9972 - binary_accuracy: 0.6220\n","Epoch 10/50\n","455/455 [==============================] - 0s 159us/step - loss: 0.9878 - binary_accuracy: 0.6132\n","Epoch 11/50\n","455/455 [==============================] - 0s 149us/step - loss: 0.9714 - binary_accuracy: 0.6220\n","Epoch 12/50\n","455/455 [==============================] - 0s 155us/step - loss: 0.9931 - binary_accuracy: 0.6132\n","Epoch 13/50\n","455/455 [==============================] - 0s 184us/step - loss: 0.9817 - binary_accuracy: 0.6176\n","Epoch 14/50\n","455/455 [==============================] - 0s 160us/step - loss: 0.9661 - binary_accuracy: 0.6220\n","Epoch 15/50\n","455/455 [==============================] - 0s 151us/step - loss: 0.9834 - binary_accuracy: 0.6286\n","Epoch 16/50\n","455/455 [==============================] - 0s 158us/step - loss: 0.9618 - binary_accuracy: 0.6484\n","Epoch 17/50\n","455/455 [==============================] - 0s 156us/step - loss: 0.9807 - binary_accuracy: 0.6198\n","Epoch 18/50\n","455/455 [==============================] - 0s 154us/step - loss: 0.9783 - binary_accuracy: 0.6198\n","Epoch 19/50\n","455/455 [==============================] - 0s 153us/step - loss: 0.9733 - binary_accuracy: 0.6286\n","Epoch 20/50\n","455/455 [==============================] - 0s 151us/step - loss: 0.9732 - binary_accuracy: 0.6198\n","Epoch 21/50\n","455/455 [==============================] - 0s 154us/step - loss: 0.9638 - binary_accuracy: 0.6242\n","Epoch 22/50\n","455/455 [==============================] - 0s 173us/step - loss: 0.9505 - binary_accuracy: 0.6308\n","Epoch 23/50\n","455/455 [==============================] - 0s 154us/step - loss: 0.9525 - binary_accuracy: 0.6242\n","Epoch 24/50\n","455/455 [==============================] - 0s 147us/step - loss: 0.9553 - binary_accuracy: 0.6264\n","Epoch 25/50\n","455/455 [==============================] - 0s 162us/step - loss: 0.9523 - binary_accuracy: 0.6132\n","Epoch 26/50\n","455/455 [==============================] - 0s 170us/step - loss: 0.9484 - binary_accuracy: 0.6220\n","Epoch 27/50\n","455/455 [==============================] - 0s 153us/step - loss: 0.9442 - binary_accuracy: 0.6286\n","Epoch 28/50\n","455/455 [==============================] - 0s 156us/step - loss: 0.9560 - binary_accuracy: 0.6088\n","Epoch 29/50\n","455/455 [==============================] - 0s 157us/step - loss: 0.9437 - binary_accuracy: 0.6176\n","Epoch 30/50\n","455/455 [==============================] - 0s 155us/step - loss: 0.9538 - binary_accuracy: 0.6418\n","Epoch 31/50\n","455/455 [==============================] - 0s 150us/step - loss: 0.9573 - binary_accuracy: 0.6286\n","Epoch 32/50\n","455/455 [==============================] - 0s 147us/step - loss: 0.9408 - binary_accuracy: 0.6308\n","Epoch 33/50\n","455/455 [==============================] - 0s 154us/step - loss: 0.9512 - binary_accuracy: 0.6264\n","Epoch 34/50\n","455/455 [==============================] - 0s 165us/step - loss: 0.9589 - binary_accuracy: 0.6286\n","Epoch 35/50\n","455/455 [==============================] - 0s 151us/step - loss: 0.9177 - binary_accuracy: 0.6352\n","Epoch 36/50\n","455/455 [==============================] - 0s 183us/step - loss: 0.8975 - binary_accuracy: 0.6286\n","Epoch 37/50\n","455/455 [==============================] - 0s 162us/step - loss: 0.8867 - binary_accuracy: 0.6242\n","Epoch 38/50\n","455/455 [==============================] - 0s 153us/step - loss: 0.8932 - binary_accuracy: 0.6286\n","Epoch 39/50\n","455/455 [==============================] - 0s 152us/step - loss: 0.8881 - binary_accuracy: 0.6308\n","Epoch 40/50\n","455/455 [==============================] - 0s 175us/step - loss: 0.8905 - binary_accuracy: 0.6308\n","Epoch 41/50\n","455/455 [==============================] - 0s 176us/step - loss: 0.8946 - binary_accuracy: 0.6352\n","Epoch 42/50\n","455/455 [==============================] - 0s 168us/step - loss: 0.8853 - binary_accuracy: 0.6286\n","Epoch 43/50\n","455/455 [==============================] - 0s 159us/step - loss: 0.8814 - binary_accuracy: 0.6264\n","Epoch 44/50\n","455/455 [==============================] - 0s 148us/step - loss: 0.8828 - binary_accuracy: 0.6308\n","Epoch 45/50\n","455/455 [==============================] - 0s 148us/step - loss: 0.8858 - binary_accuracy: 0.6286\n","Epoch 46/50\n","455/455 [==============================] - 0s 148us/step - loss: 0.8904 - binary_accuracy: 0.6308\n","Epoch 47/50\n","455/455 [==============================] - 0s 148us/step - loss: 0.8860 - binary_accuracy: 0.6286\n","Epoch 48/50\n","455/455 [==============================] - 0s 180us/step - loss: 0.8859 - binary_accuracy: 0.6308\n","Epoch 49/50\n","455/455 [==============================] - 0s 207us/step - loss: 0.8869 - binary_accuracy: 0.6308\n","Epoch 50/50\n","455/455 [==============================] - 0s 187us/step - loss: 0.8857 - binary_accuracy: 0.6396\n","Model: \"sequential_104\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_310 (Dense)            (None, 16)                496       \n","_________________________________________________________________\n","dropout_207 (Dropout)        (None, 16)                0         \n","_________________________________________________________________\n","dense_311 (Dense)            (None, 16)                272       \n","_________________________________________________________________\n","dropout_208 (Dropout)        (None, 16)                0         \n","_________________________________________________________________\n","dense_312 (Dense)            (None, 1)                 17        \n","=================================================================\n","Total params: 785\n","Trainable params: 785\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/50\n","455/455 [==============================] - 0s 363us/step - loss: 1.0069 - binary_accuracy: 0.5978\n","Epoch 2/50\n","455/455 [==============================] - 0s 150us/step - loss: 0.8975 - binary_accuracy: 0.6000\n","Epoch 3/50\n","455/455 [==============================] - 0s 143us/step - loss: 0.8951 - binary_accuracy: 0.5934\n","Epoch 4/50\n","455/455 [==============================] - 0s 162us/step - loss: 0.8985 - binary_accuracy: 0.6000\n","Epoch 5/50\n","455/455 [==============================] - 0s 175us/step - loss: 0.8945 - binary_accuracy: 0.5912\n","Epoch 6/50\n","455/455 [==============================] - 0s 193us/step - loss: 0.9060 - binary_accuracy: 0.6000\n","Epoch 7/50\n","455/455 [==============================] - 0s 165us/step - loss: 0.8937 - binary_accuracy: 0.5978\n","Epoch 8/50\n","455/455 [==============================] - 0s 159us/step - loss: 0.9169 - binary_accuracy: 0.5912\n","Epoch 9/50\n","455/455 [==============================] - 0s 168us/step - loss: 0.8899 - binary_accuracy: 0.5956\n","Epoch 10/50\n","455/455 [==============================] - 0s 155us/step - loss: 0.8794 - binary_accuracy: 0.5934\n","Epoch 11/50\n","455/455 [==============================] - 0s 160us/step - loss: 0.8852 - binary_accuracy: 0.5978\n","Epoch 12/50\n","455/455 [==============================] - 0s 170us/step - loss: 0.8897 - binary_accuracy: 0.6000\n","Epoch 13/50\n","455/455 [==============================] - 0s 152us/step - loss: 0.8851 - binary_accuracy: 0.6022\n","Epoch 14/50\n","455/455 [==============================] - 0s 147us/step - loss: 0.8784 - binary_accuracy: 0.6044\n","Epoch 15/50\n","455/455 [==============================] - 0s 151us/step - loss: 0.8842 - binary_accuracy: 0.6066\n","Epoch 16/50\n","455/455 [==============================] - 0s 150us/step - loss: 0.8878 - binary_accuracy: 0.6110\n","Epoch 17/50\n","455/455 [==============================] - 0s 150us/step - loss: 0.8957 - binary_accuracy: 0.6044\n","Epoch 18/50\n","455/455 [==============================] - 0s 156us/step - loss: 0.9126 - binary_accuracy: 0.5978\n","Epoch 19/50\n","455/455 [==============================] - 0s 155us/step - loss: 0.9007 - binary_accuracy: 0.6000\n","Epoch 20/50\n","455/455 [==============================] - 0s 160us/step - loss: 0.8763 - binary_accuracy: 0.5956\n","Epoch 21/50\n","455/455 [==============================] - 0s 160us/step - loss: 0.8905 - binary_accuracy: 0.6132\n","Epoch 22/50\n","455/455 [==============================] - 0s 213us/step - loss: 0.8814 - binary_accuracy: 0.5978\n","Epoch 23/50\n","455/455 [==============================] - 0s 159us/step - loss: 0.8853 - binary_accuracy: 0.6022\n","Epoch 24/50\n","455/455 [==============================] - 0s 172us/step - loss: 0.8823 - binary_accuracy: 0.5956\n","Epoch 25/50\n","455/455 [==============================] - 0s 158us/step - loss: 0.8828 - binary_accuracy: 0.5868\n","Epoch 26/50\n","455/455 [==============================] - 0s 152us/step - loss: 0.8821 - binary_accuracy: 0.5978\n","Epoch 27/50\n","455/455 [==============================] - 0s 149us/step - loss: 0.9169 - binary_accuracy: 0.5846\n","Epoch 28/50\n","455/455 [==============================] - 0s 161us/step - loss: 0.8800 - binary_accuracy: 0.5912\n","Epoch 29/50\n","455/455 [==============================] - 0s 155us/step - loss: 0.8762 - binary_accuracy: 0.5978\n","Epoch 30/50\n","455/455 [==============================] - 0s 148us/step - loss: 0.8786 - binary_accuracy: 0.6022\n","Epoch 31/50\n","455/455 [==============================] - 0s 147us/step - loss: 0.9082 - binary_accuracy: 0.6044\n","Epoch 32/50\n","455/455 [==============================] - 0s 165us/step - loss: 0.9076 - binary_accuracy: 0.5978\n","Epoch 33/50\n","455/455 [==============================] - 0s 168us/step - loss: 0.9126 - binary_accuracy: 0.6044\n","Epoch 34/50\n","455/455 [==============================] - 0s 152us/step - loss: 0.8794 - binary_accuracy: 0.5912\n","Epoch 35/50\n","455/455 [==============================] - 0s 179us/step - loss: 0.8808 - binary_accuracy: 0.6022\n","Epoch 36/50\n","455/455 [==============================] - 0s 169us/step - loss: 0.8891 - binary_accuracy: 0.5934\n","Epoch 37/50\n","455/455 [==============================] - 0s 149us/step - loss: 0.8876 - binary_accuracy: 0.5912\n","Epoch 38/50\n","455/455 [==============================] - 0s 157us/step - loss: 0.8832 - binary_accuracy: 0.6088\n","Epoch 39/50\n","455/455 [==============================] - 0s 159us/step - loss: 0.9193 - binary_accuracy: 0.5978\n","Epoch 40/50\n","455/455 [==============================] - 0s 187us/step - loss: 0.8840 - binary_accuracy: 0.6088\n","Epoch 41/50\n","455/455 [==============================] - 0s 166us/step - loss: 0.9173 - binary_accuracy: 0.6044\n","Epoch 42/50\n","455/455 [==============================] - 0s 152us/step - loss: 0.8824 - binary_accuracy: 0.6066\n","Epoch 43/50\n","455/455 [==============================] - 0s 151us/step - loss: 0.8814 - binary_accuracy: 0.6000\n","Epoch 44/50\n","455/455 [==============================] - 0s 152us/step - loss: 0.8784 - binary_accuracy: 0.6022\n","Epoch 45/50\n","455/455 [==============================] - 0s 167us/step - loss: 0.8796 - binary_accuracy: 0.5912\n","Epoch 46/50\n","455/455 [==============================] - 0s 149us/step - loss: 0.8771 - binary_accuracy: 0.5956\n","Epoch 47/50\n","455/455 [==============================] - 0s 167us/step - loss: 0.9001 - binary_accuracy: 0.6000\n","Epoch 48/50\n","455/455 [==============================] - 0s 153us/step - loss: 0.8878 - binary_accuracy: 0.6000\n","Epoch 49/50\n","455/455 [==============================] - 0s 176us/step - loss: 0.8835 - binary_accuracy: 0.5956\n","Epoch 50/50\n","455/455 [==============================] - 0s 147us/step - loss: 0.8779 - binary_accuracy: 0.5934\n","Model: \"sequential_105\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_313 (Dense)            (None, 16)                496       \n","_________________________________________________________________\n","dropout_209 (Dropout)        (None, 16)                0         \n","_________________________________________________________________\n","dense_314 (Dense)            (None, 16)                272       \n","_________________________________________________________________\n","dropout_210 (Dropout)        (None, 16)                0         \n","_________________________________________________________________\n","dense_315 (Dense)            (None, 1)                 17        \n","=================================================================\n","Total params: 785\n","Trainable params: 785\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/50\n","456/456 [==============================] - 0s 331us/step - loss: 1.0132 - binary_accuracy: 0.5855\n","Epoch 2/50\n","456/456 [==============================] - 0s 169us/step - loss: 0.9998 - binary_accuracy: 0.5921\n","Epoch 3/50\n","456/456 [==============================] - 0s 160us/step - loss: 1.0001 - binary_accuracy: 0.5921\n","Epoch 4/50\n","456/456 [==============================] - 0s 153us/step - loss: 0.9977 - binary_accuracy: 0.5921\n","Epoch 5/50\n","456/456 [==============================] - 0s 153us/step - loss: 1.0018 - binary_accuracy: 0.5899\n","Epoch 6/50\n","456/456 [==============================] - 0s 194us/step - loss: 0.9991 - binary_accuracy: 0.5921\n","Epoch 7/50\n","456/456 [==============================] - 0s 155us/step - loss: 0.9989 - binary_accuracy: 0.5921\n","Epoch 8/50\n","456/456 [==============================] - 0s 153us/step - loss: 1.0000 - binary_accuracy: 0.5921\n","Epoch 9/50\n","456/456 [==============================] - 0s 149us/step - loss: 0.9999 - binary_accuracy: 0.5921\n","Epoch 10/50\n","456/456 [==============================] - 0s 149us/step - loss: 1.0000 - binary_accuracy: 0.5921\n","Epoch 11/50\n","456/456 [==============================] - 0s 148us/step - loss: 0.9993 - binary_accuracy: 0.5921\n","Epoch 12/50\n","456/456 [==============================] - 0s 155us/step - loss: 0.9981 - binary_accuracy: 0.5921\n","Epoch 13/50\n","456/456 [==============================] - 0s 154us/step - loss: 0.9989 - binary_accuracy: 0.5921\n","Epoch 14/50\n","456/456 [==============================] - 0s 153us/step - loss: 0.9997 - binary_accuracy: 0.5921\n","Epoch 15/50\n","456/456 [==============================] - 0s 147us/step - loss: 1.0000 - binary_accuracy: 0.5921\n","Epoch 16/50\n","456/456 [==============================] - 0s 166us/step - loss: 0.9999 - binary_accuracy: 0.5921\n","Epoch 17/50\n","456/456 [==============================] - 0s 172us/step - loss: 1.0008 - binary_accuracy: 0.5899\n","Epoch 18/50\n","456/456 [==============================] - 0s 178us/step - loss: 0.9998 - binary_accuracy: 0.5921\n","Epoch 19/50\n","456/456 [==============================] - 0s 180us/step - loss: 1.0000 - binary_accuracy: 0.5921\n","Epoch 20/50\n","456/456 [==============================] - 0s 186us/step - loss: 0.9977 - binary_accuracy: 0.5943\n","Epoch 21/50\n","456/456 [==============================] - 0s 175us/step - loss: 0.9956 - binary_accuracy: 0.5943\n","Epoch 22/50\n","456/456 [==============================] - 0s 210us/step - loss: 0.9999 - binary_accuracy: 0.5921\n","Epoch 23/50\n","456/456 [==============================] - 0s 203us/step - loss: 0.9999 - binary_accuracy: 0.5899\n","Epoch 24/50\n","456/456 [==============================] - 0s 201us/step - loss: 1.0035 - binary_accuracy: 0.5899\n","Epoch 25/50\n","456/456 [==============================] - 0s 202us/step - loss: 1.0003 - binary_accuracy: 0.5921\n","Epoch 26/50\n","456/456 [==============================] - 0s 209us/step - loss: 0.9988 - binary_accuracy: 0.5921\n","Epoch 27/50\n","456/456 [==============================] - 0s 195us/step - loss: 0.9997 - binary_accuracy: 0.5921\n","Epoch 28/50\n","456/456 [==============================] - 0s 221us/step - loss: 0.9966 - binary_accuracy: 0.5899\n","Epoch 29/50\n","456/456 [==============================] - 0s 211us/step - loss: 0.9970 - binary_accuracy: 0.5921\n","Epoch 30/50\n","456/456 [==============================] - 0s 220us/step - loss: 0.9988 - binary_accuracy: 0.5921\n","Epoch 31/50\n","456/456 [==============================] - 0s 210us/step - loss: 0.9989 - binary_accuracy: 0.5921\n","Epoch 32/50\n","456/456 [==============================] - 0s 161us/step - loss: 1.0003 - binary_accuracy: 0.5921\n","Epoch 33/50\n","456/456 [==============================] - 0s 164us/step - loss: 0.9986 - binary_accuracy: 0.5921\n","Epoch 34/50\n","456/456 [==============================] - 0s 170us/step - loss: 1.0002 - binary_accuracy: 0.5899\n","Epoch 35/50\n","456/456 [==============================] - 0s 167us/step - loss: 1.0008 - binary_accuracy: 0.5921\n","Epoch 36/50\n","456/456 [==============================] - 0s 160us/step - loss: 1.0053 - binary_accuracy: 0.5899\n","Epoch 37/50\n","456/456 [==============================] - 0s 163us/step - loss: 0.9986 - binary_accuracy: 0.5921\n","Epoch 38/50\n","456/456 [==============================] - 0s 160us/step - loss: 0.9998 - binary_accuracy: 0.5921\n","Epoch 39/50\n","456/456 [==============================] - 0s 162us/step - loss: 1.0006 - binary_accuracy: 0.5921\n","Epoch 40/50\n","456/456 [==============================] - 0s 184us/step - loss: 0.9971 - binary_accuracy: 0.5899\n","Epoch 41/50\n","456/456 [==============================] - 0s 161us/step - loss: 0.9993 - binary_accuracy: 0.5921\n","Epoch 42/50\n","456/456 [==============================] - 0s 166us/step - loss: 1.0008 - binary_accuracy: 0.5921\n","Epoch 43/50\n","456/456 [==============================] - 0s 177us/step - loss: 1.0001 - binary_accuracy: 0.5921\n","Epoch 44/50\n","456/456 [==============================] - 0s 170us/step - loss: 1.0004 - binary_accuracy: 0.5921\n","Epoch 45/50\n","456/456 [==============================] - 0s 160us/step - loss: 1.0004 - binary_accuracy: 0.5921\n","Epoch 46/50\n","456/456 [==============================] - 0s 160us/step - loss: 0.9975 - binary_accuracy: 0.5921\n","Epoch 47/50\n","456/456 [==============================] - 0s 172us/step - loss: 1.0008 - binary_accuracy: 0.5921\n","Epoch 48/50\n","456/456 [==============================] - 0s 173us/step - loss: 1.0006 - binary_accuracy: 0.5921\n","Epoch 49/50\n","456/456 [==============================] - 0s 201us/step - loss: 1.0008 - binary_accuracy: 0.5921\n","Epoch 50/50\n","456/456 [==============================] - 0s 201us/step - loss: 0.9998 - binary_accuracy: 0.5921\n","Model: \"sequential_106\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_316 (Dense)            (None, 16)                496       \n","_________________________________________________________________\n","dropout_211 (Dropout)        (None, 16)                0         \n","_________________________________________________________________\n","dense_317 (Dense)            (None, 16)                272       \n","_________________________________________________________________\n","dropout_212 (Dropout)        (None, 16)                0         \n","_________________________________________________________________\n","dense_318 (Dense)            (None, 1)                 17        \n","=================================================================\n","Total params: 785\n","Trainable params: 785\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/50\n","455/455 [==============================] - 0s 445us/step - loss: 1.1882 - binary_accuracy: 0.6440\n","Epoch 2/50\n","455/455 [==============================] - 0s 197us/step - loss: 0.9988 - binary_accuracy: 0.6835\n","Epoch 3/50\n","455/455 [==============================] - 0s 198us/step - loss: 0.9990 - binary_accuracy: 0.6835\n","Epoch 4/50\n","455/455 [==============================] - 0s 203us/step - loss: 1.0006 - binary_accuracy: 0.6791\n","Epoch 5/50\n","455/455 [==============================] - 0s 218us/step - loss: 0.9987 - binary_accuracy: 0.6813\n","Epoch 6/50\n","455/455 [==============================] - 0s 205us/step - loss: 0.9983 - binary_accuracy: 0.6835\n","Epoch 7/50\n","455/455 [==============================] - 0s 242us/step - loss: 1.0003 - binary_accuracy: 0.6813\n","Epoch 8/50\n","455/455 [==============================] - 0s 264us/step - loss: 0.9979 - binary_accuracy: 0.6835\n","Epoch 9/50\n","455/455 [==============================] - 0s 201us/step - loss: 1.0005 - binary_accuracy: 0.6791\n","Epoch 10/50\n","455/455 [==============================] - 0s 217us/step - loss: 0.9954 - binary_accuracy: 0.6879\n","Epoch 11/50\n","455/455 [==============================] - 0s 197us/step - loss: 1.0027 - binary_accuracy: 0.6879\n","Epoch 12/50\n","455/455 [==============================] - 0s 199us/step - loss: 0.9895 - binary_accuracy: 0.6681\n","Epoch 13/50\n","455/455 [==============================] - 0s 199us/step - loss: 0.9289 - binary_accuracy: 0.7121\n","Epoch 14/50\n","455/455 [==============================] - 0s 202us/step - loss: 0.9317 - binary_accuracy: 0.7055\n","Epoch 15/50\n","455/455 [==============================] - 0s 215us/step - loss: 0.9257 - binary_accuracy: 0.7451\n","Epoch 16/50\n","455/455 [==============================] - 0s 217us/step - loss: 0.9158 - binary_accuracy: 0.7077\n","Epoch 17/50\n","455/455 [==============================] - 0s 214us/step - loss: 0.8926 - binary_accuracy: 0.7670\n","Epoch 18/50\n","455/455 [==============================] - 0s 218us/step - loss: 0.8826 - binary_accuracy: 0.7516\n","Epoch 19/50\n","455/455 [==============================] - 0s 200us/step - loss: 0.8595 - binary_accuracy: 0.7824\n","Epoch 20/50\n","455/455 [==============================] - 0s 213us/step - loss: 0.8513 - binary_accuracy: 0.8154\n","Epoch 21/50\n","455/455 [==============================] - 0s 198us/step - loss: 0.8258 - binary_accuracy: 0.8593\n","Epoch 22/50\n","455/455 [==============================] - 0s 198us/step - loss: 0.8329 - binary_accuracy: 0.8264\n","Epoch 23/50\n","455/455 [==============================] - 0s 200us/step - loss: 0.8423 - binary_accuracy: 0.8286\n","Epoch 24/50\n","455/455 [==============================] - 0s 197us/step - loss: 0.8141 - binary_accuracy: 0.8681\n","Epoch 25/50\n","455/455 [==============================] - 0s 208us/step - loss: 0.8064 - binary_accuracy: 0.8747\n","Epoch 26/50\n","455/455 [==============================] - 0s 239us/step - loss: 0.8020 - binary_accuracy: 0.8813\n","Epoch 27/50\n","455/455 [==============================] - 0s 231us/step - loss: 0.8461 - binary_accuracy: 0.8484\n","Epoch 28/50\n","455/455 [==============================] - 0s 278us/step - loss: 0.8152 - binary_accuracy: 0.8593\n","Epoch 29/50\n","455/455 [==============================] - 0s 211us/step - loss: 0.7937 - binary_accuracy: 0.8769\n","Epoch 30/50\n","455/455 [==============================] - 0s 210us/step - loss: 0.7900 - binary_accuracy: 0.8945\n","Epoch 31/50\n","455/455 [==============================] - 0s 205us/step - loss: 0.7912 - binary_accuracy: 0.9033\n","Epoch 32/50\n","455/455 [==============================] - 0s 207us/step - loss: 0.8042 - binary_accuracy: 0.8835\n","Epoch 33/50\n","455/455 [==============================] - 0s 206us/step - loss: 0.7849 - binary_accuracy: 0.9055\n","Epoch 34/50\n","455/455 [==============================] - 0s 215us/step - loss: 0.7772 - binary_accuracy: 0.9099\n","Epoch 35/50\n","455/455 [==============================] - 0s 206us/step - loss: 0.7700 - binary_accuracy: 0.9121\n","Epoch 36/50\n","455/455 [==============================] - 0s 227us/step - loss: 0.7869 - binary_accuracy: 0.8923\n","Epoch 37/50\n","455/455 [==============================] - 0s 209us/step - loss: 0.7841 - binary_accuracy: 0.9011\n","Epoch 38/50\n","455/455 [==============================] - 0s 216us/step - loss: 0.7759 - binary_accuracy: 0.9143\n","Epoch 39/50\n","455/455 [==============================] - 0s 200us/step - loss: 0.7685 - binary_accuracy: 0.9165\n","Epoch 40/50\n","455/455 [==============================] - 0s 239us/step - loss: 0.7954 - binary_accuracy: 0.8945\n","Epoch 41/50\n","455/455 [==============================] - 0s 224us/step - loss: 0.7809 - binary_accuracy: 0.9143\n","Epoch 42/50\n","455/455 [==============================] - 0s 197us/step - loss: 0.7833 - binary_accuracy: 0.9011\n","Epoch 43/50\n","455/455 [==============================] - 0s 204us/step - loss: 0.8000 - binary_accuracy: 0.8791\n","Epoch 44/50\n","455/455 [==============================] - 0s 220us/step - loss: 0.7738 - binary_accuracy: 0.9121\n","Epoch 45/50\n","455/455 [==============================] - 0s 214us/step - loss: 0.7734 - binary_accuracy: 0.9011\n","Epoch 46/50\n","455/455 [==============================] - 0s 227us/step - loss: 0.7678 - binary_accuracy: 0.9231\n","Epoch 47/50\n","455/455 [==============================] - 0s 244us/step - loss: 0.7663 - binary_accuracy: 0.9187\n","Epoch 48/50\n","455/455 [==============================] - 0s 265us/step - loss: 0.8120 - binary_accuracy: 0.8505\n","Epoch 49/50\n","455/455 [==============================] - 0s 201us/step - loss: 0.7906 - binary_accuracy: 0.8769\n","Epoch 50/50\n","455/455 [==============================] - 0s 201us/step - loss: 0.7939 - binary_accuracy: 0.9055\n","Model: \"sequential_107\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_319 (Dense)            (None, 16)                496       \n","_________________________________________________________________\n","dropout_213 (Dropout)        (None, 16)                0         \n","_________________________________________________________________\n","dense_320 (Dense)            (None, 16)                272       \n","_________________________________________________________________\n","dropout_214 (Dropout)        (None, 16)                0         \n","_________________________________________________________________\n","dense_321 (Dense)            (None, 1)                 17        \n","=================================================================\n","Total params: 785\n","Trainable params: 785\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/50\n","455/455 [==============================] - 0s 471us/step - loss: 1.0221 - binary_accuracy: 0.6374\n","Epoch 2/50\n","455/455 [==============================] - 0s 234us/step - loss: 0.9973 - binary_accuracy: 0.6462\n","Epoch 3/50\n","455/455 [==============================] - 0s 263us/step - loss: 1.0015 - binary_accuracy: 0.6396\n","Epoch 4/50\n","455/455 [==============================] - 0s 205us/step - loss: 0.9991 - binary_accuracy: 0.6418\n","Epoch 5/50\n","455/455 [==============================] - 0s 205us/step - loss: 1.0013 - binary_accuracy: 0.6374\n","Epoch 6/50\n","455/455 [==============================] - 0s 199us/step - loss: 1.0023 - binary_accuracy: 0.6396\n","Epoch 7/50\n","455/455 [==============================] - 0s 207us/step - loss: 1.0005 - binary_accuracy: 0.6418\n","Epoch 8/50\n","455/455 [==============================] - 0s 210us/step - loss: 1.0000 - binary_accuracy: 0.6418\n","Epoch 9/50\n","455/455 [==============================] - 0s 244us/step - loss: 1.0000 - binary_accuracy: 0.6418\n","Epoch 10/50\n","455/455 [==============================] - 0s 290us/step - loss: 1.0000 - binary_accuracy: 0.6418\n","Epoch 11/50\n","455/455 [==============================] - 0s 212us/step - loss: 1.0000 - binary_accuracy: 0.6418\n","Epoch 12/50\n","455/455 [==============================] - 0s 186us/step - loss: 1.0000 - binary_accuracy: 0.6418\n","Epoch 13/50\n","455/455 [==============================] - 0s 189us/step - loss: 1.0000 - binary_accuracy: 0.6418\n","Epoch 14/50\n","455/455 [==============================] - 0s 201us/step - loss: 0.9978 - binary_accuracy: 0.6440\n","Epoch 15/50\n","455/455 [==============================] - 0s 188us/step - loss: 0.9983 - binary_accuracy: 0.6440\n","Epoch 16/50\n","455/455 [==============================] - 0s 191us/step - loss: 1.0004 - binary_accuracy: 0.6396\n","Epoch 17/50\n","455/455 [==============================] - 0s 242us/step - loss: 0.9999 - binary_accuracy: 0.6418\n","Epoch 18/50\n","455/455 [==============================] - 0s 248us/step - loss: 0.9999 - binary_accuracy: 0.6418\n","Epoch 19/50\n","455/455 [==============================] - 0s 247us/step - loss: 1.0000 - binary_accuracy: 0.6418\n","Epoch 20/50\n","455/455 [==============================] - 0s 190us/step - loss: 0.9995 - binary_accuracy: 0.6418\n","Epoch 21/50\n","455/455 [==============================] - 0s 200us/step - loss: 0.9981 - binary_accuracy: 0.6418\n","Epoch 22/50\n","455/455 [==============================] - 0s 188us/step - loss: 0.9999 - binary_accuracy: 0.6418\n","Epoch 23/50\n","455/455 [==============================] - 0s 187us/step - loss: 0.9999 - binary_accuracy: 0.6418\n","Epoch 24/50\n","455/455 [==============================] - 0s 202us/step - loss: 1.0001 - binary_accuracy: 0.6418\n","Epoch 25/50\n","455/455 [==============================] - 0s 210us/step - loss: 0.9997 - binary_accuracy: 0.6418\n","Epoch 26/50\n","455/455 [==============================] - 0s 196us/step - loss: 1.0000 - binary_accuracy: 0.6418\n","Epoch 27/50\n","455/455 [==============================] - 0s 190us/step - loss: 0.9956 - binary_accuracy: 0.6462\n","Epoch 28/50\n","455/455 [==============================] - 0s 187us/step - loss: 0.9995 - binary_accuracy: 0.6440\n","Epoch 29/50\n","455/455 [==============================] - 0s 187us/step - loss: 0.9994 - binary_accuracy: 0.6396\n","Epoch 30/50\n","455/455 [==============================] - 0s 207us/step - loss: 0.9962 - binary_accuracy: 0.6440\n","Epoch 31/50\n","455/455 [==============================] - 0s 188us/step - loss: 1.0257 - binary_accuracy: 0.6484\n","Epoch 32/50\n","455/455 [==============================] - 0s 192us/step - loss: 0.9986 - binary_accuracy: 0.6418\n","Epoch 33/50\n","455/455 [==============================] - 0s 185us/step - loss: 0.9963 - binary_accuracy: 0.6462\n","Epoch 34/50\n","455/455 [==============================] - 0s 242us/step - loss: 0.9972 - binary_accuracy: 0.6418\n","Epoch 35/50\n","455/455 [==============================] - 0s 239us/step - loss: 0.9956 - binary_accuracy: 0.6462\n","Epoch 36/50\n","455/455 [==============================] - 0s 237us/step - loss: 0.9910 - binary_accuracy: 0.6527\n","Epoch 37/50\n","455/455 [==============================] - 0s 235us/step - loss: 0.9971 - binary_accuracy: 0.6418\n","Epoch 38/50\n","455/455 [==============================] - 0s 251us/step - loss: 0.9944 - binary_accuracy: 0.6440\n","Epoch 39/50\n","455/455 [==============================] - 0s 239us/step - loss: 0.9867 - binary_accuracy: 0.6527\n","Epoch 40/50\n","455/455 [==============================] - 0s 220us/step - loss: 0.9984 - binary_accuracy: 0.6374\n","Epoch 41/50\n","455/455 [==============================] - 0s 186us/step - loss: 0.9912 - binary_accuracy: 0.6462\n","Epoch 42/50\n","455/455 [==============================] - 0s 228us/step - loss: 0.9917 - binary_accuracy: 0.6505\n","Epoch 43/50\n","455/455 [==============================] - 0s 235us/step - loss: 0.9909 - binary_accuracy: 0.6484\n","Epoch 44/50\n","455/455 [==============================] - 0s 181us/step - loss: 0.9901 - binary_accuracy: 0.6484\n","Epoch 45/50\n","455/455 [==============================] - 0s 194us/step - loss: 0.9904 - binary_accuracy: 0.6440\n","Epoch 46/50\n","455/455 [==============================] - 0s 186us/step - loss: 0.9849 - binary_accuracy: 0.6505\n","Epoch 47/50\n","455/455 [==============================] - 0s 184us/step - loss: 0.9834 - binary_accuracy: 0.6571\n","Epoch 48/50\n","455/455 [==============================] - 0s 184us/step - loss: 0.9810 - binary_accuracy: 0.6571\n","Epoch 49/50\n","455/455 [==============================] - 0s 189us/step - loss: 0.9834 - binary_accuracy: 0.6527\n","Epoch 50/50\n","455/455 [==============================] - 0s 190us/step - loss: 0.9811 - binary_accuracy: 0.6593\n","Model: \"sequential_108\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_322 (Dense)            (None, 16)                496       \n","_________________________________________________________________\n","dropout_215 (Dropout)        (None, 16)                0         \n","_________________________________________________________________\n","dense_323 (Dense)            (None, 16)                272       \n","_________________________________________________________________\n","dropout_216 (Dropout)        (None, 16)                0         \n","_________________________________________________________________\n","dense_324 (Dense)            (None, 1)                 17        \n","=================================================================\n","Total params: 785\n","Trainable params: 785\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/50\n","455/455 [==============================] - 0s 457us/step - loss: 1.1462 - binary_accuracy: 0.6440\n","Epoch 2/50\n","455/455 [==============================] - 0s 204us/step - loss: 0.9845 - binary_accuracy: 0.6659\n","Epoch 3/50\n","455/455 [==============================] - 0s 208us/step - loss: 0.9413 - binary_accuracy: 0.6945\n","Epoch 4/50\n","455/455 [==============================] - 0s 248us/step - loss: 0.8568 - binary_accuracy: 0.7341\n","Epoch 5/50\n","455/455 [==============================] - 0s 198us/step - loss: 0.8652 - binary_accuracy: 0.7055\n","Epoch 6/50\n","455/455 [==============================] - 0s 225us/step - loss: 0.8541 - binary_accuracy: 0.7253\n","Epoch 7/50\n","455/455 [==============================] - 0s 200us/step - loss: 0.8425 - binary_accuracy: 0.7560\n","Epoch 8/50\n","455/455 [==============================] - 0s 202us/step - loss: 0.8319 - binary_accuracy: 0.7758\n","Epoch 9/50\n","455/455 [==============================] - 0s 197us/step - loss: 0.8198 - binary_accuracy: 0.7956\n","Epoch 10/50\n","455/455 [==============================] - 0s 197us/step - loss: 0.7939 - binary_accuracy: 0.8132\n","Epoch 11/50\n","455/455 [==============================] - 0s 197us/step - loss: 0.7920 - binary_accuracy: 0.8066\n","Epoch 12/50\n","455/455 [==============================] - 0s 197us/step - loss: 0.8185 - binary_accuracy: 0.8000\n","Epoch 13/50\n","455/455 [==============================] - 0s 199us/step - loss: 0.7982 - binary_accuracy: 0.8264\n","Epoch 14/50\n","455/455 [==============================] - 0s 221us/step - loss: 0.7961 - binary_accuracy: 0.8176\n","Epoch 15/50\n","455/455 [==============================] - 0s 275us/step - loss: 0.8279 - binary_accuracy: 0.7890\n","Epoch 16/50\n","455/455 [==============================] - 0s 212us/step - loss: 0.7927 - binary_accuracy: 0.8000\n","Epoch 17/50\n","455/455 [==============================] - 0s 195us/step - loss: 0.7736 - binary_accuracy: 0.8484\n","Epoch 18/50\n","455/455 [==============================] - 0s 197us/step - loss: 0.7938 - binary_accuracy: 0.8374\n","Epoch 19/50\n","455/455 [==============================] - 0s 191us/step - loss: 0.7727 - binary_accuracy: 0.8418\n","Epoch 20/50\n","455/455 [==============================] - 0s 194us/step - loss: 0.7791 - binary_accuracy: 0.8418\n","Epoch 21/50\n","455/455 [==============================] - 0s 193us/step - loss: 0.7587 - binary_accuracy: 0.8659\n","Epoch 22/50\n","455/455 [==============================] - 0s 197us/step - loss: 0.7730 - binary_accuracy: 0.8571\n","Epoch 23/50\n","455/455 [==============================] - 0s 204us/step - loss: 0.7599 - binary_accuracy: 0.8396\n","Epoch 24/50\n","455/455 [==============================] - 0s 197us/step - loss: 0.7728 - binary_accuracy: 0.8549\n","Epoch 25/50\n","455/455 [==============================] - 0s 196us/step - loss: 0.7625 - binary_accuracy: 0.8440\n","Epoch 26/50\n","455/455 [==============================] - 0s 212us/step - loss: 0.7567 - binary_accuracy: 0.8703\n","Epoch 27/50\n","455/455 [==============================] - 0s 258us/step - loss: 0.7439 - binary_accuracy: 0.8769\n","Epoch 28/50\n","455/455 [==============================] - 0s 242us/step - loss: 0.7462 - binary_accuracy: 0.8725\n","Epoch 29/50\n","455/455 [==============================] - 0s 196us/step - loss: 0.7460 - binary_accuracy: 0.8791\n","Epoch 30/50\n","455/455 [==============================] - 0s 193us/step - loss: 0.7560 - binary_accuracy: 0.8681\n","Epoch 31/50\n","455/455 [==============================] - 0s 193us/step - loss: 0.7425 - binary_accuracy: 0.8923\n","Epoch 32/50\n","455/455 [==============================] - 0s 195us/step - loss: 0.7440 - binary_accuracy: 0.8835\n","Epoch 33/50\n","455/455 [==============================] - 0s 196us/step - loss: 0.7387 - binary_accuracy: 0.8967\n","Epoch 34/50\n","455/455 [==============================] - 0s 194us/step - loss: 0.7446 - binary_accuracy: 0.8725\n","Epoch 35/50\n","455/455 [==============================] - 0s 245us/step - loss: 0.7328 - binary_accuracy: 0.8879\n","Epoch 36/50\n","455/455 [==============================] - 0s 263us/step - loss: 0.7359 - binary_accuracy: 0.8857\n","Epoch 37/50\n","455/455 [==============================] - 0s 213us/step - loss: 0.7321 - binary_accuracy: 0.8901\n","Epoch 38/50\n","455/455 [==============================] - 0s 193us/step - loss: 0.7488 - binary_accuracy: 0.8769\n","Epoch 39/50\n","455/455 [==============================] - 0s 197us/step - loss: 0.7634 - binary_accuracy: 0.8505\n","Epoch 40/50\n","455/455 [==============================] - 0s 200us/step - loss: 0.7353 - binary_accuracy: 0.8857\n","Epoch 41/50\n","455/455 [==============================] - 0s 192us/step - loss: 0.7262 - binary_accuracy: 0.9011\n","Epoch 42/50\n","455/455 [==============================] - 0s 194us/step - loss: 0.7366 - binary_accuracy: 0.8967\n","Epoch 43/50\n","455/455 [==============================] - 0s 194us/step - loss: 0.7318 - binary_accuracy: 0.9077\n","Epoch 44/50\n","455/455 [==============================] - 0s 208us/step - loss: 0.7359 - binary_accuracy: 0.8813\n","Epoch 45/50\n","455/455 [==============================] - 0s 198us/step - loss: 0.7317 - binary_accuracy: 0.8857\n","Epoch 46/50\n","455/455 [==============================] - 0s 206us/step - loss: 0.7411 - binary_accuracy: 0.8791\n","Epoch 47/50\n","455/455 [==============================] - 0s 216us/step - loss: 0.7367 - binary_accuracy: 0.8835\n","Epoch 48/50\n","455/455 [==============================] - 0s 230us/step - loss: 0.7387 - binary_accuracy: 0.8747\n","Epoch 49/50\n","455/455 [==============================] - 0s 199us/step - loss: 0.7275 - binary_accuracy: 0.8945\n","Epoch 50/50\n","455/455 [==============================] - 0s 200us/step - loss: 0.7552 - binary_accuracy: 0.8901\n","Model: \"sequential_109\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_325 (Dense)            (None, 16)                496       \n","_________________________________________________________________\n","dropout_217 (Dropout)        (None, 16)                0         \n","_________________________________________________________________\n","dense_326 (Dense)            (None, 16)                272       \n","_________________________________________________________________\n","dropout_218 (Dropout)        (None, 16)                0         \n","_________________________________________________________________\n","dense_327 (Dense)            (None, 1)                 17        \n","=================================================================\n","Total params: 785\n","Trainable params: 785\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/50\n","455/455 [==============================] - 0s 469us/step - loss: 1.2057 - binary_accuracy: 0.5670\n","Epoch 2/50\n","455/455 [==============================] - 0s 184us/step - loss: 1.0075 - binary_accuracy: 0.6044\n","Epoch 3/50\n","455/455 [==============================] - 0s 180us/step - loss: 1.0050 - binary_accuracy: 0.5934\n","Epoch 4/50\n","455/455 [==============================] - 0s 183us/step - loss: 0.9930 - binary_accuracy: 0.6022\n","Epoch 5/50\n","455/455 [==============================] - 0s 178us/step - loss: 0.9846 - binary_accuracy: 0.6022\n","Epoch 6/50\n","455/455 [==============================] - 0s 188us/step - loss: 0.9898 - binary_accuracy: 0.5956\n","Epoch 7/50\n","455/455 [==============================] - 0s 181us/step - loss: 0.9636 - binary_accuracy: 0.6022\n","Epoch 8/50\n","455/455 [==============================] - 0s 188us/step - loss: 0.9623 - binary_accuracy: 0.6044\n","Epoch 9/50\n","455/455 [==============================] - 0s 212us/step - loss: 0.9122 - binary_accuracy: 0.6176\n","Epoch 10/50\n","455/455 [==============================] - 0s 201us/step - loss: 0.8882 - binary_accuracy: 0.6440\n","Epoch 11/50\n","455/455 [==============================] - 0s 228us/step - loss: 0.8536 - binary_accuracy: 0.6505\n","Epoch 12/50\n","455/455 [==============================] - 0s 185us/step - loss: 0.8419 - binary_accuracy: 0.6440\n","Epoch 13/50\n","455/455 [==============================] - 0s 194us/step - loss: 0.8258 - binary_accuracy: 0.6945\n","Epoch 14/50\n","455/455 [==============================] - 0s 179us/step - loss: 0.8153 - binary_accuracy: 0.6967\n","Epoch 15/50\n","455/455 [==============================] - 0s 189us/step - loss: 0.8063 - binary_accuracy: 0.7473\n","Epoch 16/50\n","455/455 [==============================] - 0s 178us/step - loss: 0.7892 - binary_accuracy: 0.8000\n","Epoch 17/50\n"," 16/455 [>.............................] - ETA: 0s - loss: 0.7065 - binary_accuracy: 0.8750"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-24-40dc5a05ec2b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m gridsearch = gridsearch.fit(X = X, \n\u001b[0;32m----> 2\u001b[0;31m                             y = y)\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    708\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 710\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    711\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1149\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1150\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1151\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    687\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 689\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1030\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1032\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1033\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    845\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    846\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 847\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    848\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    766\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    568\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 253\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 253\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    513\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 515\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/wrappers/scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, sample_weight, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sample_weight'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mKerasClassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/wrappers/scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0mfit_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m         \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3790\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3791\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3792\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3793\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3794\u001b[0m     \u001b[0;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1603\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1604\u001b[0m     \"\"\"\n\u001b[0;32m-> 1605\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1607\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1643\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m   1644\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m-> 1645\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1647\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"GRI9WzmetPWp","colab_type":"code","colab":{}},"source":["best_params = gridsearch.best_params_\n","best_accuracy = gridsearch.best_score_  "],"execution_count":null,"outputs":[]}]}